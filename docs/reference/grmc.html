<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc • gkwdist</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc"><meta name="description" content="Computes the gradient vector (vector of first partial derivatives) of the
negative log-likelihood function for the McDonald (Mc) distribution (also
known as Beta Power) with parameters gamma (\(\gamma\)), delta
(\(\delta\)), and lambda (\(\lambda\)). This distribution is the
special case of the Generalized Kumaraswamy (GKw) distribution where
\(\alpha = 1\) and \(\beta = 1\). The gradient is useful for optimization."><meta property="og:description" content="Computes the gradient vector (vector of first partial derivatives) of the
negative log-likelihood function for the McDonald (Mc) distribution (also
known as Beta Power) with parameters gamma (\(\gamma\)), delta
(\(\delta\)), and lambda (\(\lambda\)). This distribution is the
special case of the Generalized Kumaraswamy (GKw) distribution where
\(\alpha = 1\) and \(\beta = 1\). The gradient is useful for optimization."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="default" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">gkwdist</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../index.html" aria-label="Home"><span class="fa fa-home"></span></a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><a class="external-link nav-link" href="https://github.com/evandeilton/gkwdist" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution</h1>
      <small class="dont-index">Source: <a href="https://github.com/evandeilton/gkwdist/blob/HEAD/R/RcppExports.R" class="external-link"><code>R/RcppExports.R</code></a></small>
      <div class="d-none name"><code>grmc.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>Computes the gradient vector (vector of first partial derivatives) of the
negative log-likelihood function for the McDonald (Mc) distribution (also
known as Beta Power) with parameters <code>gamma</code> (\(\gamma\)), <code>delta</code>
(\(\delta\)), and <code>lambda</code> (\(\lambda\)). This distribution is the
special case of the Generalized Kumaraswamy (GKw) distribution where
\(\alpha = 1\) and \(\beta = 1\). The gradient is useful for optimization.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">grmc</span><span class="op">(</span><span class="va">par</span>, <span class="va">data</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-par">par<a class="anchor" aria-label="anchor" href="#arg-par"></a></dt>
<dd><p>A numeric vector of length 3 containing the distribution parameters
in the order: <code>gamma</code> (\(\gamma &gt; 0\)), <code>delta</code> (\(\delta \ge 0\)),
<code>lambda</code> (\(\lambda &gt; 0\)).</p></dd>


<dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>A numeric vector of observations. All values must be strictly
between 0 and 1 (exclusive).</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>Returns a numeric vector of length 3 containing the partial derivatives
of the negative log-likelihood function \(-\ell(\theta | \mathbf{x})\) with
respect to each parameter:
\((-\partial \ell/\partial \gamma, -\partial \ell/\partial \delta, -\partial \ell/\partial \lambda)\).
Returns a vector of <code>NaN</code> if any parameter values are invalid according
to their constraints, or if any value in <code>data</code> is not in the
interval (0, 1).</p>
    </div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>The components of the gradient vector of the negative log-likelihood
(\(-\nabla \ell(\theta | \mathbf{x})\)) for the Mc (\(\alpha=1, \beta=1\))
model are:</p>
<p>$$
-\frac{\partial \ell}{\partial \gamma} = n[\psi(\gamma+\delta+1) - \psi(\gamma)] -
\lambda\sum_{i=1}^{n}\ln(x_i)
$$
$$
-\frac{\partial \ell}{\partial \delta} = n[\psi(\gamma+\delta+1) - \psi(\delta+1)] -
\sum_{i=1}^{n}\ln(1-x_i^{\lambda})
$$
$$
-\frac{\partial \ell}{\partial \lambda} = -\frac{n}{\lambda} - \gamma\sum_{i=1}^{n}\ln(x_i) +
\delta\sum_{i=1}^{n}\frac{x_i^{\lambda}\ln(x_i)}{1-x_i^{\lambda}}
$$</p>
<p>where \(\psi(\cdot)\) is the digamma function (<code><a href="https://rdrr.io/r/base/Special.html" class="external-link">digamma</a></code>).
These formulas represent the derivatives of \(-\ell(\theta)\), consistent with
minimizing the negative log-likelihood. They correspond to the relevant components
of the general GKw gradient (<code><a href="grgkw.html">grgkw</a></code>) evaluated at \(\alpha=1, \beta=1\).</p>
    </div>
    <div class="section level2">
    <h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a></h2>
    <p>McDonald, J. B. (1984). Some generalized functions for the size distribution
of income. <em>Econometrica</em>, 52(3), 647-663.</p>
<p>Cordeiro, G. M., &amp; de Castro, M. (2011). A new family of generalized
distributions. <em>Journal of Statistical Computation and Simulation</em>,</p>
<p>(Note: Specific gradient formulas might be derived or sourced from additional references).</p>
    </div>
    <div class="section level2">
    <h2 id="see-also">See also<a class="anchor" aria-label="anchor" href="#see-also"></a></h2>
    <div class="dont-index"><p><code><a href="grgkw.html">grgkw</a></code> (parent distribution gradient),
<code><a href="llmc.html">llmc</a></code> (negative log-likelihood for Mc),
<code>hsmc</code> (Hessian for Mc, if available),
<code><a href="dmc.html">dmc</a></code> (density for Mc),
<code><a href="https://rdrr.io/r/stats/optim.html" class="external-link">optim</a></code>,
<code><a href="https://rdrr.io/pkg/numDeriv/man/grad.html" class="external-link">grad</a></code> (for numerical gradient comparison),
<code><a href="https://rdrr.io/r/base/Special.html" class="external-link">digamma</a></code>.</p></div>
    </div>
    <div class="section level2">
    <h2 id="author">Author<a class="anchor" aria-label="anchor" href="#author"></a></h2>
    <p>Lopes, J. E.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="co"># \donttest{</span></span></span>
<span class="r-in"><span><span class="co"># Assuming existence of rmc, llmc, grmc, hsmc functions for Mc distribution</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Generate sample data</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">true_par_mc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span>gamma <span class="op">=</span> <span class="fl">2</span>, delta <span class="op">=</span> <span class="fl">3</span>, lambda <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">sample_data_mc</span> <span class="op">&lt;-</span> <span class="fu"><a href="rmc.html">rmc</a></span><span class="op">(</span><span class="fl">100</span>, gamma <span class="op">=</span> <span class="va">true_par_mc</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, delta <span class="op">=</span> <span class="va">true_par_mc</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>,</span></span>
<span class="r-in"><span>                      lambda <span class="op">=</span> <span class="va">true_par_mc</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html" class="external-link">hist</a></span><span class="op">(</span><span class="va">sample_data_mc</span>, breaks <span class="op">=</span> <span class="fl">20</span>, main <span class="op">=</span> <span class="st">"Mc(2, 3, 0.5) Sample"</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="grmc-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># --- Find MLE estimates ---</span></span></span>
<span class="r-in"><span><span class="va">start_par_mc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">0.8</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">mle_result_mc</span> <span class="op">&lt;-</span> <span class="fu">stats</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/r/stats/optim.html" class="external-link">optim</a></span><span class="op">(</span>par <span class="op">=</span> <span class="va">start_par_mc</span>,</span></span>
<span class="r-in"><span>                              fn <span class="op">=</span> <span class="va">llmc</span>,</span></span>
<span class="r-in"><span>                              gr <span class="op">=</span> <span class="va">grmc</span>, <span class="co"># Use analytical gradient for Mc</span></span></span>
<span class="r-in"><span>                              method <span class="op">=</span> <span class="st">"BFGS"</span>,</span></span>
<span class="r-in"><span>                              hessian <span class="op">=</span> <span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>                              data <span class="op">=</span> <span class="va">sample_data_mc</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># --- Compare analytical gradient to numerical gradient ---</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="va">mle_result_mc</span><span class="op">$</span><span class="va">convergence</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">&amp;&amp;</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"numDeriv"</span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="va">mle_par_mc</span> <span class="op">&lt;-</span> <span class="va">mle_result_mc</span><span class="op">$</span><span class="va">par</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"\nComparing Gradients for Mc at MLE estimates:\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="co"># Numerical gradient of llmc</span></span></span>
<span class="r-in"><span>  <span class="va">num_grad_mc</span> <span class="op">&lt;-</span> <span class="fu">numDeriv</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/numDeriv/man/grad.html" class="external-link">grad</a></span><span class="op">(</span>func <span class="op">=</span> <span class="va">llmc</span>, x <span class="op">=</span> <span class="va">mle_par_mc</span>, data <span class="op">=</span> <span class="va">sample_data_mc</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="co"># Analytical gradient from grmc</span></span></span>
<span class="r-in"><span>  <span class="va">ana_grad_mc</span> <span class="op">&lt;-</span> <span class="fu">grmc</span><span class="op">(</span>par <span class="op">=</span> <span class="va">mle_par_mc</span>, data <span class="op">=</span> <span class="va">sample_data_mc</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Numerical Gradient (Mc):\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">num_grad_mc</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Analytical Gradient (Mc):\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">ana_grad_mc</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="co"># Check differences</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Max absolute difference between Mc gradients:\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">num_grad_mc</span> <span class="op">-</span> <span class="va">ana_grad_mc</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="kw">else</span> <span class="op">{</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"\nSkipping Mc gradient comparison.\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Comparing Gradients for Mc at MLE estimates:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Numerical Gradient (Mc):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -0.0090383310 -0.0008723594 -0.0061479778</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Analytical Gradient (Mc):</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] -0.0090383286 -0.0008723581 -0.0061479812</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Max absolute difference between Mc gradients:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 3.31495e-09</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example with Hessian comparison (if hsmc exists)</span></span></span>
<span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="va">mle_result_mc</span><span class="op">$</span><span class="va">convergence</span> <span class="op">==</span> <span class="fl">0</span> <span class="op">&amp;&amp;</span></span></span>
<span class="r-in"><span>    <span class="fu"><a href="https://rdrr.io/r/base/ns-load.html" class="external-link">requireNamespace</a></span><span class="op">(</span><span class="st">"numDeriv"</span>, quietly <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="fu"><a href="https://rdrr.io/r/base/exists.html" class="external-link">exists</a></span><span class="op">(</span><span class="st">"hsmc"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span>  <span class="va">num_hess_mc</span> <span class="op">&lt;-</span> <span class="fu">numDeriv</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/numDeriv/man/hessian.html" class="external-link">hessian</a></span><span class="op">(</span>func <span class="op">=</span> <span class="va">llmc</span>, x <span class="op">=</span> <span class="va">mle_par_mc</span>, data <span class="op">=</span> <span class="va">sample_data_mc</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="va">ana_hess_mc</span> <span class="op">&lt;-</span> <span class="fu"><a href="hsmc.html">hsmc</a></span><span class="op">(</span>par <span class="op">=</span> <span class="va">mle_par_mc</span>, data <span class="op">=</span> <span class="va">sample_data_mc</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"\nMax absolute difference between Mc Hessians:\n"</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html" class="external-link">max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">abs</a></span><span class="op">(</span><span class="va">num_hess_mc</span> <span class="op">-</span> <span class="va">ana_hess_mc</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="op">}</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Max absolute difference between Mc Hessians:</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1] 1.039143e-08</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Lopes, J. E..</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer></div>





  </body></html>

