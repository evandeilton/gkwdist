[{"path":"https://evandeilton.github.io/gkwdist/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 gkwdist authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"J. E. Lopes. Author, maintainer.","code":""},{"path":"https://evandeilton.github.io/gkwdist/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Lopes J (2025). gkwdist: Generalized Kumaraswamy Distribution Family. R package version 1.0.5, https://github.com/evandeilton/gkwdist.","code":"@Manual{,   title = {gkwdist: Generalized Kumaraswamy Distribution Family},   author = {J. E. Lopes},   year = {2025},   note = {R package version 1.0.5},   url = {https://github.com/evandeilton/gkwdist}, }"},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"gkwdist implements Generalized Kumaraswamy (GKw) distribution family seven nested sub-models bounded continuous data (0,1)(0,1). functions implemented C++ via RcppArmadillo maximum computational efficiency. Key Features: - Seven flexible distributions proportions, rates, bounded data - Standard R distribution API: d*, p*, q*, r* - Analytical log-likelihood, gradient, Hessian functions - functions implemented C++ optimal performance - 10-50× faster equivalent R implementations - Numerically stable extreme parameter values","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"# Install from GitHub # install.packages(\"devtools\") devtools::install_github(\"evandeilton/gkwdist\")"},{"path":[]},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"function-types","dir":"","previous_headings":"The Distribution Family","what":"Function Types","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Distribution Functions (C++ implementation R interface): d*() — Probability density function (PDF) p*() — Cumulative distribution function (CDF) q*() — Quantile function (inverse CDF) r*() — Random number generation Analytical Functions Maximum Likelihood (C++ implementation): analytical functions use signature: function(par, data) par numeric vector parameters. ll*(par, data) — Negative log-likelihood: −ℓ(𝛉;𝐱)=−∑=1nlogf(xi;𝛉)-\\ell(\\boldsymbol{\\theta}; \\mathbf{x}) = -\\sum_{=1}^n \\log f(x_i; \\boldsymbol{\\theta}) gr*(par, data) — Negative gradient (negative score vector): −∇𝛉ℓ(𝛉;𝐱)-\\nabla_{\\boldsymbol{\\theta}} \\ell(\\boldsymbol{\\theta}; \\mathbf{x}) hs*(par, data) — Negative Hessian matrix: −∇𝛉2ℓ(𝛉;𝐱)-\\nabla^2_{\\boldsymbol{\\theta}} \\ell(\\boldsymbol{\\theta}; \\mathbf{x}) Note: functions return negative values facilitate direct use optimization routines like optim(), perform minimization default.","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"mathematical-specification","dir":"","previous_headings":"","what":"Mathematical Specification","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Notation: parameters strictly positive (α,β,γ,δ,λ>0\\alpha, \\beta, \\gamma, \\delta, \\lambda > 0); support x∈(0,1)x \\(0, 1). beta function B(,b)=Γ()Γ(b)/Γ(+b)B(,b) = \\Gamma()\\Gamma(b)/\\Gamma(+b), regularized incomplete beta function Iz(,b)=Bz(,b)/B(,b)I_z(,b) = B_z(,b)/B(,b) Bz(,b)=∫0zta−1(1−t)b−1dtB_z(,b) = \\int_0^z t^{-1}(1-t)^{b-1}dt.","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"id_1-generalized-kumaraswamy-gkw","dir":"","previous_headings":"Mathematical Specification","what":"1. Generalized Kumaraswamy (GKw)","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Parameters: α,β,γ,δ,λ>0\\alpha, \\beta, \\gamma, \\delta, \\lambda > 0 PDF: fGKw(x;α,β,γ,δ,λ)=λαβB(γ,δ)xα−1(1−xα)β−1[1−(1−xα)β]γλ−1{1−[1−(1−xα)β]λ}δ−1f_{\\text{GKw}}(x; \\alpha, \\beta, \\gamma, \\delta, \\lambda) = \\frac{\\lambda \\alpha \\beta}{B(\\gamma, \\delta)} x^{\\alpha-1} (1-x^\\alpha)^{\\beta-1} [1-(1-x^\\alpha)^\\beta]^{\\gamma\\lambda-1} \\left\\{1-[1-(1-x^\\alpha)^\\beta]^\\lambda\\right\\}^{\\delta-1} CDF: FGKw(x;α,β,γ,δ,λ)=[1−(1−xα)β]λ(γ,δ)F_{\\text{GKw}}(x; \\alpha, \\beta, \\gamma, \\delta, \\lambda) = I_{[1-(1-x^\\alpha)^\\beta]^\\lambda}(\\gamma, \\delta) Quantile: Numerical inversion CDF via root-finding algorithms. Moments: Analytical expressions available closed form. Numerical integration simulation methods required.","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"id_2-beta-kumaraswamy-bkw","dir":"","previous_headings":"Mathematical Specification","what":"2. Beta-Kumaraswamy (BKw)","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Relationship: Special case GKw λ=1\\lambda = 1 PDF: fBKw(x;α,β,γ,δ)=αβB(γ,δ)xα−1(1−xα)β−1[1−(1−xα)β]γ−1{1−[1−(1−xα)β]}δ−1f_{\\text{BKw}}(x; \\alpha, \\beta, \\gamma, \\delta) = \\frac{\\alpha \\beta}{B(\\gamma, \\delta)} x^{\\alpha-1} (1-x^\\alpha)^{\\beta-1} [1-(1-x^\\alpha)^\\beta]^{\\gamma-1} \\left\\{1-[1-(1-x^\\alpha)^\\beta]\\right\\}^{\\delta-1} Simplifying: fBKw(x;α,β,γ,δ)=αβB(γ,δ)xα−1(1−xα)β−1[1−(1−xα)β]γ−1(1−xα)β(δ−1)f_{\\text{BKw}}(x; \\alpha, \\beta, \\gamma, \\delta) = \\frac{\\alpha \\beta}{B(\\gamma, \\delta)} x^{\\alpha-1} (1-x^\\alpha)^{\\beta-1} [1-(1-x^\\alpha)^\\beta]^{\\gamma-1} (1-x^\\alpha)^{\\beta(\\delta-1)} =αβB(γ,δ)xα−1(1−xα)βδ−1[1−(1−xα)β]γ−1= \\frac{\\alpha \\beta}{B(\\gamma, \\delta)} x^{\\alpha-1} (1-x^\\alpha)^{\\beta\\delta-1} [1-(1-x^\\alpha)^\\beta]^{\\gamma-1} CDF: FBKw(x;α,β,γ,δ)=I1−(1−xα)β(γ,δ)F_{\\text{BKw}}(x; \\alpha, \\beta, \\gamma, \\delta) = I_{1-(1-x^\\alpha)^\\beta}(\\gamma, \\delta) Quantile: Numerical inversion via root-finding. inverse: u=Iy(γ,δ)wherey=1−(1−xα)βu = I_y(\\gamma, \\delta) \\quad \\text{} \\quad y = 1-(1-x^\\alpha)^\\beta Solving xx: x=[1−(1−Iu−1(γ,δ))1/β]1/αx = \\left[1-\\left(1-I_u^{-1}(\\gamma, \\delta)\\right)^{1/\\beta}\\right]^{1/\\alpha}","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"id_3-kumaraswamy-kumaraswamy-kkw","dir":"","previous_headings":"Mathematical Specification","what":"3. Kumaraswamy-Kumaraswamy (KKw)","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Relationship: Special case GKw γ=1\\gamma = 1 PDF: fKKw(x;α,β,δ,λ)=αβδλxα−1(1−xα)β−1[1−(1−xα)β]λ−1{1−[1−(1−xα)β]λ}δ−1f_{\\text{KKw}}(x; \\alpha, \\beta, \\delta, \\lambda) = \\alpha \\beta \\delta \\lambda \\, x^{\\alpha-1} (1-x^\\alpha)^{\\beta-1} [1-(1-x^\\alpha)^\\beta]^{\\lambda-1} \\left\\{1-[1-(1-x^\\alpha)^\\beta]^\\lambda\\right\\}^{\\delta-1} CDF: FKKw(x;α,β,δ,λ)=1−{1−[1−(1−xα)β]λ}δF_{\\text{KKw}}(x; \\alpha, \\beta, \\delta, \\lambda) = 1 - \\left\\{1-[1-(1-x^\\alpha)^\\beta]^\\lambda\\right\\}^\\delta Quantile (closed-form): QKKw(p;α,β,δ,λ)=[1−(1−[1−(1−p)1/δ]1/λ)1/β]1/αQ_{\\text{KKw}}(p; \\alpha, \\beta, \\delta, \\lambda) = \\left[1 - \\left(1 - \\left[1-(1-p)^{1/\\delta}\\right]^{1/\\lambda}\\right)^{1/\\beta}\\right]^{1/\\alpha} Moments: Analytical expressions available closed form.","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"id_4-exponentiated-kumaraswamy-ekw","dir":"","previous_headings":"Mathematical Specification","what":"4. Exponentiated Kumaraswamy (EKw)","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Relationship: Special case GKw γ=δ=1\\gamma = \\delta = 1 PDF: fEKw(x;α,β,λ)=λαβxα−1(1−xα)β−1[1−(1−xα)β]λ−1f_{\\text{EKw}}(x; \\alpha, \\beta, \\lambda) = \\lambda \\alpha \\beta \\, x^{\\alpha-1} (1-x^\\alpha)^{\\beta-1} [1-(1-x^\\alpha)^\\beta]^{\\lambda-1} CDF: FEKw(x;α,β,λ)=[1−(1−xα)β]λF_{\\text{EKw}}(x; \\alpha, \\beta, \\lambda) = [1-(1-x^\\alpha)^\\beta]^\\lambda Quantile (closed-form): QEKw(p;α,β,λ)=[1−(1−p1/λ)1/β]1/αQ_{\\text{EKw}}(p; \\alpha, \\beta, \\lambda) = \\left[1-\\left(1-p^{1/\\lambda}\\right)^{1/\\beta}\\right]^{1/\\alpha} Moments: 𝔼(Xr)=λ∑k=0∞(−1)k(λk+1)k+1⋅βB(1+rα,(k+1)β)\\mathbb{E}(X^r) = \\lambda \\sum_{k=0}^{\\infty} \\frac{(-1)^k \\binom{\\lambda}{k+1}}{k+1} \\cdot \\beta B\\left(1 + \\frac{r}{\\alpha}, (k+1)\\beta\\right) binomial coefficient generalized: (λk+1)=λ(λ−1)⋯(λ−k)(k+1)!\\binom{\\lambda}{k+1} = \\frac{\\lambda(\\lambda-1)\\cdots(\\lambda-k)}{(k+1)!}.","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"id_5-mcdonald-beta-power","dir":"","previous_headings":"Mathematical Specification","what":"5. McDonald (Beta Power)","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Relationship: Special case GKw α=β=1\\alpha = \\beta = 1 PDF: fMC(x;γ,δ,λ)=λB(γ,δ)xγλ−1(1−xλ)δ−1f_{\\text{MC}}(x; \\gamma, \\delta, \\lambda) = \\frac{\\lambda}{B(\\gamma, \\delta)} x^{\\gamma\\lambda-1} (1-x^\\lambda)^{\\delta-1} CDF: FMC(x;γ,δ,λ)=Ixλ(γ,δ)F_{\\text{MC}}(x; \\gamma, \\delta, \\lambda) = I_{x^\\lambda}(\\gamma, \\delta) Quantile: QMC(p;γ,δ,λ)=[Ip−1(γ,δ)]1/λQ_{\\text{MC}}(p; \\gamma, \\delta, \\lambda) = [I_p^{-1}(\\gamma, \\delta)]^{1/\\lambda} Ip−1(γ,δ)I_p^{-1}(\\gamma, \\delta) inverse regularized incomplete beta function (quantile function Beta distribution). Moments: 𝔼(Xr)=B(γ+r/λ,δ)B(γ,δ)\\mathbb{E}(X^r) = \\frac{B(\\gamma + r/\\lambda, \\delta)}{B(\\gamma, \\delta)} valid r/λ>−γr/\\lambda > -\\gamma.","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"id_6-kumaraswamy-kw","dir":"","previous_headings":"Mathematical Specification","what":"6. Kumaraswamy (Kw)","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Relationship: Special case GKw γ=δ=λ=1\\gamma = \\delta = \\lambda = 1 PDF: fKw(x;α,β)=αβxα−1(1−xα)β−1f_{\\text{Kw}}(x; \\alpha, \\beta) = \\alpha \\beta \\, x^{\\alpha-1} (1-x^\\alpha)^{\\beta-1} CDF: FKw(x;α,β)=1−(1−xα)βF_{\\text{Kw}}(x; \\alpha, \\beta) = 1 - (1-x^\\alpha)^\\beta Quantile (closed-form): QKw(p;α,β)=[1−(1−p)1/β]1/αQ_{\\text{Kw}}(p; \\alpha, \\beta) = [1-(1-p)^{1/\\beta}]^{1/\\alpha} Moments: 𝔼(Xr)=βB(1+rα,β)=βΓ(1+r/α)Γ(β)Γ(1+r/α+β)\\mathbb{E}(X^r) = \\beta B\\left(1 + \\frac{r}{\\alpha}, \\beta\\right) = \\frac{\\beta \\, \\Gamma(1+r/\\alpha) \\, \\Gamma(\\beta)}{\\Gamma(1+r/\\alpha+\\beta)} valid r/α>−1r/\\alpha > -1. Special Cases: 𝔼(X)=βΓ(1+1/α)Γ(β)Γ(1+1/α+β)\\mathbb{E}(X) = \\frac{\\beta \\, \\Gamma(1+1/\\alpha) \\, \\Gamma(\\beta)}{\\Gamma(1+1/\\alpha+\\beta)} 𝔼(X2)=βΓ(1+2/α)Γ(β)Γ(1+2/α+β)\\mathbb{E}(X^2) = \\frac{\\beta \\, \\Gamma(1+2/\\alpha) \\, \\Gamma(\\beta)}{\\Gamma(1+2/\\alpha+\\beta)} Var(X)=𝔼(X2)−[𝔼(X)]2\\text{Var}(X) = \\mathbb{E}(X^2) - [\\mathbb{E}(X)]^2","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"id_7-beta","dir":"","previous_headings":"Mathematical Specification","what":"7. Beta","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Relationship: Special case GKw α=β=λ=1\\alpha = \\beta = \\lambda = 1 PDF: fBeta(x;γ,δ)=1B(γ,δ)xγ−1(1−x)δ−1f_{\\text{Beta}}(x; \\gamma, \\delta) = \\frac{1}{B(\\gamma, \\delta)} x^{\\gamma-1} (1-x)^{\\delta-1} CDF: FBeta(x;γ,δ)=Ix(γ,δ)F_{\\text{Beta}}(x; \\gamma, \\delta) = I_x(\\gamma, \\delta) Quantile: QBeta(p;γ,δ)=Ip−1(γ,δ)Q_{\\text{Beta}}(p; \\gamma, \\delta) = I_p^{-1}(\\gamma, \\delta) Moments: 𝔼(Xr)=B(γ+r,δ)B(γ,δ)=Γ(γ+r)Γ(δ)Γ(γ+δ)Γ(γ)Γ(γ+δ+r)Γ(δ)\\mathbb{E}(X^r) = \\frac{B(\\gamma+r, \\delta)}{B(\\gamma, \\delta)} = \\frac{\\Gamma(\\gamma+r) \\, \\Gamma(\\delta) \\, \\Gamma(\\gamma+\\delta)}{\\Gamma(\\gamma) \\, \\Gamma(\\gamma+\\delta+r) \\, \\Gamma(\\delta)} 𝔼(X)=γγ+δ\\mathbb{E}(X) = \\frac{\\gamma}{\\gamma+\\delta} Var(X)=γδ(γ+δ)2(γ+δ+1)\\text{Var}(X) = \\frac{\\gamma\\delta}{(\\gamma+\\delta)^2(\\gamma+\\delta+1)}","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"hierarchical-structure","dir":"","previous_headings":"","what":"Hierarchical Structure","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Note: Beta distribution obtained MC setting λ=1\\lambda = 1, GKw setting α=β=λ=1\\alpha = \\beta = \\lambda = 1. Kumaraswamy distribution obtained EKw setting λ=1\\lambda = 1, GKw setting γ=δ=λ=1\\gamma = \\delta = \\lambda = 1.","code":"GKw(α, β, γ, δ, λ)                               /               \\                            λ = 1             γ = 1                             /                    \\                    BKw(α, β, γ, δ)         KKw(α, β, δ, λ)                          |                          |                      α = β = 1                    δ = 1                          |                          |                     MC(γ, δ, λ)              EKw(α, β, λ)                          |                          |                       λ = 1                    γ = δ = 1                          |                          |                     Beta(γ, δ)                   Kw(α, β)"},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-1-basic-distribution-functions","dir":"","previous_headings":"Usage Examples","what":"Example 1: Basic Distribution Functions","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  # Set parameters alpha <- 2; beta <- 3; gamma <- 1.5; delta <- 2; lambda <- 1.2 x <- seq(0.01, 0.99, length.out = 100)  # Density dens <- dgkw(x, alpha, beta, gamma, delta, lambda)  # CDF cdf <- pgkw(x, alpha, beta, gamma, delta, lambda)  # Quantiles q <- qgkw(c(0.25, 0.5, 0.75), alpha, beta, gamma, delta, lambda) print(q)  # Random generation set.seed(123) random_sample <- rgkw(1000, alpha, beta, gamma, delta, lambda)  # Visualization par(mfrow = c(1, 2)) plot(x, dens, type = \"l\", lwd = 2, col = \"blue\",      main = \"GKw PDF\", xlab = \"x\", ylab = \"Density\") grid()  plot(x, cdf, type = \"l\", lwd = 2, col = \"red\",      main = \"GKw CDF\", xlab = \"x\", ylab = \"F(x)\") grid()"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-2-comparing-distribution-families","dir":"","previous_headings":"Usage Examples","what":"Example 2: Comparing Distribution Families","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  par(mfrow = c(1,1), mar = c(3,3,2,2))  x <- seq(0.001, 0.999, length.out = 500)  # Compute densities for all families d_gkw  <- dgkw(x, 2, 3, 1.5, 2, 1.2) d_bkw  <- dbkw(x, 2, 3, 1.5, 2) d_kkw  <- dkkw(x, 2, 3, 2, 1.2) d_ekw  <- dekw(x, 2, 3, 1.5) d_mc   <- dmc(x, 2, 3, 1.2) d_kw   <- dkw(x, 2, 5) d_beta <- dbeta_(x, 2, 3)  # Plot comparison plot(x, d_gkw, type = \"l\", lwd = 2, col = \"black\",      ylim = c(0, max(d_gkw, d_bkw, d_kkw, d_ekw, d_mc, d_kw, d_beta)),      main = \"Distribution Family Comparison\",      xlab = \"x\", ylab = \"Density\") lines(x, d_bkw, lwd = 2, col = \"red\") lines(x, d_kkw, lwd = 2, col = \"blue\") lines(x, d_ekw, lwd = 2, col = \"green\") lines(x, d_mc,  lwd = 2, col = \"purple\") lines(x, d_kw,  lwd = 2, col = \"orange\") lines(x, d_beta, lwd = 2, col = \"brown\") legend(\"topright\",        legend = c(\"GKw\", \"BKw\", \"KKw\", \"EKw\", \"MC\", \"Kw\", \"Beta\"),        col = c(\"black\", \"red\", \"blue\", \"green\", \"purple\", \"orange\", \"brown\"),        lwd = 2, cex = 0.85) grid()"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-3-maximum-likelihood-estimation-using-optim","dir":"","previous_headings":"Usage Examples","what":"Example 3: Maximum Likelihood Estimation Using optim()","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  # Generate synthetic data from Kumaraswamy distribution set.seed(2024)  n <- 2000 true_alpha <- 2.5 true_beta  <- 3.5 data <- rkw(n, true_alpha, true_beta)  # Get starting values par_ini <- gkwgetstartvalues(data, family = \"kw\", n_starts = 2)  # Optimization using BFGS with analytical gradient fit <- optim(   par = par_ini,   fn = llkw,  # Negative log-likelihood function   gr = grkw,  # Negative gradient (negative score function)   data = data,   method = \"BFGS\",   hessian = TRUE )  # Standard errors from observed information matrix se <- sqrt(diag(solve(fit$hessian)))  # 95% Confidence intervals ci <- cbind(   Lower    = fit$par - 1.96 * se,   Estimate = fit$par,   Upper    = fit$par + 1.96 * se ) rownames(ci) <- c(\"alpha\", \"beta\")  cat(\"True parameters:    \", true_alpha, true_beta, \"\\n\") cat(\"Estimated parameters:\", fit$par, \"\\n\\n\") print(ci)"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-4-goodness-of-fit-diagnostic-plot","dir":"","previous_headings":"Usage Examples","what":"Example 4: Goodness-of-Fit Diagnostic Plot","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  # Using fitted model from Example 3 x_grid <- seq(0.001, 0.999, length.out = 200)  # Fitted density fitted_dens <- dkw(x_grid, fit$par[1], fit$par[2])  # True density (for comparison) true_dens <- dkw(x_grid, true_alpha, true_beta)  # Diagnostic plot hist(data, breaks = 30, probability = TRUE,      col = \"lightgray\", border = \"white\",      main = \"Kumaraswamy Distribution Fit\",      xlab = \"Data\", ylab = \"Density\") lines(x_grid, fitted_dens, col = \"red\", lwd = 2, lty = 1) lines(x_grid, true_dens, col = \"blue\", lwd = 2, lty = 2) legend(\"topright\",        legend = c(\"Observed Data\", \"Fitted Model\", \"True Model\"),        col = c(\"gray\", \"red\", \"blue\"),        lwd = c(10, 2, 2), lty = c(1, 1, 2)) grid()"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-5-model-selection-using-aic-and-bic","dir":"","previous_headings":"Usage Examples","what":"Example 5: Model Selection Using AIC and BIC","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  # Generate data from Exponentiated Kumaraswamy set.seed(456) n <- 1500 data <- rekw(n, alpha = 2, beta = 3, lambda = 1.5)  # Define competing models models <- list(   Beta = list(     nll = function(par) llbeta(par, data),     gr = function(par) grbeta(par, data),     start = gkwgetstartvalues(data, family = \"beta\"),     npar = 2   ),   Kw = list(     nll = function(par) llkw(par, data),     gr = function(par) grkw(par, data),     start = gkwgetstartvalues(data, family = \"kw\"),     npar = 2   ),   EKw = list(     nll = function(par) llekw(par, data),     gr = function(par) grekw(par, data),     start = gkwgetstartvalues(data, family = \"ekw\"),     npar = 3   ),   MC = list(     nll = function(par) llmc(par, data),     gr = function(par) grmc(par, data),     start = gkwgetstartvalues(data, family = \"mc\"),     npar = 3   ) )  # Fit all models using optim with analytical gradients fits <- lapply(models, function(m) {   optim(par = m$start, fn = m$nll, gr = m$gr, method = \"BFGS\") })  # Extract log-likelihoods and compute information criteria loglik <- sapply(fits, function(f) -f$value) k <- sapply(models, `[[`, \"npar\")  results <- data.frame(   Model  = names(models),   Coefs  = sapply(fits, function(f) paste0(round(f$par, 3), collapse = \"|\")),   LogLik = round(loglik, 2),   nPar   = k,   AIC    = round(-2 * loglik + 2 * k, 2),   BIC    = round(-2 * loglik + k * log(n), 2) )  # Sort by AIC results <- results[order(results$AIC), ] print(results, row.names = FALSE) cat(\"\\nBest model by AIC:\", results$Model[1], \"\\n\")"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-6-using-analytical-functions-directly","dir":"","previous_headings":"Usage Examples","what":"Example 6: Using Analytical Functions Directly","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  # Generate data from EKw set.seed(789) n <- 1000 data <- rekw(n, alpha = 2, beta = 3, lambda = 1.5) params <- c(2, 3, 1.5)  # Compute analytical functions at true parameters nll <- llekw(params, data) neg_score <- grekw(params, data) neg_hess <- hsekw(params, data)  # Fisher information matrix (negative of negative Hessian = Hessian) fisher <- -neg_hess  # Asymptotic standard errors se <- sqrt(diag(solve(fisher))) names(se) <- c(\"alpha\", \"beta\", \"lambda\")  cat(\"Negative log-likelihood:\", nll, \"\\n\") cat(\"\\nNegative score vector (should be close to zero at true params):\\n\") print(neg_score) cat(\"\\nNegative Hessian matrix:\\n\") print(neg_hess) cat(\"\\nFisher Information matrix:\\n\") print(fisher) cat(\"\\nAsymptotic standard errors:\\n\") print(se)"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-7-q-q-plot-for-model-validation","dir":"","previous_headings":"Usage Examples","what":"Example 7: Q-Q Plot for Model Validation","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  # Generate data and fit model set.seed(101) n <- 2000 data <- rkw(n, alpha = 2, beta = 3)  # Fit using optim fit <- optim(   par = c(1, 1),   fn = function(par) llkw(par, data),   gr = function(par) grkw(par, data),   method = \"BFGS\" )  # Theoretical quantiles p <- ppoints(n) theoretical_q <- qkw(p, fit$par[1], fit$par[2])  # Empirical quantiles empirical_q <- sort(data)  # Q-Q plot plot(theoretical_q, empirical_q,      xlab = \"Theoretical Quantiles\",      ylab = \"Empirical Quantiles\",      main = \"Q-Q Plot: Kumaraswamy Distribution\",      pch = 19, col = rgb(0, 0, 1, 0.5)) abline(0, 1, col = \"red\", lwd = 2, lty = 2) grid()"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-8-fitting-gkw-full-model-using-optim","dir":"","previous_headings":"Usage Examples","what":"Example 8: Fitting GKw (Full Model) Using optim()","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  # Generate data from GKw set.seed(2025) n <- 10000 true_params <- c(alpha = 2, beta = 2.5, gamma = 1.5, delta = 2, lambda = 1.3) data <- rgkw(n, true_params[1], true_params[2], true_params[3],              true_params[4], true_params[5])  # Get starting values par_ini <- gkwgetstartvalues(data, family = \"gkw\", n_starts = 5)  # Fit using optim with analytical gradient fit_gkw <- optim(   par = par_ini,    fn = llgkw,    # Negative log-likelihood   gr = grgkw,    # Negative gradient   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(maxit = 1000) )  # Results se <- sqrt(diag(solve(fit_gkw$hessian))) estimates <- data.frame(   Parameter = names(true_params),   True = true_params,   Estimate = fit_gkw$par,   SE = se ) print(estimates, digits = 4)"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"example-9-comparing-analytical-vs-numerical-derivatives","dir":"","previous_headings":"Usage Examples","what":"Example 9: Comparing Analytical vs Numerical Derivatives","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"library(gkwdist)  # Generate data set.seed(999) n <- 10000 data <- rkw(n, alpha = 2, beta = 3) par <- c(2, 3)  # Negative analytical gradient neg_grad_analytical <- grkw(par, data)  # Numerical gradient (using finite differences) neg_grad_numerical <- numDeriv::grad(   func = function(p) llkw(p, data),   x = par )  # Compare comparison <- data.frame(   Parameter = c(\"alpha\", \"beta\"),   Analytical = neg_grad_analytical,   Numerical = neg_grad_numerical,   Difference = abs(neg_grad_analytical - neg_grad_numerical) ) print(comparison, digits = 8)"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"performance-comparison","dir":"","previous_headings":"","what":"Performance Comparison","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"C++ implementation provides substantial performance gains: C++ Implementation Matters: Speed: Critical maximum likelihood estimation large datasets Numerical Stability: Better handling extreme parameter values edge cases Memory Efficiency: Optimized memory allocation tight loops Scalability: Linear scaling sample size Precision: Analytical derivatives exact (floating-point precision)","code":"library(microbenchmark)  # Generate large dataset n <- 10000 data <- rkw(n, 2, 3)  # Compare log-likelihood computation benchmark <- microbenchmark(   R_sum_log_d = -sum(log(dkw(data, 2, 3))),  # Manual negative log-likelihood   Cpp_ll = llkw(c(2, 3), data),               # C++ negative log-likelihood   times = 100 )  print(benchmark) plot(benchmark) # Typical results: C++ implementation is 10-50× faster"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"when-to-use-each-distribution","dir":"","previous_headings":"","what":"When to Use Each Distribution","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Model Selection Workflow: Start Beta Kumaraswamy (2 parameters) Check goodness--fit using Q-Q plots formal tests inadequate, try EKw MC (3 parameters) complex patterns, use BKw, KKw, GKw (4-5 parameters) Use AIC/BIC balance fit quality parsimony Validate final model residual diagnostics","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, 81(7), 883-898. doi:10.1080/00949650903530745 Carrasco, J. M. F., Ferrari, S. L. P., & Cordeiro, G. M. (2010). new generalized Kumaraswamy distribution. arXiv:1004.0911. arxiv.org/abs/1004.0911 Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. doi:10.1016/0022-1694(80)90036-0 Jones, M. C. (2009). Kumaraswamy’s distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81. doi:10.1016/j.stamet.2008.04.001 Lemonte, . J., & Cordeiro, G. M. (2013). extended Lomax distribution. Statistics, 47(4), 800-816. doi:10.1080/02331888.2011.568119 Cordeiro, G. M., & Lemonte, . J. (2011). β-Birnbaum–Saunders distribution: improved distribution fatigue life modeling. Computational Statistics & Data Analysis, 55(3), 1445-1461. doi:10.1016/j.csda.2010.10.007 McDonald, J. B. (1984). generalized functions size distribution income. Econometrica, 52(3), 647-663. doi:10.2307/1913469 Cordeiro, G. M., & Brito, R. S. (2012). beta power distribution. Brazilian Journal Probability Statistics, 26(1), 88-112. doi:10.1214/10-BJPS124","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"","code":"citation(\"gkwdist\") @Manual{gkwdist2025,   title  = {gkwdist: Generalized Kumaraswamy Distribution Family},   author = {J. E. Lopes},   year   = {2025},   note   = {R package},   url    = {https://github.com/evandeilton/gkwdist} }"},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"author","dir":"","previous_headings":"","what":"Author","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"J. E. Lopes LEG - Laboratory Statistics Geoinformation PPGMNE - Graduate Program Numerical Methods Engineering Federal University Paraná (UFPR), Brazil Email: evandeilton@gmail.com","code":""},{"path":"https://evandeilton.github.io/gkwdist/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"gkwdist: Generalized Kumaraswamy Distribution Family","text":"MIT License. See LICENSE file details.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbeta_.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","title":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","text":"Computes probability density function (PDF) standard Beta distribution, using parameterization common generalized distribution families. distribution parameterized gamma (\\(\\gamma\\)) delta (\\(\\delta\\)), corresponding standard Beta distribution shape parameters shape1 = gamma shape2 = delta + 1. distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbeta_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","text":"","code":"dbeta_(x, gamma, delta, log_prob = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/dbeta_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","text":"x Vector quantiles (values 0 1). gamma First shape parameter (shape1), \\(\\gamma > 0\\). Can scalar vector. Default: 1.0. delta Second shape parameter delta + 1 (shape2), requires \\(\\delta \\ge 0\\) shape2 >= 1. Can scalar vector. Default: 0.0 (leading shape2 = 1). log_prob Logical; TRUE, logarithm density returned (\\(\\log(f(x))\\)). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbeta_.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","text":"vector density values (\\(f(x)\\)) log-density values (\\(\\log(f(x))\\)). length result determined recycling rule applied arguments (x, gamma, delta). Returns 0 (-Inf log_prob = TRUE) x outside interval (0, 1), NaN parameters invalid (e.g., gamma <= 0, delta < 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbeta_.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","text":"probability density function (PDF) calculated function corresponds standard Beta distribution \\(Beta(\\gamma, \\delta+1)\\): $$ f(x; \\gamma, \\delta) = \\frac{x^{\\gamma-1} (1-x)^{(\\delta+1)-1}}{B(\\gamma, \\delta+1)} = \\frac{x^{\\gamma-1} (1-x)^{\\delta}}{B(\\gamma, \\delta+1)} $$ \\(0 < x < 1\\), \\(B(,b)\\) Beta function (beta). specific parameterization arises special case five-parameter Generalized Kumaraswamy (GKw) distribution (dgkw) obtained setting parameters \\(\\alpha = 1\\), \\(\\beta = 1\\), \\(\\lambda = 1\\). therefore equivalent McDonald (Mc)/Beta Power distribution (dmc) \\(\\lambda = 1\\). Note difference second parameter compared dbeta, dbeta(x, shape1, shape2) uses shape2 directly. , shape1 = gamma shape2 = delta + 1.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbeta_.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","text":"Johnson, N. L., Kotz, S., & Balakrishnan, N. (1995). Continuous Univariate Distributions, Volume 2 (2nd ed.). Wiley. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation,","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/dbeta_.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbeta_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of the Beta Distribution (gamma, delta+1 Parameterization) — dbeta_","text":"","code":"# \\donttest{ # Example values x_vals <- c(0.2, 0.5, 0.8) gamma_par <- 2.0 # Corresponds to shape1 delta_par <- 3.0 # Corresponds to shape2 - 1 shape1 <- gamma_par shape2 <- delta_par + 1  # Calculate density using dbeta_ densities <- dbeta_(x_vals, gamma_par, delta_par) print(densities) #> [1] 2.048 1.250 0.128  # Compare with stats::dbeta densities_stats <- stats::dbeta(x_vals, shape1 = shape1, shape2 = shape2) print(paste(\"Max difference vs stats::dbeta:\", max(abs(densities - densities_stats)))) #> [1] \"Max difference vs stats::dbeta: 0\"  # Compare with dgkw setting alpha=1, beta=1, lambda=1 densities_gkw <- dgkw(x_vals, alpha = 1.0, beta = 1.0, gamma = gamma_par,                       delta = delta_par, lambda = 1.0) print(paste(\"Max difference vs dgkw:\", max(abs(densities - densities_gkw)))) #> [1] \"Max difference vs dgkw: 0\"  # Compare with dmc setting lambda=1 densities_mc <- dmc(x_vals, gamma = gamma_par, delta = delta_par, lambda = 1.0) print(paste(\"Max difference vs dmc:\", max(abs(densities - densities_mc)))) #> [1] \"Max difference vs dmc: 4.44089209850063e-16\"  # Calculate log-density log_densities <- dbeta_(x_vals, gamma_par, delta_par, log_prob = TRUE) print(log_densities) #> [1]  0.7168637  0.2231436 -2.0557250 print(stats::dbeta(x_vals, shape1 = shape1, shape2 = shape2, log = TRUE)) #> [1]  0.7168637  0.2231436 -2.0557250  # Plot the density curve_x <- seq(0.001, 0.999, length.out = 200) curve_y <- dbeta_(curve_x, gamma = 2, delta = 3) # Beta(2, 4) plot(curve_x, curve_y, type = \"l\", main = \"Beta(2, 4) Density via dbeta_\",      xlab = \"x\", ylab = \"f(x)\", col = \"blue\") curve(stats::dbeta(x, 2, 4), add=TRUE, col=\"red\", lty=2) legend(\"topright\", legend=c(\"dbeta_(gamma=2, delta=3)\", \"stats::dbeta(shape1=2, shape2=4)\"),        col=c(\"blue\", \"red\"), lty=c(1,2), bty=\"n\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/dbkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","title":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","text":"Computes probability density function (PDF) Beta-Kumaraswamy (BKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)). distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","text":"","code":"dbkw(x, alpha, beta, gamma, delta, log_prob = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/dbkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","text":"x Vector quantiles (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. log_prob Logical; TRUE, logarithm density returned (\\(\\log(f(x))\\)). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","text":"vector density values (\\(f(x)\\)) log-density values (\\(\\log(f(x))\\)). length result determined recycling rule applied arguments (x, alpha, beta, gamma, delta). Returns 0 (-Inf log_prob = TRUE) x outside interval (0, 1), NaN parameters invalid (e.g., alpha <= 0, beta <= 0, gamma <= 0, delta < 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","text":"probability density function (PDF) Beta-Kumaraswamy (BKw) distribution given : $$ f(x; \\alpha, \\beta, \\gamma, \\delta) = \\frac{\\alpha \\beta}{B(\\gamma, \\delta+1)} x^{\\alpha - 1} \\bigl(1 - x^\\alpha\\bigr)^{\\beta(\\delta+1) - 1} \\bigl[1 - \\bigl(1 - x^\\alpha\\bigr)^\\beta\\bigr]^{\\gamma - 1} $$ \\(0 < x < 1\\), \\(B(,b)\\) Beta function (beta). BKw distribution special case five-parameter Generalized Kumaraswamy (GKw) distribution (dgkw) obtained setting parameter \\(\\lambda = 1\\). Numerical evaluation performed using algorithms similar dgkw, ensuring stability.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/dbkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dbkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of the Beta-Kumaraswamy (BKw) Distribution — dbkw","text":"","code":"# \\donttest{ # Example values x_vals <- c(0.2, 0.5, 0.8) alpha_par <- 2.0 beta_par <- 1.5 gamma_par <- 1.0 # Equivalent to Kw when gamma=1 delta_par <- 0.5  # Calculate density densities <- dbkw(x_vals, alpha_par, beta_par, gamma_par, delta_par) print(densities) #> [1] 0.8552273 1.5703957 1.0038773  # Calculate log-density log_densities <- dbkw(x_vals, alpha_par, beta_par, gamma_par, delta_par,                       log_prob = TRUE) print(log_densities) #> [1] -0.156388009  0.451327626  0.003869786 # Check: should match log(densities) print(log(densities)) #> [1] -0.156388009  0.451327626  0.003869786  # Compare with dgkw setting lambda = 1 densities_gkw <- dgkw(x_vals, alpha_par, beta_par, gamma = gamma_par,                       delta = delta_par, lambda = 1.0) print(paste(\"Max difference:\", max(abs(densities - densities_gkw)))) # Should be near zero #> [1] \"Max difference: 2.22044604925031e-16\"  # Plot the density for different gamma values curve_x <- seq(0.01, 0.99, length.out = 200) curve_y1 <- dbkw(curve_x, alpha = 2, beta = 3, gamma = 0.5, delta = 1) curve_y2 <- dbkw(curve_x, alpha = 2, beta = 3, gamma = 1.0, delta = 1) curve_y3 <- dbkw(curve_x, alpha = 2, beta = 3, gamma = 2.0, delta = 1)  plot(curve_x, curve_y1, type = \"l\", main = \"BKw Density Examples (alpha=2, beta=3, delta=1)\",      xlab = \"x\", ylab = \"f(x)\", col = \"blue\", ylim = range(0, curve_y1, curve_y2, curve_y3)) lines(curve_x, curve_y2, col = \"red\") lines(curve_x, curve_y3, col = \"green\") legend(\"topright\", legend = c(\"gamma=0.5\", \"gamma=1.0\", \"gamma=2.0\"),        col = c(\"blue\", \"red\", \"green\"), lty = 1, bty = \"n\")  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/dekw.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","title":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","text":"Computes probability density function (PDF) Exponentiated Kumaraswamy (EKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), lambda (\\(\\lambda\\)). distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dekw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","text":"","code":"dekw(x, alpha, beta, lambda, log_prob = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/dekw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","text":"x Vector quantiles (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. lambda Shape parameter lambda > 0 (exponent parameter). Can scalar vector. Default: 1.0. log_prob Logical; TRUE, logarithm density returned (\\(\\log(f(x))\\)). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dekw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","text":"vector density values (\\(f(x)\\)) log-density values (\\(\\log(f(x))\\)). length result determined recycling rule applied arguments (x, alpha, beta, lambda). Returns 0 (-Inf log_prob = TRUE) x outside interval (0, 1), NaN parameters invalid (e.g., alpha <= 0, beta <= 0, lambda <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dekw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","text":"probability density function (PDF) Exponentiated Kumaraswamy (EKw) distribution given : $$ f(x; \\alpha, \\beta, \\lambda) = \\lambda \\alpha \\beta x^{\\alpha-1} (1 - x^\\alpha)^{\\beta-1} \\bigl[1 - (1 - x^\\alpha)^\\beta \\bigr]^{\\lambda - 1} $$ \\(0 < x < 1\\). EKw distribution special case five-parameter Generalized Kumaraswamy (GKw) distribution (dgkw) obtained setting parameters \\(\\gamma = 1\\) \\(\\delta = 0\\). \\(\\lambda = 1\\), EKw distribution reduces standard Kumaraswamy distribution.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dekw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","text":"Nadarajah, S., Cordeiro, G. M., & Ortega, E. M. (2012). exponentiated Kumaraswamy distribution. Journal Franklin Institute, 349(3), Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/dekw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dekw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of the Exponentiated Kumaraswamy (EKw) Distribution — dekw","text":"","code":"# \\donttest{ # Example values x_vals <- c(0.2, 0.5, 0.8) alpha_par <- 2.0 beta_par <- 3.0 lambda_par <- 1.5 # Exponent parameter  # Calculate density densities <- dekw(x_vals, alpha_par, beta_par, lambda_par) print(densities) #> [1] 0.5631989 1.9246241 0.9110922  # Calculate log-density log_densities <- dekw(x_vals, alpha_par, beta_par, lambda_par, log_prob = TRUE) print(log_densities) #> [1] -0.57412239  0.65473067 -0.09311121 # Check: should match log(densities) print(log(densities)) #> [1] -0.57412239  0.65473067 -0.09311121  # Compare with dgkw setting gamma = 1, delta = 0 densities_gkw <- dgkw(x_vals, alpha_par, beta_par, gamma = 1.0, delta = 0.0,                       lambda = lambda_par) print(paste(\"Max difference:\", max(abs(densities - densities_gkw)))) # Should be near zero #> [1] \"Max difference: 0\"  # Plot the density for different lambda values curve_x <- seq(0.01, 0.99, length.out = 200) curve_y1 <- dekw(curve_x, alpha = 2, beta = 3, lambda = 0.5) # less peaked curve_y2 <- dekw(curve_x, alpha = 2, beta = 3, lambda = 1.0) # standard Kw curve_y3 <- dekw(curve_x, alpha = 2, beta = 3, lambda = 2.0) # more peaked  plot(curve_x, curve_y2, type = \"l\", main = \"EKw Density Examples (alpha=2, beta=3)\",      xlab = \"x\", ylab = \"f(x)\", col = \"red\", ylim = range(0, curve_y1, curve_y2, curve_y3)) lines(curve_x, curve_y1, col = \"blue\") lines(curve_x, curve_y3, col = \"green\") legend(\"topright\", legend = c(\"lambda=0.5\", \"lambda=1.0 (Kw)\", \"lambda=2.0\"),        col = c(\"blue\", \"red\", \"green\"), lty = 1, bty = \"n\")  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/dgkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of the Generalized Kumaraswamy Distribution — dgkw","title":"Density of the Generalized Kumaraswamy Distribution — dgkw","text":"Computes probability density function (PDF) five-parameter Generalized Kumaraswamy (GKw) distribution, defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dgkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of the Generalized Kumaraswamy Distribution — dgkw","text":"","code":"dgkw(x, alpha, beta, gamma, delta, lambda, log_prob = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/dgkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of the Generalized Kumaraswamy Distribution — dgkw","text":"x Vector quantiles (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. log_prob Logical; TRUE, logarithm density returned. Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dgkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of the Generalized Kumaraswamy Distribution — dgkw","text":"vector density values (\\(f(x)\\)) log-density values (\\(\\log(f(x))\\)). length result determined recycling rule applied arguments (x, alpha, beta, gamma, delta, lambda). Returns 0 (-Inf log_prob = TRUE) x outside interval (0, 1), NaN parameters invalid.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dgkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density of the Generalized Kumaraswamy Distribution — dgkw","text":"probability density function Generalized Kumaraswamy (GKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)) given : $$ f(x; \\alpha, \\beta, \\gamma, \\delta, \\lambda) =   \\frac{\\lambda \\alpha \\beta x^{\\alpha-1}(1-x^{\\alpha})^{\\beta-1}}        {B(\\gamma, \\delta+1)}   [1-(1-x^{\\alpha})^{\\beta}]^{\\gamma\\lambda-1}   [1-[1-(1-x^{\\alpha})^{\\beta}]^{\\lambda}]^{\\delta} $$ \\(x \\(0,1)\\), \\(B(, b)\\) Beta function beta. distribution proposed Cordeiro & de Castro (2011) includes several distributions special cases: Kumaraswamy (Kw): gamma = 1, delta = 0, lambda = 1 Exponentiated Kumaraswamy (EKw): gamma = 1, delta = 0 Beta-Kumaraswamy (BKw): lambda = 1 Generalized Beta type 1 (GB1 - implies McDonald): alpha = 1, beta = 1 Beta distribution: alpha = 1, beta = 1, lambda = 1 function includes checks valid parameters input values x. uses numerical stabilization x close 0 1.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dgkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density of the Generalized Kumaraswamy Distribution — dgkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, 81(7), 883-898. Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/dgkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density of the Generalized Kumaraswamy Distribution — dgkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dgkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of the Generalized Kumaraswamy Distribution — dgkw","text":"","code":"# \\donttest{ # Simple density evaluation at a point dgkw(0.5, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) # Kw case #> [1] 1.6875  # Plot the PDF for various parameter sets x_vals <- seq(0.01, 0.99, by = 0.01)  # Standard Kumaraswamy (gamma=1, delta=0, lambda=1) pdf_kw <- dgkw(x_vals, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1)  # Beta equivalent (alpha=1, beta=1, lambda=1) - Beta(gamma, delta+1) pdf_beta <- dgkw(x_vals, alpha = 1, beta = 1, gamma = 2, delta = 3, lambda = 1) # Compare with stats::dbeta pdf_beta_check <- stats::dbeta(x_vals, shape1 = 2, shape2 = 3 + 1) # max(abs(pdf_beta - pdf_beta_check)) # Should be close to zero  # Exponentiated Kumaraswamy (gamma=1, delta=0) pdf_ekw <- dgkw(x_vals, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 2)  plot(x_vals, pdf_kw, type = \"l\", ylim = range(c(pdf_kw, pdf_beta, pdf_ekw)),      main = \"GKw Densities Examples\", ylab = \"f(x)\", xlab=\"x\", col = \"blue\") lines(x_vals, pdf_beta, col = \"red\") lines(x_vals, pdf_ekw, col = \"green\") legend(\"topright\", legend = c(\"Kw(2,3)\", \"Beta(2,4) equivalent\", \"EKw(2,3, lambda=2)\"),        col = c(\"blue\", \"red\", \"green\"), lty = 1, bty = \"n\")   # Log-density log_pdf_val <- dgkw(0.5, 2, 3, 1, 0, 1, log_prob = TRUE) print(log_pdf_val) #> [1] 0.5232481 print(log(dgkw(0.5, 2, 3, 1, 0, 1))) # Should match #> [1] 0.5232481  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/dkkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","title":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","text":"Computes probability density function (PDF) Kumaraswamy-Kumaraswamy (kkw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","text":"","code":"dkkw(x, alpha, beta, delta, lambda, log_prob = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/dkkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","text":"x Vector quantiles (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. log_prob Logical; TRUE, logarithm density returned (\\(\\log(f(x))\\)). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","text":"vector density values (\\(f(x)\\)) log-density values (\\(\\log(f(x))\\)). length result determined recycling rule applied arguments (x, alpha, beta, delta, lambda). Returns 0 (-Inf log_prob = TRUE) x outside interval (0, 1), NaN parameters invalid (e.g., alpha <= 0, beta <= 0, delta < 0, lambda <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","text":"Kumaraswamy-Kumaraswamy (kkw) distribution special case five-parameter Generalized Kumaraswamy distribution (dgkw) obtained setting parameter \\(\\gamma = 1\\). probability density function given : $$ f(x; \\alpha, \\beta, \\delta, \\lambda) = (\\delta + 1) \\lambda \\alpha \\beta x^{\\alpha - 1} (1 - x^\\alpha)^{\\beta - 1} \\bigl[1 - (1 - x^\\alpha)^\\beta\\bigr]^{\\lambda - 1} \\bigl\\{1 - \\bigl[1 - (1 - x^\\alpha)^\\beta\\bigr]^\\lambda\\bigr\\}^{\\delta} $$ \\(0 < x < 1\\). Note \\(1/(\\delta+1)\\) corresponds Beta function term \\(B(1, \\delta+1)\\) \\(\\gamma=1\\). Numerical evaluation follows similar stability considerations dgkw.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/dkkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of the Kumaraswamy-Kumaraswamy (kkw) Distribution — dkkw","text":"","code":"# \\donttest{ # Example values x_vals <- c(0.2, 0.5, 0.8) alpha_par <- 2.0 beta_par <- 3.0 delta_par <- 0.5 lambda_par <- 1.5  # Calculate density densities <- dkkw(x_vals, alpha_par, beta_par, delta_par, lambda_par) print(densities) #> [1] 0.8281038 2.1612055 0.3594057  # Calculate log-density log_densities <- dkkw(x_vals, alpha_par, beta_par, delta_par, lambda_par,                        log_prob = TRUE) print(log_densities) #> [1] -0.1886168  0.7706662 -1.0233034 # Check: should match log(densities) print(log(densities)) #> [1] -0.1886168  0.7706662 -1.0233034  # Compare with dgkw setting gamma = 1 densities_gkw <- dgkw(x_vals, alpha_par, beta_par, gamma = 1.0,                       delta_par, lambda_par) print(paste(\"Max difference:\", max(abs(densities - densities_gkw)))) # Should be near zero #> [1] \"Max difference: 0\"  # Plot the density curve_x <- seq(0.01, 0.99, length.out = 200) curve_y <- dkkw(curve_x, alpha_par, beta_par, delta_par, lambda_par) plot(curve_x, curve_y, type = \"l\", main = \"kkw Density Example\",      xlab = \"x\", ylab = \"f(x)\", col = \"blue\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/dkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of the Kumaraswamy (Kw) Distribution — dkw","title":"Density of the Kumaraswamy (Kw) Distribution — dkw","text":"Computes probability density function (PDF) two-parameter Kumaraswamy (Kw) distribution shape parameters alpha (\\(\\alpha\\)) beta (\\(\\beta\\)). distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of the Kumaraswamy (Kw) Distribution — dkw","text":"","code":"dkw(x, alpha, beta, log_prob = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/dkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of the Kumaraswamy (Kw) Distribution — dkw","text":"x Vector quantiles (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. log_prob Logical; TRUE, logarithm density returned (\\(\\log(f(x))\\)). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of the Kumaraswamy (Kw) Distribution — dkw","text":"vector density values (\\(f(x)\\)) log-density values (\\(\\log(f(x))\\)). length result determined recycling rule applied arguments (x, alpha, beta). Returns 0 (-Inf log_prob = TRUE) x outside interval (0, 1), NaN parameters invalid (e.g., alpha <= 0, beta <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density of the Kumaraswamy (Kw) Distribution — dkw","text":"probability density function (PDF) Kumaraswamy (Kw) distribution given : $$ f(x; \\alpha, \\beta) = \\alpha \\beta x^{\\alpha-1} (1 - x^\\alpha)^{\\beta-1} $$ \\(0 < x < 1\\), \\(\\alpha > 0\\), \\(\\beta > 0\\). Kumaraswamy distribution identical Generalized Kumaraswamy (GKw) distribution (dgkw) parameters \\(\\gamma = 1\\), \\(\\delta = 0\\), \\(\\lambda = 1\\). also special case Exponentiated Kumaraswamy (dekw) \\(\\lambda = 1\\), Kumaraswamy-Kumaraswamy (dkkw) \\(\\delta = 0\\) \\(\\lambda = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density of the Kumaraswamy (Kw) Distribution — dkw","text":"Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/dkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density of the Kumaraswamy (Kw) Distribution — dkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of the Kumaraswamy (Kw) Distribution — dkw","text":"","code":"# \\donttest{ # Example values x_vals <- c(0.2, 0.5, 0.8) alpha_par <- 2.0 beta_par <- 3.0  # Calculate density using dkw densities <- dkw(x_vals, alpha_par, beta_par) print(densities) #> [1] 1.10592 1.68750 0.62208  # Calculate log-density log_densities <- dkw(x_vals, alpha_par, beta_par, log_prob = TRUE) print(log_densities) #> [1]  0.1006776  0.5232481 -0.4746866 # Check: should match log(densities) print(log(densities)) #> [1]  0.1006776  0.5232481 -0.4746866  # Compare with dgkw setting gamma = 1, delta = 0, lambda = 1 densities_gkw <- dgkw(x_vals, alpha_par, beta_par, gamma = 1.0, delta = 0.0,                       lambda = 1.0) print(paste(\"Max difference:\", max(abs(densities - densities_gkw)))) # Should be near zero #> [1] \"Max difference: 0\"  # Plot the density for different shape parameter combinations curve_x <- seq(0.001, 0.999, length.out = 200) plot(curve_x, dkw(curve_x, alpha = 2, beta = 3), type = \"l\",      main = \"Kumaraswamy Density Examples\", xlab = \"x\", ylab = \"f(x)\",      col = \"blue\", ylim = c(0, 4)) lines(curve_x, dkw(curve_x, alpha = 3, beta = 2), col = \"red\") lines(curve_x, dkw(curve_x, alpha = 0.5, beta = 0.5), col = \"green\") # U-shaped lines(curve_x, dkw(curve_x, alpha = 5, beta = 1), col = \"purple\") # J-shaped lines(curve_x, dkw(curve_x, alpha = 1, beta = 3), col = \"orange\") # J-shaped (reversed) legend(\"top\", legend = c(\"a=2, b=3\", \"a=3, b=2\", \"a=0.5, b=0.5\", \"a=5, b=1\", \"a=1, b=3\"),        col = c(\"blue\", \"red\", \"green\", \"purple\", \"orange\"), lty = 1, bty = \"n\", ncol = 2)  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/dmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","title":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","text":"Computes probability density function (PDF) McDonald (Mc) distribution (also previously referred Beta Power) parameters gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","text":"","code":"dmc(x, gamma, delta, lambda, log_prob = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/dmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","text":"x Vector quantiles (values 0 1). gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. log_prob Logical; TRUE, logarithm density returned (\\(\\log(f(x))\\)). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","text":"vector density values (\\(f(x)\\)) log-density values (\\(\\log(f(x))\\)). length result determined recycling rule applied arguments (x, gamma, delta, lambda). Returns 0 (-Inf log_prob = TRUE) x outside interval (0, 1), NaN parameters invalid (e.g., gamma <= 0, delta < 0, lambda <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","text":"probability density function (PDF) McDonald (Mc) distribution given : $$ f(x; \\gamma, \\delta, \\lambda) = \\frac{\\lambda}{B(\\gamma,\\delta+1)} x^{\\gamma \\lambda - 1} (1 - x^\\lambda)^\\delta $$ \\(0 < x < 1\\), \\(B(,b)\\) Beta function (beta). Mc distribution special case five-parameter Generalized Kumaraswamy (GKw) distribution (dgkw) obtained setting parameters \\(\\alpha = 1\\) \\(\\beta = 1\\). introduced McDonald (1984) related Generalized Beta distribution first kind (GB1). \\(\\lambda=1\\), simplifies standard Beta distribution parameters \\(\\gamma\\) \\(\\delta+1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","text":"McDonald, J. B. (1984). generalized functions size distribution income. Econometrica, 52(3), 647-663. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/dmc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/dmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Density of the McDonald (Mc)/Beta Power Distribution Distribution — dmc","text":"","code":"# \\donttest{ # Example values x_vals <- c(0.2, 0.5, 0.8) gamma_par <- 2.0 delta_par <- 1.5 lambda_par <- 1.0 # Equivalent to Beta(gamma, delta+1)  # Calculate density using dmc densities <- dmc(x_vals, gamma_par, delta_par, lambda_par) print(densities) #> [1] 1.252198 1.546796 0.626099 # Compare with Beta density print(stats::dbeta(x_vals, shape1 = gamma_par, shape2 = delta_par + 1)) #> [1] 1.252198 1.546796 0.626099  # Calculate log-density log_densities <- dmc(x_vals, gamma_par, delta_par, lambda_par, log_prob = TRUE) print(log_densities) #> [1]  0.2249005  0.4361857 -0.4682467  # Compare with dgkw setting alpha = 1, beta = 1 densities_gkw <- dgkw(x_vals, alpha = 1.0, beta = 1.0, gamma = gamma_par,                       delta = delta_par, lambda = lambda_par) print(paste(\"Max difference:\", max(abs(densities - densities_gkw)))) # Should be near zero #> [1] \"Max difference: 0\"  # Plot the density for different lambda values curve_x <- seq(0.01, 0.99, length.out = 200) curve_y1 <- dmc(curve_x, gamma = 2, delta = 3, lambda = 0.5) curve_y2 <- dmc(curve_x, gamma = 2, delta = 3, lambda = 1.0) # Beta(2, 4) curve_y3 <- dmc(curve_x, gamma = 2, delta = 3, lambda = 2.0)  plot(curve_x, curve_y2, type = \"l\", main = \"McDonald (Mc) Density (gamma=2, delta=3)\",      xlab = \"x\", ylab = \"f(x)\", col = \"red\", ylim = range(0, curve_y1, curve_y2, curve_y3)) lines(curve_x, curve_y1, col = \"blue\") lines(curve_x, curve_y3, col = \"green\") legend(\"topright\", legend = c(\"lambda=0.5\", \"lambda=1.0 (Beta)\", \"lambda=2.0\"),        col = c(\"blue\", \"red\", \"green\"), lty = 1, bty = \"n\")  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwdist-package.html","id":null,"dir":"Reference","previous_headings":"","what":"gkwdist: Generalized Kumaraswamy Distribution Family — gkwdist-package","title":"gkwdist: Generalized Kumaraswamy Distribution Family — gkwdist-package","text":"Implements five-parameter Generalized Kumaraswamy (GKw) distribution proposed Carrasco, Ferrari Cordeiro (2010) arXiv:1004.0911 seven nested sub-families modeling bounded continuous data unit interval (0,1). GKw distribution extends Kumaraswamy distribution described Jones (2009) doi:10.1016/j.stamet.2008.04.001 . Provides density, distribution, quantile, random generation functions, along analytical log-likelihood, gradient, Hessian functions implemented 'C++' via 'RcppArmadillo' maximum computational efficiency. Suitable modeling proportions, rates, percentages, indices exhibiting complex features bimodality, asymmetry, heavy tails adequately captured standard distributions like Beta Kumaraswamy.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwdist-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"gkwdist: Generalized Kumaraswamy Distribution Family — gkwdist-package","text":"Maintainer: J. E. Lopes evandeilton@gmail.com (ORCID)","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwgetstartvalues.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate Distribution Parameters Using Method of Moments — gkwgetstartvalues","title":"Estimate Distribution Parameters Using Method of Moments — gkwgetstartvalues","text":"Estimates parameters various distribution families Generalized Kumaraswamy family using method moments. implementation optimized numerical stability computational efficiency Nelder-Mead optimization adaptive numerical integration.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwgetstartvalues.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate Distribution Parameters Using Method of Moments — gkwgetstartvalues","text":"","code":"gkwgetstartvalues(x, family = \"gkw\", n_starts = 5L)"},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwgetstartvalues.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate Distribution Parameters Using Method of Moments — gkwgetstartvalues","text":"x Numeric vector observations. values must open interval (0,1). Values outside range automatically truncated avoid numerical issues. family Character string specifying distribution family. Valid options : \"gkw\" (Generalized Kumaraswamy - 5 parameters), \"bkw\" (Beta-Kumaraswamy - 4 parameters), \"kkw\" (Kumaraswamy-Kumaraswamy - 4 parameters), \"ekw\" (Exponentiated Kumaraswamy - 3 parameters), \"mc\" (McDonald - 3 parameters), \"kw\" (Kumaraswamy - 2 parameters), \"beta\" (Beta - 2 parameters). string case-insensitive. Default \"gkw\". n_starts Integer specifying number different initial parameter values try optimization. starting points increase probability finding global optimum cost longer computation time. Default 5.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwgetstartvalues.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate Distribution Parameters Using Method of Moments — gkwgetstartvalues","text":"Named numeric vector containing estimated parameters specified distribution family. Parameter names correspond distribution specification. estimation fails, returns vector NA values appropriate parameter names.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwgetstartvalues.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate Distribution Parameters Using Method of Moments — gkwgetstartvalues","text":"function uses method moments estimate distribution parameters minimizing weighted sum squared relative errors theoretical sample moments (orders 1 5). optimization employs Nelder-Mead simplex algorithm, derivative-free particularly robust problem. Key implementation features: logarithmic calculations numerical stability, adaptive numerical integration using Simpson's rule fallback trapezoidal rule, multiple random starting points avoid local minima, decreasing weights higher-order moments (1.0, 0.8, 0.6, 0.4, 0.2), automatic parameter constraint enforcement. Parameter Constraints: parameters constrained positive values. Additionally, family-specific constraints enforced: alpha beta (0.1, 50.0), gamma (0.1, 10.0) GKw-related families (0.1, 50.0) Beta, delta (0.01, 10.0), lambda (0.1, 20.0). function issue warnings empty input vectors, sample sizes less 10 (unreliable estimation), failure find valid parameter estimates (returns defaults).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwgetstartvalues.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate Distribution Parameters Using Method of Moments — gkwgetstartvalues","text":"Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/gkwgetstartvalues.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate Distribution Parameters Using Method of Moments — gkwgetstartvalues","text":"","code":"# \\donttest{ # Generate sample data from Beta distribution set.seed(123) x <- rbeta(100, shape1 = 2, shape2 = 3)  # Estimate Beta parameters params_beta <- gkwgetstartvalues(x, family = \"beta\") print(params_beta) #>    gamma    delta  #> 2.421561 2.455624   # Estimate Kumaraswamy parameters params_kw <- gkwgetstartvalues(x, family = \"kw\") print(params_kw) #>    alpha     beta  #> 1.972954 1.895691   # Estimate GKw parameters with more starting points params_gkw <- gkwgetstartvalues(x, family = \"gkw\", n_starts = 10) print(params_gkw) #>     alpha      beta     gamma     delta    lambda  #> 1.2590661 3.1762475 1.9558583 0.0100000 0.9977211  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/grbeta.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","title":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","text":"Computes gradient vector (vector first partial derivatives) negative log-likelihood function standard Beta distribution, using parameterization common generalized distribution families. distribution parameterized gamma (\\(\\gamma\\)) delta (\\(\\delta\\)), corresponding standard Beta distribution shape parameters shape1 = gamma shape2 = delta + 1. gradient useful optimization algorithms.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbeta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","text":"","code":"grbeta(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/grbeta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","text":"par numeric vector length 2 containing distribution parameters order: gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbeta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","text":"Returns numeric vector length 2 containing partial derivatives negative log-likelihood function \\(-\\ell(\\theta | \\mathbf{x})\\) respect parameter: \\((-\\partial \\ell/\\partial \\gamma, -\\partial \\ell/\\partial \\delta)\\). Returns vector NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbeta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","text":"function calculates gradient negative log-likelihood Beta distribution parameters shape1 = gamma (\\(\\gamma\\)) shape2 = delta + 1 (\\(\\delta+1\\)). components gradient vector (\\(-\\nabla \\ell(\\theta | \\mathbf{x})\\)) : $$ -\\frac{\\partial \\ell}{\\partial \\gamma} = n[\\psi(\\gamma) - \\psi(\\gamma+\\delta+1)] - \\sum_{=1}^{n}\\ln(x_i) $$ $$ -\\frac{\\partial \\ell}{\\partial \\delta} = n[\\psi(\\delta+1) - \\psi(\\gamma+\\delta+1)] - \\sum_{=1}^{n}\\ln(1-x_i) $$ \\(\\psi(\\cdot)\\) digamma function (digamma). formulas represent derivatives \\(-\\ell(\\theta)\\), consistent minimizing negative log-likelihood. correspond relevant components general GKw gradient (grgkw) evaluated \\(\\alpha=1, \\beta=1, \\lambda=1\\). Note parameterization: standard Beta shape parameters \\(\\gamma\\) \\(\\delta+1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbeta.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","text":"Johnson, N. L., Kotz, S., & Balakrishnan, N. (1995). Continuous Univariate Distributions, Volume 2 (2nd ed.). Wiley. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, (Note: Specific gradient formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/grbeta.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbeta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — grbeta","text":"","code":"# \\donttest{ ## Example 1: Basic Gradient Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(gamma = 2.0, delta = 3.0) data <- rbeta_(n, gamma = true_params[1], delta = true_params[2])  # Evaluate gradient at true parameters grad_true <- grbeta(par = true_params, data = data) cat(\"Gradient at true parameters:\\n\") #> Gradient at true parameters: print(grad_true) #> [1] -13.640592   5.466001 cat(\"Norm:\", sqrt(sum(grad_true^2)), \"\\n\") #> Norm: 14.695   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 2.5),   c(2.0, 3.0),   c(2.5, 3.5) )  grad_norms <- apply(test_params, 1, function(p) {   g <- grbeta(p, data)   sqrt(sum(g^2)) })  results <- data.frame(   Gamma = test_params[, 1],   Delta = test_params[, 2],   Grad_Norm = grad_norms ) print(results, digits = 4) #>   Gamma Delta Grad_Norm #> 1   1.5   2.5    206.71 #> 2   2.0   3.0     14.69 #> 3   2.5   3.5    104.03   ## Example 2: Gradient in Optimization  # Optimization with analytical gradient fit_with_grad <- optim(   par = c(1.5, 2.5),   fn = llbeta,   gr = grbeta,   data = data,   method = \"L-BFGS-B\",   lower = c(0.01, 0.01),   upper = c(100, 100),   hessian = TRUE,   control = list(trace = 0) )  # Optimization without gradient fit_no_grad <- optim(   par = c(1.5, 2.5),   fn = llbeta,   data = data,   method = \"L-BFGS-B\",   lower = c(0.01, 0.01),   upper = c(100, 100),   hessian = TRUE,   control = list(trace = 0) )  comparison <- data.frame(   Method = c(\"With Gradient\", \"Without Gradient\"),   Gamma = c(fit_with_grad$par[1], fit_no_grad$par[1]),   Delta = c(fit_with_grad$par[2], fit_no_grad$par[2]),   NegLogLik = c(fit_with_grad$value, fit_no_grad$value),   Iterations = c(fit_with_grad$counts[1], fit_no_grad$counts[1]) ) print(comparison, digits = 4, row.names = FALSE) #>            Method Gamma Delta NegLogLik Iterations #>     With Gradient 2.029 2.997    -359.8         12 #>  Without Gradient 2.029 2.997    -359.8         12   ## Example 3: Verifying Gradient at MLE  mle <- fit_with_grad$par names(mle) <- c(\"gamma\", \"delta\")  # At MLE, gradient should be approximately zero gradient_at_mle <- grbeta(par = mle, data = data) cat(\"\\nGradient at MLE:\\n\") #>  #> Gradient at MLE: print(gradient_at_mle) #> [1] -0.0020945895  0.0006804804 cat(\"Max absolute component:\", max(abs(gradient_at_mle)), \"\\n\") #> Max absolute component: 0.00209459  cat(\"Gradient norm:\", sqrt(sum(gradient_at_mle^2)), \"\\n\") #> Gradient norm: 0.002202353    ## Example 4: Numerical vs Analytical Gradient  # Manual finite difference gradient numerical_gradient <- function(f, x, data, h = 1e-7) {   grad <- numeric(length(x))   for (i in seq_along(x)) {     x_plus <- x_minus <- x     x_plus[i] <- x[i] + h     x_minus[i] <- x[i] - h     grad[i] <- (f(x_plus, data) - f(x_minus, data)) / (2 * h)   }   return(grad) }  # Compare at MLE grad_analytical <- grbeta(par = mle, data = data) grad_numerical <- numerical_gradient(llbeta, mle, data)  comparison_grad <- data.frame(   Parameter = c(\"gamma\", \"delta\"),   Analytical = grad_analytical,   Numerical = grad_numerical,   Abs_Diff = abs(grad_analytical - grad_numerical),   Rel_Error = abs(grad_analytical - grad_numerical) /               (abs(grad_analytical) + 1e-10) ) print(comparison_grad, digits = 8) #>   Parameter     Analytical      Numerical      Abs_Diff    Rel_Error #> 1     gamma -0.00209458950 -0.00210093276 6.3432585e-06 0.0030284016 #> 2     delta  0.00068048039  0.00067643668 4.0437060e-06 0.0059424276   ## Example 5: Score Test Statistic  # Score test for H0: theta = theta0 theta0 <- c(1.8, 2.8) score_theta0 <- -grbeta(par = theta0, data = data)  # Fisher information at theta0 fisher_info <- hsbeta(par = theta0, data = data)  # Score test statistic score_stat <- t(score_theta0) %*% solve(fisher_info) %*% score_theta0 p_value <- pchisq(score_stat, df = 2, lower.tail = FALSE)  cat(\"\\nScore Test:\\n\") #>  #> Score Test: cat(\"H0: gamma=1.8, delta=2.8\\n\") #> H0: gamma=1.8, delta=2.8 cat(\"Test statistic:\", score_stat, \"\\n\") #> Test statistic: 11.47398  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 0.003224    ## Example 6: Confidence Ellipse (Gamma vs Delta)  # Observed information obs_info <- hsbeta(par = mle, data = data) vcov_full <- solve(obs_info)  # Create confidence ellipse theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  eig_decomp <- eigen(vcov_full) ellipse <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Marginal confidence intervals se_2d <- sqrt(diag(vcov_full)) ci_gamma <- mle[1] + c(-1, 1) * 1.96 * se_2d[1] ci_delta <- mle[2] + c(-1, 1) * 1.96 * se_2d[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = expression(delta),      main = \"95% Confidence Region (Gamma vs Delta)\", las = 1)  # Add marginal CIs abline(v = ci_gamma, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_delta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/grbkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","title":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","text":"Computes gradient vector (vector first partial derivatives) negative log-likelihood function Beta-Kumaraswamy (BKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\lambda = 1\\). gradient typically used optimization algorithms maximum likelihood estimation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","text":"","code":"grbkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/grbkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","text":"par numeric vector length 4 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","text":"Returns numeric vector length 4 containing partial derivatives negative log-likelihood function \\(-\\ell(\\theta | \\mathbf{x})\\) respect parameter: \\((-\\partial \\ell/\\partial \\alpha, -\\partial \\ell/\\partial \\beta, -\\partial \\ell/\\partial \\gamma, -\\partial \\ell/\\partial \\delta)\\). Returns vector NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","text":"components gradient vector negative log-likelihood (\\(-\\nabla \\ell(\\theta | \\mathbf{x})\\)) BKw (\\(\\lambda=1\\)) model : $$ -\\frac{\\partial \\ell}{\\partial \\alpha} = -\\frac{n}{\\alpha} - \\sum_{=1}^{n}\\ln(x_i) + \\sum_{=1}^{n}\\left[x_i^{\\alpha} \\ln(x_i) \\left(\\frac{\\beta(\\delta+1)-1}{v_i} - \\frac{(\\gamma-1) \\beta v_i^{\\beta-1}}{w_i}\\right)\\right] $$ $$ -\\frac{\\partial \\ell}{\\partial \\beta} = -\\frac{n}{\\beta} - (\\delta+1)\\sum_{=1}^{n}\\ln(v_i) + \\sum_{=1}^{n}\\left[\\frac{(\\gamma-1) v_i^{\\beta} \\ln(v_i)}{w_i}\\right] $$ $$ -\\frac{\\partial \\ell}{\\partial \\gamma} = n[\\psi(\\gamma) - \\psi(\\gamma+\\delta+1)] - \\sum_{=1}^{n}\\ln(w_i) $$ $$ -\\frac{\\partial \\ell}{\\partial \\delta} = n[\\psi(\\delta+1) - \\psi(\\gamma+\\delta+1)] - \\beta\\sum_{=1}^{n}\\ln(v_i) $$ : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) \\(\\psi(\\cdot)\\) digamma function (digamma). formulas represent derivatives \\(-\\ell(\\theta)\\), consistent minimizing negative log-likelihood. correspond general GKw gradient (grgkw) components \\(\\alpha, \\beta, \\gamma, \\delta\\) evaluated \\(\\lambda=1\\). Note component \\(\\lambda\\) omitted. Numerical stability maintained careful implementation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. (Note: Specific gradient formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/grbkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grbkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the Negative Log-Likelihood for the BKw Distribution — grbkw","text":"","code":"# \\donttest{ ## Example 1: Basic Gradient Evaluation  # Generate sample data set.seed(2203) n <- 1000 true_params <- c(alpha = 2.0, beta = 1.5, gamma = 1.5, delta = 0.5) data <- rbkw(n, alpha = true_params[1], beta = true_params[2],              gamma = true_params[3], delta = true_params[4])  # Evaluate gradient at true parameters grad_true <- grbkw(par = true_params, data = data) cat(\"Gradient at true parameters:\\n\") #> Gradient at true parameters: print(grad_true) #> [1]  31.18587 -45.45918  29.19980 -41.56769 cat(\"Norm:\", sqrt(sum(grad_true^2)), \"\\n\") #> Norm: 74.96397   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 1.0, 1.0, 0.3),   c(2.0, 1.5, 1.5, 0.5),   c(2.5, 2.0, 2.0, 0.7) )  grad_norms <- apply(test_params, 1, function(p) {   g <- grbkw(p, data)   sqrt(sum(g^2)) })  results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Gamma = test_params[, 3],   Delta = test_params[, 4],   Grad_Norm = grad_norms ) print(results, digits = 4) #>   Alpha Beta Gamma Delta Grad_Norm #> 1   1.5  1.0   1.0   0.3    337.55 #> 2   2.0  1.5   1.5   0.5     74.96 #> 3   2.5  2.0   2.0   0.7    380.04   ## Example 2: Gradient in Optimization  # Optimization with analytical gradient fit_with_grad <- optim(   par = c(1.8, 1.2, 1.1, 0.3),   fn = llbkw,   gr = grbkw,   data = data,   method = \"Nelder-Mead\",   hessian = TRUE,   control = list(trace = 0) )  # Optimization without gradient fit_no_grad <- optim(   par = c(1.8, 1.2, 1.1, 0.3),   fn = llbkw,   data = data,   method = \"Nelder-Mead\",   hessian = TRUE,   control = list(trace = 0) )  comparison <- data.frame(   Method = c(\"With Gradient\", \"Without Gradient\"),   Alpha = c(fit_with_grad$par[1], fit_no_grad$par[1]),   Beta = c(fit_with_grad$par[2], fit_no_grad$par[2]),   Gamma = c(fit_with_grad$par[3], fit_no_grad$par[3]),   Delta = c(fit_with_grad$par[4], fit_no_grad$par[4]),   NegLogLik = c(fit_with_grad$value, fit_no_grad$value),   Iterations = c(fit_with_grad$counts[1], fit_no_grad$counts[1]) ) print(comparison, digits = 4, row.names = FALSE) #>            Method Alpha  Beta Gamma   Delta NegLogLik Iterations #>     With Gradient  2.57 2.332 1.122 0.06702    -270.2        501 #>  Without Gradient  2.57 2.332 1.122 0.06702    -270.2        501   ## Example 3: Verifying Gradient at MLE  mle <- fit_with_grad$par names(mle) <- c(\"alpha\", \"beta\", \"gamma\", \"delta\")  # At MLE, gradient should be approximately zero gradient_at_mle <- grbkw(par = mle, data = data) cat(\"\\nGradient at MLE:\\n\") #>  #> Gradient at MLE: print(gradient_at_mle) #> [1]  0.5000681 -0.1496257  0.6667976 -0.2655980 cat(\"Max absolute component:\", max(abs(gradient_at_mle)), \"\\n\") #> Max absolute component: 0.6667976  cat(\"Gradient norm:\", sqrt(sum(gradient_at_mle^2)), \"\\n\") #> Gradient norm: 0.8874781    ## Example 4: Numerical vs Analytical Gradient  # Manual finite difference gradient numerical_gradient <- function(f, x, data, h = 1e-7) {   grad <- numeric(length(x))   for (i in seq_along(x)) {     x_plus <- x_minus <- x     x_plus[i] <- x[i] + h     x_minus[i] <- x[i] - h     grad[i] <- (f(x_plus, data) - f(x_minus, data)) / (2 * h)   }   return(grad) }  # Compare at MLE grad_analytical <- grbkw(par = mle, data = data) grad_numerical <- numerical_gradient(llbkw, mle, data)  comparison_grad <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"gamma\", \"delta\"),   Analytical = grad_analytical,   Numerical = grad_numerical,   Abs_Diff = abs(grad_analytical - grad_numerical),   Rel_Error = abs(grad_analytical - grad_numerical) /               (abs(grad_analytical) + 1e-10) ) print(comparison_grad, digits = 8) #>   Parameter  Analytical   Numerical      Abs_Diff     Rel_Error #> 1     alpha  0.50006808  0.50006093 7.1441844e-06 1.4286424e-05 #> 2      beta -0.14962570 -0.14962154 4.1532289e-06 2.7757458e-05 #> 3     gamma  0.66679761  0.66679576 1.8569186e-06 2.7848309e-06 #> 4     delta -0.26559804 -0.26560144 3.4024424e-06 1.2810495e-05   ## Example 5: Score Test Statistic  # Score test for H0: theta = theta0 theta0 <- c(1.8, 1.3, 1.2, 0.4) score_theta0 <- -grbkw(par = theta0, data = data)  # Fisher information at theta0 fisher_info <- hsbkw(par = theta0, data = data)  # Score test statistic score_stat <- t(score_theta0) %*% solve(fisher_info) %*% score_theta0 p_value <- pchisq(score_stat, df = 4, lower.tail = FALSE)  cat(\"\\nScore Test:\\n\") #>  #> Score Test: cat(\"H0: alpha=1.8, beta=1.3, gamma=1.2, delta=0.4\\n\") #> H0: alpha=1.8, beta=1.3, gamma=1.2, delta=0.4 cat(\"Test statistic:\", score_stat, \"\\n\") #> Test statistic: 61.34372  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 1.514e-12    ## Example 6: Confidence Ellipses (Selected pairs)  # Observed information obs_info <- hsbkw(par = mle, data = data) vcov_full <- solve(obs_info)  # Create confidence ellipses theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  # Alpha vs Beta ellipse vcov_ab <- vcov_full[1:2, 1:2] eig_decomp_ab <- eigen(vcov_ab) ellipse_ab <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_ab[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp_ab$vectors %*% diag(sqrt(eig_decomp_ab$values)) %*% v) }  # Alpha vs Gamma ellipse vcov_ag <- vcov_full[c(1, 3), c(1, 3)] eig_decomp_ag <- eigen(vcov_ag) ellipse_ag <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_ag[i, ] <- mle[c(1, 3)] + sqrt(chi2_val) *     (eig_decomp_ag$vectors %*% diag(sqrt(eig_decomp_ag$values)) %*% v) }  # Beta vs Delta ellipse vcov_bd <- vcov_full[c(2, 4), c(2, 4)] eig_decomp_bd <- eigen(vcov_bd) ellipse_bd <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_bd[i, ] <- mle[c(2, 4)] + sqrt(chi2_val) *     (eig_decomp_bd$vectors %*% diag(sqrt(eig_decomp_bd$values)) %*% v) }  # Marginal confidence intervals se_ab <- sqrt(diag(vcov_ab)) ci_alpha_ab <- mle[1] + c(-1, 1) * 1.96 * se_ab[1] ci_beta_ab <- mle[2] + c(-1, 1) * 1.96 * se_ab[2]  se_ag <- sqrt(diag(vcov_ag)) ci_alpha_ag <- mle[1] + c(-1, 1) * 1.96 * se_ag[1] ci_gamma_ag <- mle[3] + c(-1, 1) * 1.96 * se_ag[2]  se_bd <- sqrt(diag(vcov_bd)) ci_beta_bd <- mle[2] + c(-1, 1) * 1.96 * se_bd[1] ci_delta_bd <- mle[4] + c(-1, 1) * 1.96 * se_bd[2]  # Plot selected ellipses side by side par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Alpha vs Beta plot(ellipse_ab[, 1], ellipse_ab[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"Alpha vs Beta\", las = 1, xlim = range(ellipse_ab[, 1], ci_alpha_ab),      ylim = range(ellipse_ab[, 2], ci_beta_ab)) abline(v = ci_alpha_ab, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_beta_ab, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Alpha vs Gamma plot(ellipse_ag[, 1], ellipse_ag[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(gamma),      main = \"Alpha vs Gamma\", las = 1, xlim = range(ellipse_ag[, 1], ci_alpha_ag),      ylim = range(ellipse_ag[, 2], ci_gamma_ag)) abline(v = ci_alpha_ag, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_gamma_ag, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Beta vs Delta plot(ellipse_bd[, 1], ellipse_bd[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = expression(delta),      main = \"Beta vs Delta\", las = 1, xlim = range(ellipse_bd[, 1], ci_beta_bd),      ylim = range(ellipse_bd[, 2], ci_delta_bd)) abline(v = ci_beta_bd, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_delta_bd, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[2], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[4], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\", cex = 0.8)   par(mfrow = c(1, 1))  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/grekw.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","title":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","text":"Computes gradient vector (vector first partial derivatives) negative log-likelihood function Exponentiated Kumaraswamy (EKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\) \\(\\delta = 0\\). gradient useful optimization.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grekw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","text":"","code":"grekw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/grekw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","text":"par numeric vector length 3 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grekw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","text":"Returns numeric vector length 3 containing partial derivatives negative log-likelihood function \\(-\\ell(\\theta | \\mathbf{x})\\) respect parameter: \\((-\\partial \\ell/\\partial \\alpha, -\\partial \\ell/\\partial \\beta, -\\partial \\ell/\\partial \\lambda)\\). Returns vector NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grekw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","text":"components gradient vector negative log-likelihood (\\(-\\nabla \\ell(\\theta | \\mathbf{x})\\)) EKw (\\(\\gamma=1, \\delta=0\\)) model : $$ -\\frac{\\partial \\ell}{\\partial \\alpha} = -\\frac{n}{\\alpha} - \\sum_{=1}^{n}\\ln(x_i) + \\sum_{=1}^{n}\\left[x_i^{\\alpha} \\ln(x_i) \\left(\\frac{\\beta-1}{v_i} - \\frac{(\\lambda-1) \\beta v_i^{\\beta-1}}{w_i}\\right)\\right] $$ $$ -\\frac{\\partial \\ell}{\\partial \\beta} = -\\frac{n}{\\beta} - \\sum_{=1}^{n}\\ln(v_i) + \\sum_{=1}^{n}\\left[\\frac{(\\lambda-1) v_i^{\\beta} \\ln(v_i)}{w_i}\\right] $$ $$ -\\frac{\\partial \\ell}{\\partial \\lambda} = -\\frac{n}{\\lambda} - \\sum_{=1}^{n}\\ln(w_i) $$ : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) formulas represent derivatives \\(-\\ell(\\theta)\\), consistent minimizing negative log-likelihood. correspond relevant components general GKw gradient (grgkw) evaluated \\(\\gamma=1, \\delta=0\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grekw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","text":"Nadarajah, S., Cordeiro, G. M., & Ortega, E. M. (2012). exponentiated Kumaraswamy distribution. Journal Franklin Institute, 349(3), Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. (Note: Specific gradient formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/grekw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grekw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the Negative Log-Likelihood for the EKw Distribution — grekw","text":"","code":"# \\donttest{ ## Example 1: Basic Gradient Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.5, beta = 3.5, lambda = 2.0) data <- rekw(n, alpha = true_params[1], beta = true_params[2],              lambda = true_params[3])  # Evaluate gradient at true parameters grad_true <- grekw(par = true_params, data = data) cat(\"Gradient at true parameters:\\n\") #> Gradient at true parameters: print(grad_true) #> [1]  6.172699 -4.918839  3.176895 cat(\"Norm:\", sqrt(sum(grad_true^2)), \"\\n\") #> Norm: 8.508223   # Evaluate at different parameter values test_params <- rbind(   c(2.0, 3.0, 1.5),   c(2.5, 3.5, 2.0),   c(3.0, 4.0, 2.5) )  grad_norms <- apply(test_params, 1, function(p) {   g <- grekw(p, data)   sqrt(sum(g^2)) })  results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Lambda = test_params[, 3],   Grad_Norm = grad_norms ) print(results, digits = 4) #>   Alpha Beta Lambda Grad_Norm #> 1   2.0  3.0    1.5   473.068 #> 2   2.5  3.5    2.0     8.508 #> 3   3.0  4.0    2.5   429.054   ## Example 2: Gradient in Optimization  # Optimization with analytical gradient fit_with_grad <- optim(   par = c(2, 3, 1.5),   fn = llekw,   gr = grekw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(trace = 0) )  # Optimization without gradient fit_no_grad <- optim(   par = c(2, 3, 1.5),   fn = llekw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(trace = 0) )  comparison <- data.frame(   Method = c(\"With Gradient\", \"Without Gradient\"),   Alpha = c(fit_with_grad$par[1], fit_no_grad$par[1]),   Beta = c(fit_with_grad$par[2], fit_no_grad$par[2]),   Lambda = c(fit_with_grad$par[3], fit_no_grad$par[3]),   NegLogLik = c(fit_with_grad$value, fit_no_grad$value),   Iterations = c(fit_with_grad$counts[1], fit_no_grad$counts[1]) ) print(comparison, digits = 4, row.names = FALSE) #>            Method Alpha  Beta Lambda NegLogLik Iterations #>     With Gradient 2.663 3.653  1.843    -491.3         59 #>  Without Gradient 2.663 3.653  1.843    -491.3         59   ## Example 3: Verifying Gradient at MLE  mle <- fit_with_grad$par names(mle) <- c(\"alpha\", \"beta\", \"lambda\")  # At MLE, gradient should be approximately zero gradient_at_mle <- grekw(par = mle, data = data) cat(\"\\nGradient at MLE:\\n\") #>  #> Gradient at MLE: print(gradient_at_mle) #> [1] 2.067846e-05 8.446125e-06 1.901242e-05 cat(\"Max absolute component:\", max(abs(gradient_at_mle)), \"\\n\") #> Max absolute component: 2.067846e-05  cat(\"Gradient norm:\", sqrt(sum(gradient_at_mle^2)), \"\\n\") #> Gradient norm: 2.933271e-05    ## Example 4: Numerical vs Analytical Gradient  # Manual finite difference gradient numerical_gradient <- function(f, x, data, h = 1e-7) {   grad <- numeric(length(x))   for (i in seq_along(x)) {     x_plus <- x_minus <- x     x_plus[i] <- x[i] + h     x_minus[i] <- x[i] - h     grad[i] <- (f(x_plus, data) - f(x_minus, data)) / (2 * h)   }   return(grad) }  # Compare at MLE grad_analytical <- grekw(par = mle, data = data) grad_numerical <- numerical_gradient(llekw, mle, data)  comparison_grad <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"lambda\"),   Analytical = grad_analytical,   Numerical = grad_numerical,   Abs_Diff = abs(grad_analytical - grad_numerical),   Rel_Error = abs(grad_analytical - grad_numerical) /               (abs(grad_analytical) + 1e-10) ) print(comparison_grad, digits = 8) #>   Parameter    Analytical     Numerical      Abs_Diff   Rel_Error #> 1     alpha 2.0678456e-05 8.2422957e-06 1.2436161e-05 0.601403713 #> 2      beta 8.4461253e-06 8.2422957e-06 2.0382958e-07 0.024132624 #> 3    lambda 1.9012424e-05 1.9326762e-05 3.1433795e-07 0.016533204   ## Example 5: Score Test Statistic  # Score test for H0: theta = theta0 theta0 <- c(2.2, 3.2, 1.8) score_theta0 <- -grekw(par = theta0, data = data)  # Fisher information at theta0 fisher_info <- hsekw(par = theta0, data = data)  # Score test statistic score_stat <- t(score_theta0) %*% solve(fisher_info) %*% score_theta0 p_value <- pchisq(score_stat, df = 3, lower.tail = FALSE)  cat(\"\\nScore Test:\\n\") #>  #> Score Test: cat(\"H0: alpha=2.2, beta=3.2, lambda=1.8\\n\") #> H0: alpha=2.2, beta=3.2, lambda=1.8 cat(\"Test statistic:\", score_stat, \"\\n\") #> Test statistic: 56.50173  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 3.283e-12    ## Example 6: Confidence Ellipse (Alpha vs Beta)  # Observed information obs_info <- hsekw(par = mle, data = data) vcov_full <- solve(obs_info) vcov_2d <- vcov_full[1:2, 1:2]  # Create confidence ellipse theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  eig_decomp <- eigen(vcov_2d) ellipse <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Marginal confidence intervals se_2d <- sqrt(diag(vcov_2d)) ci_alpha <- mle[1] + c(-1, 1) * 1.96 * se_2d[1] ci_beta <- mle[2] + c(-1, 1) * 1.96 * se_2d[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"95% Confidence Region (Alpha vs Beta)\", las = 1)  # Add marginal CIs abline(v = ci_alpha, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_beta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")    ## Example 7: Confidence Ellipse (Alpha vs Lambda)  # Extract 2x2 submatrix for alpha and lambda vcov_2d_al <- vcov_full[c(1, 3), c(1, 3)]  # Create confidence ellipse eig_decomp_al <- eigen(vcov_2d_al) ellipse_al <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_al[i, ] <- mle[c(1, 3)] + sqrt(chi2_val) *     (eig_decomp_al$vectors %*% diag(sqrt(eig_decomp_al$values)) %*% v) }  # Marginal confidence intervals se_2d_al <- sqrt(diag(vcov_2d_al)) ci_alpha_2 <- mle[1] + c(-1, 1) * 1.96 * se_2d_al[1] ci_lambda <- mle[3] + c(-1, 1) * 1.96 * se_2d_al[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse_al[, 1], ellipse_al[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(lambda),      main = \"95% Confidence Region (Alpha vs Lambda)\", las = 1)  # Add marginal CIs abline(v = ci_alpha_2, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_lambda, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")    ## Example 8: Confidence Ellipse (Beta vs Lambda)  # Extract 2x2 submatrix for beta and lambda vcov_2d_bl <- vcov_full[2:3, 2:3]  # Create confidence ellipse eig_decomp_bl <- eigen(vcov_2d_bl) ellipse_bl <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_bl[i, ] <- mle[2:3] + sqrt(chi2_val) *     (eig_decomp_bl$vectors %*% diag(sqrt(eig_decomp_bl$values)) %*% v) }  # Marginal confidence intervals se_2d_bl <- sqrt(diag(vcov_2d_bl)) ci_beta_2 <- mle[2] + c(-1, 1) * 1.96 * se_2d_bl[1] ci_lambda_2 <- mle[3] + c(-1, 1) * 1.96 * se_2d_bl[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse_bl[, 1], ellipse_bl[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = expression(lambda),      main = \"95% Confidence Region (Beta vs Lambda)\", las = 1)  # Add marginal CIs abline(v = ci_beta_2, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_lambda_2, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[2], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[3], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/grgkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","title":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","text":"Computes gradient vector (vector partial derivatives) negative log-likelihood function five-parameter Generalized Kumaraswamy (GKw) distribution. provides analytical gradient, often used efficient optimization via maximum likelihood estimation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grgkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","text":"","code":"grgkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/grgkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","text":"par numeric vector length 5 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grgkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","text":"Returns numeric vector length 5 containing partial derivatives negative log-likelihood function \\(-\\ell(\\theta | \\mathbf{x})\\) respect parameter: \\((-\\partial \\ell/\\partial \\alpha, -\\partial \\ell/\\partial \\beta, -\\partial \\ell/\\partial \\gamma, -\\partial \\ell/\\partial \\delta, -\\partial \\ell/\\partial \\lambda)\\). Returns vector NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grgkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","text":"components gradient vector negative log-likelihood (\\(-\\nabla \\ell(\\theta | \\mathbf{x})\\)) : $$ -\\frac{\\partial \\ell}{\\partial \\alpha} = -\\frac{n}{\\alpha} - \\sum_{=1}^{n}\\ln(x_i) + \\sum_{=1}^{n}\\left[x_i^{\\alpha} \\ln(x_i) \\left(\\frac{\\beta-1}{v_i} - \\frac{(\\gamma\\lambda-1) \\beta v_i^{\\beta-1}}{w_i} + \\frac{\\delta \\lambda \\beta v_i^{\\beta-1} w_i^{\\lambda-1}}{z_i}\\right)\\right] $$ $$ -\\frac{\\partial \\ell}{\\partial \\beta} = -\\frac{n}{\\beta} - \\sum_{=1}^{n}\\ln(v_i) + \\sum_{=1}^{n}\\left[v_i^{\\beta} \\ln(v_i) \\left(\\frac{\\gamma\\lambda-1}{w_i} - \\frac{\\delta \\lambda w_i^{\\lambda-1}}{z_i}\\right)\\right] $$ $$ -\\frac{\\partial \\ell}{\\partial \\gamma} = n[\\psi(\\gamma) - \\psi(\\gamma+\\delta+1)] - \\lambda\\sum_{=1}^{n}\\ln(w_i) $$ $$ -\\frac{\\partial \\ell}{\\partial \\delta} = n[\\psi(\\delta+1) - \\psi(\\gamma+\\delta+1)] - \\sum_{=1}^{n}\\ln(z_i) $$ $$ -\\frac{\\partial \\ell}{\\partial \\lambda} = -\\frac{n}{\\lambda} - \\gamma\\sum_{=1}^{n}\\ln(w_i) + \\delta\\sum_{=1}^{n}\\frac{w_i^{\\lambda}\\ln(w_i)}{z_i} $$ : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) \\(z_i = 1 - w_i^{\\lambda} = 1 - [1-(1-x_i^{\\alpha})^{\\beta}]^{\\lambda}\\) \\(\\psi(\\cdot)\\) digamma function (digamma). Numerical stability ensured careful implementation, including checks valid inputs handling intermediate calculations involving potentially small large numbers, often leveraging Armadillo C++ library efficiency.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grgkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/grgkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grgkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the Negative Log-Likelihood for the GKw Distribution — grgkw","text":"","code":"# \\donttest{ ## Example 1: Basic Gradient Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.0, beta = 3.0, gamma = 1.5, delta = 2.0, lambda = 1.8) data <- rgkw(n, alpha = true_params[1], beta = true_params[2],              gamma = true_params[3], delta = true_params[4],              lambda = true_params[5])  # Evaluate gradient at true parameters grad_true <- grgkw(par = true_params, data = data) cat(\"Gradient at true parameters:\\n\") #> Gradient at true parameters: print(grad_true) #> [1] -34.386342  12.010575 -19.736267   7.392701 -22.078415 cat(\"Norm:\", sqrt(sum(grad_true^2)), \"\\n\") #> Norm: 47.52161   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 2.5, 1.2, 1.5, 1.5),   c(2.0, 3.0, 1.5, 2.0, 1.8),   c(2.5, 3.5, 1.8, 2.5, 2.0) )  grad_norms <- apply(test_params, 1, function(p) {   g <- grgkw(p, data)   sqrt(sum(g^2)) })  results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Gamma = test_params[, 3],   Delta = test_params[, 4],   Lambda = test_params[, 5],   Grad_Norm = grad_norms ) print(results, digits = 4) #>   Alpha Beta Gamma Delta Lambda Grad_Norm #> 1   1.5  2.5   1.2   1.5    1.5   1504.78 #> 2   2.0  3.0   1.5   2.0    1.8     47.52 #> 3   2.5  3.5   1.8   2.5    2.0   1402.07   ## Example 2: Gradient in Optimization  # Optimization with analytical gradient fit_with_grad <- optim(   par = c(1.5, 2.5, 1.2, 1.5, 1.5),   fn = llgkw,   gr = grgkw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(trace = 0, maxit = 1000) )  # Optimization without gradient fit_no_grad <- optim(   par = c(1.5, 2.5, 1.2, 1.5, 1.5),   fn = llgkw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(trace = 0, maxit = 1000) )  comparison <- data.frame(   Method = c(\"With Gradient\", \"Without Gradient\"),   Alpha = c(fit_with_grad$par[1], fit_no_grad$par[1]),   Beta = c(fit_with_grad$par[2], fit_no_grad$par[2]),   Gamma = c(fit_with_grad$par[3], fit_no_grad$par[3]),   Delta = c(fit_with_grad$par[4], fit_no_grad$par[4]),   Lambda = c(fit_with_grad$par[5], fit_no_grad$par[5]),   NegLogLik = c(fit_with_grad$value, fit_no_grad$value),   Iterations = c(fit_with_grad$counts[1], fit_no_grad$counts[1]) ) print(comparison, digits = 4, row.names = FALSE) #>            Method Alpha  Beta  Gamma Delta Lambda NegLogLik Iterations #>     With Gradient 1.349 3.626 0.3486 1.254  13.31    -704.3        363 #>  Without Gradient 1.190 3.262 0.3825 1.480  14.10    -704.3        403   ## Example 3: Verifying Gradient at MLE  mle <- fit_with_grad$par names(mle) <- c(\"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\")  # At MLE, gradient should be approximately zero gradient_at_mle <- grgkw(par = mle, data = data) cat(\"\\nGradient at MLE:\\n\") #>  #> Gradient at MLE: print(gradient_at_mle) #> [1]  0.123066970 -0.002843102 -0.020414284  0.033724568 -0.004658634 cat(\"Max absolute component:\", max(abs(gradient_at_mle)), \"\\n\") #> Max absolute component: 0.123067  cat(\"Gradient norm:\", sqrt(sum(gradient_at_mle^2)), \"\\n\") #> Gradient norm: 0.129342    ## Example 4: Numerical vs Analytical Gradient  # Manual finite difference gradient numerical_gradient <- function(f, x, data, h = 1e-7) {   grad <- numeric(length(x))   for (i in seq_along(x)) {     x_plus <- x_minus <- x     x_plus[i] <- x[i] + h     x_minus[i] <- x[i] - h     grad[i] <- (f(x_plus, data) - f(x_minus, data)) / (2 * h)   }   return(grad) }  # Compare at MLE grad_analytical <- grgkw(par = mle, data = data) grad_numerical <- numerical_gradient(llgkw, mle, data)  comparison_grad <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\"),   Analytical = grad_analytical,   Numerical = grad_numerical,   Abs_Diff = abs(grad_analytical - grad_numerical),   Rel_Error = abs(grad_analytical - grad_numerical) /               (abs(grad_analytical) + 1e-10) ) print(comparison_grad, digits = 8) #>   Parameter    Analytical     Numerical      Abs_Diff     Rel_Error #> 1     alpha  0.1230669702  0.1230688440 1.8738061e-06 1.5225905e-05 #> 2      beta -0.0028431022 -0.0028438762 7.7406409e-07 2.7226037e-04 #> 3     gamma -0.0204142837 -0.0204079242 6.3594175e-06 3.1151803e-04 #> 4     delta  0.0337245677  0.0337212214 3.3462955e-06 9.9224267e-05 #> 5    lambda -0.0046586339 -0.0046577497 8.8416197e-07 1.8978996e-04   ## Example 5: Score Test Statistic  # Score test for H0: theta = theta0 theta0 <- c(1.8, 2.8, 1.3, 1.8, 1.6) score_theta0 <- grgkw(par = theta0, data = data)  # Fisher information at theta0 fisher_info <- hsgkw(par = theta0, data = data)  # Score test statistic score_stat <- t(score_theta0) %*% solve(fisher_info) %*% score_theta0 p_value <- pchisq(score_stat, df = 5, lower.tail = FALSE)  cat(\"\\nScore Test:\\n\") #>  #> Score Test: cat(\"H0: alpha=1.8, beta=2.8, gamma=1.3, delta=1.8, lambda=1.6\\n\") #> H0: alpha=1.8, beta=2.8, gamma=1.3, delta=1.8, lambda=1.6 cat(\"Test statistic:\", score_stat, \"\\n\") #> Test statistic: 258.9207  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: < 2.2e-16    ## Example 6: Confidence Ellipse (Alpha vs Beta)  # Observed information obs_info <- hsgkw(par = mle, data = data) vcov_full <- solve(obs_info) vcov_2d <- vcov_full[1:2, 1:2]  # Create confidence ellipse theta <- seq(0, 2 * pi, length.out = round(n/4)) chi2_val <- qchisq(0.95, df = 2)  eig_decomp <- eigen(vcov_2d) ellipse <- matrix(NA, nrow = round(n/4), ncol = 2) for (i in 1:round(n/4)) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Marginal confidence intervals se_2d <- sqrt(diag(vcov_2d)) ci_alpha <- mle[1] + c(-1, 1) * 1.96 * se_2d[1] ci_beta <- mle[2] + c(-1, 1) * 1.96 * se_2d[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"95% Confidence Region (Alpha vs Beta)\", las = 1)  # Add marginal CIs abline(v = ci_alpha, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_beta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")    ## Example 7: Confidence Ellipse (Gamma vs Delta)  # Extract 2x2 submatrix for gamma and delta vcov_2d_gd <- vcov_full[3:4, 3:4]  # Create confidence ellipse eig_decomp_gd <- eigen(vcov_2d_gd) ellipse_gd <- matrix(NA, nrow = round(n/4), ncol = 2) for (i in 1:round(n/4)) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_gd[i, ] <- mle[3:4] + sqrt(chi2_val) *     (eig_decomp_gd$vectors %*% diag(sqrt(eig_decomp_gd$values)) %*% v) }  # Marginal confidence intervals se_2d_gd <- sqrt(diag(vcov_2d_gd)) ci_gamma <- mle[3] + c(-1, 1) * 1.96 * se_2d_gd[1] ci_delta <- mle[4] + c(-1, 1) * 1.96 * se_2d_gd[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse_gd[, 1], ellipse_gd[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = expression(delta),      main = \"95% Confidence Region (Gamma vs Delta)\", las = 1)  # Add marginal CIs abline(v = ci_gamma, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_delta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[3], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[3], true_params[4], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/grkkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","title":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","text":"Computes gradient vector (vector first partial derivatives) negative log-likelihood function Kumaraswamy-Kumaraswamy (kkw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\). gradient typically used optimization algorithms maximum likelihood estimation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","text":"","code":"grkkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/grkkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","text":"par numeric vector length 4 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","text":"Returns numeric vector length 4 containing partial derivatives negative log-likelihood function \\(-\\ell(\\theta | \\mathbf{x})\\) respect parameter: \\((-\\partial \\ell/\\partial \\alpha, -\\partial \\ell/\\partial \\beta, -\\partial \\ell/\\partial \\delta, -\\partial \\ell/\\partial \\lambda)\\). Returns vector NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","text":"components gradient vector negative log-likelihood (\\(-\\nabla \\ell(\\theta | \\mathbf{x})\\)) kkw (\\(\\gamma=1\\)) model : $$ -\\frac{\\partial \\ell}{\\partial \\alpha} = -\\frac{n}{\\alpha} - \\sum_{=1}^{n}\\ln(x_i) + (\\beta-1)\\sum_{=1}^{n}\\frac{x_i^{\\alpha}\\ln(x_i)}{v_i} - (\\lambda-1)\\sum_{=1}^{n}\\frac{\\beta v_i^{\\beta-1} x_i^{\\alpha}\\ln(x_i)}{w_i} + \\delta\\sum_{=1}^{n}\\frac{\\lambda w_i^{\\lambda-1} \\beta v_i^{\\beta-1} x_i^{\\alpha}\\ln(x_i)}{z_i} $$ $$ -\\frac{\\partial \\ell}{\\partial \\beta} = -\\frac{n}{\\beta} - \\sum_{=1}^{n}\\ln(v_i) + (\\lambda-1)\\sum_{=1}^{n}\\frac{v_i^{\\beta}\\ln(v_i)}{w_i} - \\delta\\sum_{=1}^{n}\\frac{\\lambda w_i^{\\lambda-1} v_i^{\\beta}\\ln(v_i)}{z_i} $$ $$ -\\frac{\\partial \\ell}{\\partial \\delta} = -\\frac{n}{\\delta+1} - \\sum_{=1}^{n}\\ln(z_i) $$ $$ -\\frac{\\partial \\ell}{\\partial \\lambda} = -\\frac{n}{\\lambda} - \\sum_{=1}^{n}\\ln(w_i) + \\delta\\sum_{=1}^{n}\\frac{w_i^{\\lambda}\\ln(w_i)}{z_i} $$ : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) \\(z_i = 1 - w_i^{\\lambda} = 1 - [1-(1-x_i^{\\alpha})^{\\beta}]^{\\lambda}\\) formulas represent derivatives \\(-\\ell(\\theta)\\), consistent minimizing negative log-likelihood. correspond general GKw gradient (grgkw) components \\(\\alpha, \\beta, \\delta, \\lambda\\) evaluated \\(\\gamma=1\\). Note component \\(\\gamma\\) omitted. Numerical stability maintained careful implementation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/grkkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the Negative Log-Likelihood for the kkw Distribution — grkkw","text":"","code":"# \\donttest{ ## Example 1: Basic Gradient Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.0, beta = 3.0, delta = 1.5, lambda = 2.0) data <- rkkw(n, alpha = true_params[1], beta = true_params[2],              delta = true_params[3], lambda = true_params[4])  # Evaluate gradient at true parameters grad_true <- grkkw(par = true_params, data = data) cat(\"Gradient at true parameters:\\n\") #> Gradient at true parameters: print(grad_true) #> [1] 11.766117 -6.438008 -5.538257  5.937580 cat(\"Norm:\", sqrt(sum(grad_true^2)), \"\\n\") #> Norm: 15.67854   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 2.5, 1.0, 1.5),   c(2.0, 3.0, 1.5, 2.0),   c(2.5, 3.5, 2.0, 2.5) )  grad_norms <- apply(test_params, 1, function(p) {   g <- grkkw(p, data)   sqrt(sum(g^2)) })  results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Delta = test_params[, 3],   Lambda = test_params[, 4],   Grad_Norm = grad_norms ) print(results, digits = 4) #>   Alpha Beta Delta Lambda Grad_Norm #> 1   1.5  2.5   1.0    1.5    910.71 #> 2   2.0  3.0   1.5    2.0     15.68 #> 3   2.5  3.5   2.0    2.5    896.28   ## Example 2: Gradient in Optimization  # Optimization with analytical gradient fit_with_grad <- optim(   par = c(1.5, 2.5, 1.0, 1.5),   fn = llkkw,   gr = grkkw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(trace = 0) )  # Optimization without gradient fit_no_grad <- optim(   par = c(1.5, 2.5, 1.0, 1.5),   fn = llkkw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(trace = 0) )  comparison <- data.frame(   Method = c(\"With Gradient\", \"Without Gradient\"),   Alpha = c(fit_with_grad$par[1], fit_no_grad$par[1]),   Beta = c(fit_with_grad$par[2], fit_no_grad$par[2]),   Delta = c(fit_with_grad$par[3], fit_no_grad$par[3]),   Lambda = c(fit_with_grad$par[4], fit_no_grad$par[4]),   NegLogLik = c(fit_with_grad$value, fit_no_grad$value),   Iterations = c(fit_with_grad$counts[1], fit_no_grad$counts[1]) ) print(comparison, digits = 4, row.names = FALSE) #>            Method Alpha  Beta  Delta Lambda NegLogLik Iterations #>     With Gradient 2.304 3.610 1.2222  1.705    -586.5        113 #>  Without Gradient 2.495 4.544 0.8006  1.570    -586.5        213   ## Example 3: Verifying Gradient at MLE  mle <- fit_with_grad$par names(mle) <- c(\"alpha\", \"beta\", \"delta\", \"lambda\")  # At MLE, gradient should be approximately zero gradient_at_mle <- grkkw(par = mle, data = data) cat(\"\\nGradient at MLE:\\n\") #>  #> Gradient at MLE: print(gradient_at_mle) #> [1]  0.05693999 -0.03217987 -0.03422936  0.04666259 cat(\"Max absolute component:\", max(abs(gradient_at_mle)), \"\\n\") #> Max absolute component: 0.05693999  cat(\"Gradient norm:\", sqrt(sum(gradient_at_mle^2)), \"\\n\") #> Gradient norm: 0.08733128    ## Example 4: Numerical vs Analytical Gradient  # Manual finite difference gradient numerical_gradient <- function(f, x, data, h = 1e-7) {   grad <- numeric(length(x))   for (i in seq_along(x)) {     x_plus <- x_minus <- x     x_plus[i] <- x[i] + h     x_minus[i] <- x[i] - h     grad[i] <- (f(x_plus, data) - f(x_minus, data)) / (2 * h)   }   return(grad) }  # Compare at MLE grad_analytical <- grkkw(par = mle, data = data) grad_numerical <- numerical_gradient(llkkw, mle, data)  comparison_grad <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"delta\", \"lambda\"),   Analytical = grad_analytical,   Numerical = grad_numerical,   Abs_Diff = abs(grad_analytical - grad_numerical),   Rel_Error = abs(grad_analytical - grad_numerical) /               (abs(grad_analytical) + 1e-10) ) print(comparison_grad, digits = 8) #>   Parameter   Analytical    Numerical      Abs_Diff     Rel_Error #> 1     alpha  0.056939988  0.056946874 6.8854030e-06 1.2092386e-04 #> 2      beta -0.032179868 -0.032188154 8.2867859e-06 2.5751461e-04 #> 3     delta -0.034229365 -0.034231107 1.7418460e-06 5.0887477e-05 #> 4    lambda  0.046662594  0.046659352 3.2420501e-06 6.9478566e-05   ## Example 5: Score Test Statistic  # Score test for H0: theta = theta0 theta0 <- c(1.8, 2.8, 1.3, 1.8) score_theta0 <- -grkkw(par = theta0, data = data)  # Fisher information at theta0 fisher_info <- hskkw(par = theta0, data = data)  # Score test statistic score_stat <- t(score_theta0) %*% solve(fisher_info) %*% score_theta0 p_value <- pchisq(score_stat, df = 4, lower.tail = FALSE)  cat(\"\\nScore Test:\\n\") #>  #> Score Test: cat(\"H0: alpha=1.8, beta=2.8, delta=1.3, lambda=1.8\\n\") #> H0: alpha=1.8, beta=2.8, delta=1.3, lambda=1.8 cat(\"Test statistic:\", score_stat, \"\\n\") #> Test statistic: 65.77351  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 1.768e-13    ## Example 6: Confidence Ellipse with Gradient Information  # For visualization, use first two parameters (alpha, beta) # Observed information obs_info <- hskkw(par = mle, data = data) vcov_full <- solve(obs_info) vcov_2d <- vcov_full[1:2, 1:2]  # Create confidence ellipse theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  eig_decomp <- eigen(vcov_2d) ellipse <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Marginal confidence intervals se_2d <- sqrt(diag(vcov_2d)) ci_alpha <- mle[1] + c(-1, 1) * 1.96 * se_2d[1] ci_beta <- mle[2] + c(-1, 1) * 1.96 * se_2d[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"95% Confidence Region (Alpha vs Beta)\", las = 1)  # Add marginal CIs abline(v = ci_alpha, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_beta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/grkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","title":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","text":"Computes gradient vector (vector first partial derivatives) negative log-likelihood function two-parameter Kumaraswamy (Kw) distribution parameters alpha (\\(\\alpha\\)) beta (\\(\\beta\\)). provides analytical gradient often used efficient optimization via maximum likelihood estimation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","text":"","code":"grkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/grkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","text":"par numeric vector length 2 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","text":"Returns numeric vector length 2 containing partial derivatives negative log-likelihood function \\(-\\ell(\\theta | \\mathbf{x})\\) respect parameter: \\((-\\partial \\ell/\\partial \\alpha, -\\partial \\ell/\\partial \\beta)\\). Returns vector NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","text":"components gradient vector negative log-likelihood (\\(-\\nabla \\ell(\\theta | \\mathbf{x})\\)) Kw model : $$ -\\frac{\\partial \\ell}{\\partial \\alpha} = -\\frac{n}{\\alpha} - \\sum_{=1}^{n}\\ln(x_i) + (\\beta-1)\\sum_{=1}^{n}\\frac{x_i^{\\alpha}\\ln(x_i)}{v_i} $$ $$ -\\frac{\\partial \\ell}{\\partial \\beta} = -\\frac{n}{\\beta} - \\sum_{=1}^{n}\\ln(v_i) $$ \\(v_i = 1 - x_i^{\\alpha}\\). formulas represent derivatives \\(-\\ell(\\theta)\\), consistent minimizing negative log-likelihood. correspond relevant components general GKw gradient (grgkw) evaluated \\(\\gamma=1, \\delta=0, \\lambda=1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","text":"Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81. (Note: Specific gradient formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/grkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the Negative Log-Likelihood for the Kumaraswamy (Kw) Distribution — grkw","text":"","code":"# \\donttest{ ## Example 1: Basic Gradient Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.5, beta = 3.5) data <- rkw(n, alpha = true_params[1], beta = true_params[2])  # Evaluate gradient at true parameters grad_true <- grkw(par = true_params, data = data) cat(\"Gradient at true parameters:\\n\") #> Gradient at true parameters: print(grad_true) #> [1]  5.795703 -3.955898 cat(\"Norm:\", sqrt(sum(grad_true^2)), \"\\n\") #> Norm: 7.017072   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 2.5),   c(2.0, 3.0),   c(2.5, 3.5),   c(3.0, 4.0) )  grad_norms <- apply(test_params, 1, function(p) {   g <- grkw(p, data)   sqrt(sum(g^2)) })  results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Grad_Norm = grad_norms ) print(results, digits = 4) #>   Alpha Beta Grad_Norm #> 1   1.5  2.5   448.520 #> 2   2.0  3.0   175.451 #> 3   2.5  3.5     7.017 #> 4   3.0  4.0   137.615   ## Example 2: Gradient in Optimization  # Optimization with analytical gradient fit_with_grad <- optim(   par = c(2, 2),   fn = llkw,   gr = grkw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(trace = 0) )  # Optimization without gradient fit_no_grad <- optim(   par = c(2, 2),   fn = llkw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(trace = 0) )  comparison <- data.frame(   Method = c(\"With Gradient\", \"Without Gradient\"),   Alpha = c(fit_with_grad$par[1], fit_no_grad$par[1]),   Beta = c(fit_with_grad$par[2], fit_no_grad$par[2]),   NegLogLik = c(fit_with_grad$value, fit_no_grad$value),   Iterations = c(fit_with_grad$counts[1], fit_no_grad$counts[1]) ) print(comparison, digits = 4, row.names = FALSE) #>            Method Alpha  Beta NegLogLik Iterations #>     With Gradient 2.511 3.571    -279.6         30 #>  Without Gradient 2.511 3.571    -279.6         31   ## Example 3: Verifying Gradient at MLE  mle <- fit_with_grad$par names(mle) <- c(\"alpha\", \"beta\")  # At MLE, gradient should be approximately zero gradient_at_mle <- grkw(par = mle, data = data) cat(\"\\nGradient at MLE:\\n\") #>  #> Gradient at MLE: print(gradient_at_mle) #> [1]  2.071782e-05 -1.146518e-05 cat(\"Max absolute component:\", max(abs(gradient_at_mle)), \"\\n\") #> Max absolute component: 2.071782e-05  cat(\"Gradient norm:\", sqrt(sum(gradient_at_mle^2)), \"\\n\") #> Gradient norm: 2.367865e-05    ## Example 4: Numerical vs Analytical Gradient  # Manual finite difference gradient numerical_gradient <- function(f, x, data, h = 1e-7) {   grad <- numeric(length(x))   for (i in seq_along(x)) {     x_plus <- x_minus <- x     x_plus[i] <- x[i] + h     x_minus[i] <- x[i] - h     grad[i] <- (f(x_plus, data) - f(x_minus, data)) / (2 * h)   }   return(grad) }  # Compare at several points test_points <- rbind(   c(1.5, 2.5),   c(2.0, 3.0),   mle,   c(3.0, 4.0) )  cat(\"\\nNumerical vs Analytical Gradient Comparison:\\n\") #>  #> Numerical vs Analytical Gradient Comparison: for (i in 1:nrow(test_points)) {   grad_analytical <- grkw(par = test_points[i, ], data = data)   grad_numerical <- numerical_gradient(llkw, test_points[i, ], data)      cat(\"\\nPoint\", i, \": alpha =\", test_points[i, 1],        \", beta =\", test_points[i, 2], \"\\n\")      comparison <- data.frame(     Parameter = c(\"alpha\", \"beta\"),     Analytical = grad_analytical,     Numerical = grad_numerical,     Abs_Diff = abs(grad_analytical - grad_numerical),     Rel_Error = abs(grad_analytical - grad_numerical) /                  (abs(grad_analytical) + 1e-10)   )   print(comparison, digits = 8) } #>  #> Point 1 : alpha = 1.5 , beta = 2.5  #>   Parameter Analytical  Numerical      Abs_Diff     Rel_Error #> 1     alpha -431.55771 -431.55771 1.2864847e-06 2.9810258e-09 #> 2      beta  122.18002  122.18002 7.1891532e-07 5.8840662e-09 #>  #> Point 2 : alpha = 2 , beta = 3  #>   Parameter  Analytical   Numerical      Abs_Diff     Rel_Error #> 1     alpha -170.184879 -170.184880 1.3360205e-06 7.8504066e-09 #> 2      beta   42.661367   42.661367 3.0471102e-07 7.1425518e-09 #>  #> Point 3 : alpha = 2.511171 , beta = 3.570812  #>   Parameter     Analytical      Numerical      Abs_Diff   Rel_Error #> 1     alpha  2.0717825e-05  2.1600499e-05 8.8267439e-07 0.042604382 #> 2      beta -1.1465180e-05 -1.0800250e-05 6.6493050e-07 0.057995138 #>  #> Point 4 : alpha = 3 , beta = 4  #>   Parameter Analytical  Numerical      Abs_Diff     Rel_Error #> 1     alpha 133.673727 133.673730 2.8540615e-06 2.1350953e-08 #> 2      beta -32.697532 -32.697532 5.1952384e-08 1.5888778e-09   ## Example 5: Gradient Path Visualization  # Create grid alpha_grid <- seq(mle[1] - 1, mle[1] + 1, length.out = 20) beta_grid <- seq(mle[2] - 1, mle[2] + 1, length.out = 20) alpha_grid <- alpha_grid[alpha_grid > 0] beta_grid <- beta_grid[beta_grid > 0]  # Compute gradient vectors grad_alpha <- matrix(NA, nrow = length(alpha_grid), ncol = length(beta_grid)) grad_beta <- matrix(NA, nrow = length(alpha_grid), ncol = length(beta_grid))  for (i in seq_along(alpha_grid)) {   for (j in seq_along(beta_grid)) {     g <- grkw(c(alpha_grid[i], beta_grid[j]), data)     grad_alpha[i, j] <- -g[1]  # Negative for gradient ascent     grad_beta[i, j] <- -g[2]   } }  # Plot gradient field par(mar = c(4, 4, 3, 1)) plot(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5,      xlim = range(alpha_grid), ylim = range(beta_grid),      xlab = expression(alpha), ylab = expression(beta),      main = \"Gradient Vector Field\", las = 1)  # Subsample for clearer visualization step <- 2 for (i in seq(1, length(alpha_grid), by = step)) {   for (j in seq(1, length(beta_grid), by = step)) {     arrows(alpha_grid[i], beta_grid[j],            alpha_grid[i] + 0.05 * grad_alpha[i, j],            beta_grid[j] + 0.05 * grad_beta[i, j],            length = 0.05, col = \"#2E4057\", lwd = 1)   } }  points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) legend(\"topright\",        legend = c(\"MLE\", \"True\"),        col = c(\"#8B0000\", \"#006400\"),        pch = c(19, 17), bty = \"n\") grid(col = \"gray90\")    ## Example 6: Score Test Statistic  # Score test for H0: theta = theta0 theta0 <- c(2, 3) score_theta0 <- -grkw(par = theta0, data = data)  # Score is negative gradient  # Fisher information at theta0 (using Hessian) fisher_info <- hskw(par = theta0, data = data)  # Score test statistic score_stat <- t(score_theta0) %*% solve(fisher_info) %*% score_theta0 p_value <- pchisq(score_stat, df = 2, lower.tail = FALSE)  cat(\"\\nScore Test:\\n\") #>  #> Score Test: cat(\"H0: alpha = 2, beta = 3\\n\") #> H0: alpha = 2, beta = 3 cat(\"Score vector:\", score_theta0, \"\\n\") #> Score vector: 170.1849 -42.66137  cat(\"Test statistic:\", score_stat, \"\\n\") #> Test statistic: 55.14706  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 1.059e-12   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/grmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","title":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","text":"Computes gradient vector (vector first partial derivatives) negative log-likelihood function McDonald (Mc) distribution (also known Beta Power) parameters gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\alpha = 1\\) \\(\\beta = 1\\). gradient useful optimization.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","text":"","code":"grmc(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/grmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","text":"par numeric vector length 3 containing distribution parameters order: gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","text":"Returns numeric vector length 3 containing partial derivatives negative log-likelihood function \\(-\\ell(\\theta | \\mathbf{x})\\) respect parameter: \\((-\\partial \\ell/\\partial \\gamma, -\\partial \\ell/\\partial \\delta, -\\partial \\ell/\\partial \\lambda)\\). Returns vector NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","text":"components gradient vector negative log-likelihood (\\(-\\nabla \\ell(\\theta | \\mathbf{x})\\)) Mc (\\(\\alpha=1, \\beta=1\\)) model : $$ -\\frac{\\partial \\ell}{\\partial \\gamma} = n[\\psi(\\gamma+\\delta+1) - \\psi(\\gamma)] - \\lambda\\sum_{=1}^{n}\\ln(x_i) $$ $$ -\\frac{\\partial \\ell}{\\partial \\delta} = n[\\psi(\\gamma+\\delta+1) - \\psi(\\delta+1)] - \\sum_{=1}^{n}\\ln(1-x_i^{\\lambda}) $$ $$ -\\frac{\\partial \\ell}{\\partial \\lambda} = -\\frac{n}{\\lambda} - \\gamma\\sum_{=1}^{n}\\ln(x_i) + \\delta\\sum_{=1}^{n}\\frac{x_i^{\\lambda}\\ln(x_i)}{1-x_i^{\\lambda}} $$ \\(\\psi(\\cdot)\\) digamma function (digamma). formulas represent derivatives \\(-\\ell(\\theta)\\), consistent minimizing negative log-likelihood. correspond relevant components general GKw gradient (grgkw) evaluated \\(\\alpha=1, \\beta=1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","text":"McDonald, J. B. (1984). generalized functions size distribution income. Econometrica, 52(3), 647-663. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, (Note: Specific gradient formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/grmc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/grmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — grmc","text":"","code":"# \\donttest{ # Assuming existence of rmc, llmc, grmc, hsmc functions for Mc distribution  # Generate sample data set.seed(123) true_par_mc <- c(gamma = 2, delta = 3, lambda = 0.5) sample_data_mc <- rmc(100, gamma = true_par_mc[1], delta = true_par_mc[2],                       lambda = true_par_mc[3]) hist(sample_data_mc, breaks = 20, main = \"Mc(2, 3, 0.5) Sample\")   # --- Find MLE estimates --- start_par_mc <- c(1.5, 2.5, 0.8) mle_result_mc <- stats::optim(par = start_par_mc,                               fn = llmc,                               gr = grmc, # Use analytical gradient for Mc                               method = \"BFGS\",                               hessian = TRUE,                               data = sample_data_mc)  # --- Compare analytical gradient to numerical gradient --- if (mle_result_mc$convergence == 0 &&     requireNamespace(\"numDeriv\", quietly = TRUE)) {    mle_par_mc <- mle_result_mc$par   cat(\"\\nComparing Gradients for Mc at MLE estimates:\\n\")    # Numerical gradient of llmc   num_grad_mc <- numDeriv::grad(func = llmc, x = mle_par_mc, data = sample_data_mc)    # Analytical gradient from grmc   ana_grad_mc <- grmc(par = mle_par_mc, data = sample_data_mc)    cat(\"Numerical Gradient (Mc):\\n\")   print(num_grad_mc)   cat(\"Analytical Gradient (Mc):\\n\")   print(ana_grad_mc)    # Check differences   cat(\"Max absolute difference between Mc gradients:\\n\")   print(max(abs(num_grad_mc - ana_grad_mc)))  } else {   cat(\"\\nSkipping Mc gradient comparison.\\n\") } #>  #> Comparing Gradients for Mc at MLE estimates: #> Numerical Gradient (Mc): #> [1] -0.0090383310 -0.0008723594 -0.0061479778 #> Analytical Gradient (Mc): #> [1] -0.0090383286 -0.0008723581 -0.0061479812 #> Max absolute difference between Mc gradients: #> [1] 3.31495e-09  # Example with Hessian comparison (if hsmc exists) if (mle_result_mc$convergence == 0 &&     requireNamespace(\"numDeriv\", quietly = TRUE) && exists(\"hsmc\")) {    num_hess_mc <- numDeriv::hessian(func = llmc, x = mle_par_mc, data = sample_data_mc)   ana_hess_mc <- hsmc(par = mle_par_mc, data = sample_data_mc)   cat(\"\\nMax absolute difference between Mc Hessians:\\n\")   print(max(abs(num_hess_mc - ana_hess_mc)))  } #>  #> Max absolute difference between Mc Hessians: #> [1] 1.039143e-08  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbeta.html","id":null,"dir":"Reference","previous_headings":"","what":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","title":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","text":"Computes analytic 2x2 Hessian matrix (matrix second partial derivatives) negative log-likelihood function standard Beta distribution, using parameterization common generalized distribution families. distribution parameterized gamma (\\(\\gamma\\)) delta (\\(\\delta\\)), corresponding standard Beta distribution shape parameters shape1 = gamma shape2 = delta + 1. Hessian useful estimating standard errors optimization algorithms.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbeta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","text":"","code":"hsbeta(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbeta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","text":"par numeric vector length 2 containing distribution parameters order: gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbeta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","text":"Returns 2x2 numeric matrix representing Hessian matrix negative log-likelihood function, \\(-\\partial^2 \\ell / (\\partial \\theta_i \\partial \\theta_j)\\), \\(\\theta = (\\gamma, \\delta)\\). Returns 2x2 matrix populated NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbeta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","text":"function calculates analytic second partial derivatives negative log-likelihood function (\\(-\\ell(\\theta|\\mathbf{x})\\)) Beta distribution parameters shape1 = gamma (\\(\\gamma\\)) shape2 = delta + 1 (\\(\\delta+1\\)). components Hessian matrix (\\(-\\mathbf{H}(\\theta)\\)) : $$ -\\frac{\\partial^2 \\ell}{\\partial \\gamma^2} = n[\\psi'(\\gamma) - \\psi'(\\gamma+\\delta+1)] $$ $$ -\\frac{\\partial^2 \\ell}{\\partial \\gamma \\partial \\delta} = -n\\psi'(\\gamma+\\delta+1) $$ $$ -\\frac{\\partial^2 \\ell}{\\partial \\delta^2} = n[\\psi'(\\delta+1) - \\psi'(\\gamma+\\delta+1)] $$ \\(\\psi'(\\cdot)\\) trigamma function (trigamma). formulas represent second derivatives \\(-\\ell(\\theta)\\), consistent minimizing negative log-likelihood. correspond relevant 2x2 submatrix general GKw Hessian (hsgkw) evaluated \\(\\alpha=1, \\beta=1, \\lambda=1\\). Note parameterization difference standard Beta distribution (shape2 = delta + 1). returned matrix symmetric.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbeta.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","text":"Johnson, N. L., Kotz, S., & Balakrishnan, N. (1995). Continuous Univariate Distributions, Volume 2 (2nd ed.). Wiley. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, (Note: Specific Hessian formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbeta.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbeta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hessian Matrix of the Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — hsbeta","text":"","code":"# \\donttest{ ## Example 1: Basic Hessian Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(gamma = 2.0, delta = 3.0) data <- rbeta_(n, gamma = true_params[1], delta = true_params[2])  # Evaluate Hessian at true parameters hess_true <- hsbeta(par = true_params, data = data) cat(\"Hessian matrix at true parameters:\\n\") #> Hessian matrix at true parameters: print(hess_true, digits = 4) #>        [,1]   [,2] #> [1,]  463.6 -181.3 #> [2,] -181.3  102.5  # Check symmetry cat(\"\\nSymmetry check (max |H - H^T|):\",     max(abs(hess_true - t(hess_true))), \"\\n\") #>  #> Symmetry check (max |H - H^T|): 0    ## Example 2: Hessian Properties at MLE  # Fit model fit <- optim(   par = c(1.5, 2.5),   fn = llbeta,   gr = grbeta,   data = data,   method = \"L-BFGS-B\",   lower = c(0.01, 0.01),   upper = c(100, 100),   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"gamma\", \"delta\")  # Hessian at MLE hessian_at_mle <- hsbeta(par = mle, data = data) cat(\"\\nHessian at MLE:\\n\") #>  #> Hessian at MLE: print(hessian_at_mle, digits = 4) #>        [,1]   [,2] #> [1,]  453.1 -180.5 #> [2,] -180.5  103.6  # Compare with optim's numerical Hessian cat(\"\\nComparison with optim Hessian:\\n\") #>  #> Comparison with optim Hessian: cat(\"Max absolute difference:\",     max(abs(hessian_at_mle - fit$hessian)), \"\\n\") #> Max absolute difference: 7.627406e-05   # Eigenvalue analysis eigenvals <- eigen(hessian_at_mle, only.values = TRUE)$values cat(\"\\nEigenvalues:\\n\") #>  #> Eigenvalues: print(eigenvals) #> [1] 529.51472  27.09873  cat(\"\\nPositive definite:\", all(eigenvals > 0), \"\\n\") #>  #> Positive definite: TRUE  cat(\"Condition number:\", max(eigenvals) / min(eigenvals), \"\\n\") #> Condition number: 19.54021    ## Example 3: Standard Errors and Confidence Intervals  # Observed information matrix obs_info <- hessian_at_mle  # Variance-covariance matrix vcov_matrix <- solve(obs_info) cat(\"\\nVariance-Covariance Matrix:\\n\") #>  #> Variance-Covariance Matrix: print(vcov_matrix, digits = 6) #>           [,1]      [,2] #> [1,] 0.0072172 0.0125770 #> [2,] 0.0125770 0.0315734  # Standard errors se <- sqrt(diag(vcov_matrix)) names(se) <- c(\"gamma\", \"delta\")  # Correlation matrix corr_matrix <- cov2cor(vcov_matrix) cat(\"\\nCorrelation Matrix:\\n\") #>  #> Correlation Matrix: print(corr_matrix, digits = 4) #>        [,1]   [,2] #> [1,] 1.0000 0.8332 #> [2,] 0.8332 1.0000  # Confidence intervals z_crit <- qnorm(0.975) results <- data.frame(   Parameter = c(\"gamma\", \"delta\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - z_crit * se,   CI_Upper = mle + z_crit * se ) print(results, digits = 4) #>       Parameter True   MLE      SE CI_Lower CI_Upper #> gamma     gamma    2 2.029 0.08495    1.862    2.195 #> delta     delta    3 2.997 0.17769    2.649    3.346  cat(sprintf(\"\\nMLE corresponds approx to Beta(%.2f, %.2f)\\n\",     mle[1], mle[2] + 1)) #>  #> MLE corresponds approx to Beta(2.03, 4.00) cat(\"True corresponds to Beta(%.2f, %.2f)\\n\",     true_params[1], true_params[2] + 1) #> True corresponds to Beta(%.2f, %.2f) #>  2 4   ## Example 4: Determinant and Trace Analysis  # Compute at different points test_params <- rbind(   c(1.5, 2.5),   c(2.0, 3.0),   mle,   c(2.5, 3.5) )  hess_properties <- data.frame(   Gamma = numeric(),   Delta = numeric(),   Determinant = numeric(),   Trace = numeric(),   Min_Eigenval = numeric(),   Max_Eigenval = numeric(),   Cond_Number = numeric(),   stringsAsFactors = FALSE )  for (i in 1:nrow(test_params)) {   H <- hsbeta(par = test_params[i, ], data = data)   eigs <- eigen(H, only.values = TRUE)$values    hess_properties <- rbind(hess_properties, data.frame(     Gamma = test_params[i, 1],     Delta = test_params[i, 2],     Determinant = det(H),     Trace = sum(diag(H)),     Min_Eigenval = min(eigs),     Max_Eigenval = max(eigs),     Cond_Number = max(eigs) / min(eigs)   )) }  cat(\"\\nHessian Properties at Different Points:\\n\") #>  #> Hessian Properties at Different Points: print(hess_properties, digits = 4, row.names = FALSE) #>  Gamma Delta Determinant Trace Min_Eigenval Max_Eigenval Cond_Number #>  1.500 2.500       28810 822.5        36.66        785.9       21.44 #>  2.000 3.000       14642 566.1        27.17        538.9       19.84 #>  2.029 2.997       14349 556.6        27.10        529.5       19.54 #>  2.500 3.500        8482 432.0        20.62        411.4       19.95   ## Example 5: Curvature Visualization (Gamma vs Delta)  # Create grid around MLE gamma_grid <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = 25) delta_grid <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = 25) gamma_grid <- gamma_grid[gamma_grid > 0] delta_grid <- delta_grid[delta_grid > 0]  # Compute curvature measures determinant_surface <- matrix(NA, nrow = length(gamma_grid),                                ncol = length(delta_grid)) trace_surface <- matrix(NA, nrow = length(gamma_grid),                          ncol = length(delta_grid))  for (i in seq_along(gamma_grid)) {   for (j in seq_along(delta_grid)) {     H <- hsbeta(c(gamma_grid[i], delta_grid[j]), data)     determinant_surface[i, j] <- det(H)     trace_surface[i, j] <- sum(diag(H))   } }  # Plot par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  contour(gamma_grid, delta_grid, determinant_surface,         xlab = expression(gamma), ylab = expression(delta),         main = \"Hessian Determinant\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(gamma_grid, delta_grid, trace_surface,         xlab = expression(gamma), ylab = expression(delta),         main = \"Hessian Trace\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")   ## Example 6: Confidence Ellipse (Gamma vs Delta)  # Extract 2x2 submatrix (full matrix in this case) vcov_2d <- vcov_matrix  # Create confidence ellipse theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  eig_decomp <- eigen(vcov_2d) ellipse <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Marginal confidence intervals se_2d <- sqrt(diag(vcov_2d)) ci_gamma <- mle[1] + c(-1, 1) * 1.96 * se_2d[1] ci_delta <- mle[2] + c(-1, 1) * 1.96 * se_2d[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = expression(delta),      main = \"95% Confidence Ellipse (Gamma vs Delta)\", las = 1)  # Add marginal CIs abline(v = ci_gamma, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_delta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","title":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","text":"Computes analytic 4x4 Hessian matrix (matrix second partial derivatives) negative log-likelihood function Beta-Kumaraswamy (BKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\lambda = 1\\). Hessian useful estimating standard errors optimization algorithms.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","text":"","code":"hsbkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","text":"par numeric vector length 4 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","text":"Returns 4x4 numeric matrix representing Hessian matrix negative log-likelihood function, \\(-\\partial^2 \\ell / (\\partial \\theta_i \\partial \\theta_j)\\), \\(\\theta = (\\alpha, \\beta, \\gamma, \\delta)\\). Returns 4x4 matrix populated NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","text":"function calculates analytic second partial derivatives negative log-likelihood function based BKw log-likelihood (\\(\\lambda=1\\) case GKw, see llbkw): $$ \\ell(\\theta | \\mathbf{x}) = n[\\ln(\\alpha) + \\ln(\\beta) - \\ln B(\\gamma, \\delta+1)] + \\sum_{=1}^{n} [(\\alpha-1)\\ln(x_i) + (\\beta(\\delta+1)-1)\\ln(v_i) + (\\gamma-1)\\ln(w_i)] $$ \\(\\theta = (\\alpha, \\beta, \\gamma, \\delta)\\), \\(B(,b)\\) Beta function (beta), intermediate terms : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) Hessian matrix returned contains elements \\(- \\frac{\\partial^2 \\ell(\\theta | \\mathbf{x})}{\\partial \\theta_i \\partial \\theta_j}\\) \\(\\theta_i, \\theta_j \\\\{\\alpha, \\beta, \\gamma, \\delta\\}\\). Key properties returned matrix: Dimensions: 4x4. Symmetry: matrix symmetric. Ordering: Rows columns correspond parameters order \\(\\alpha, \\beta, \\gamma, \\delta\\). Content: Analytic second derivatives negative log-likelihood. corresponds relevant 4x4 submatrix 5x5 GKw Hessian (hsgkw) evaluated \\(\\lambda=1\\). exact analytical formulas implemented directly.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. (Note: Specific Hessian formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsbkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hessian Matrix of the Negative Log-Likelihood for the BKw Distribution — hsbkw","text":"","code":"# \\donttest{ ## Example 1: Basic Hessian Evaluation  # Generate sample data set.seed(2203) n <- 1000 true_params <- c(alpha = 2.0, beta = 1.5, gamma = 1.5, delta = 0.5) data <- rbkw(n, alpha = true_params[1], beta = true_params[2],              gamma = true_params[3], delta = true_params[4])  # Evaluate Hessian at true parameters hess_true <- hsbkw(par = true_params, data = data) cat(\"Hessian matrix at true parameters:\\n\") #> Hessian matrix at true parameters: print(hess_true, digits = 4) #>        [,1]   [,2]   [,3]   [,4] #> [1,]  536.6 -465.2  552.9 -418.2 #> [2,] -465.2  648.7 -447.0  563.2 #> [3,]  552.9 -447.0  539.9 -394.9 #> [4,] -418.2  563.2 -394.9  539.9  # Check symmetry cat(\"\\nSymmetry check (max |H - H^T|):\",     max(abs(hess_true - t(hess_true))), \"\\n\") #>  #> Symmetry check (max |H - H^T|): 0    ## Example 2: Hessian Properties at MLE  # Fit model fit <- optim(   par = c(1.8, 1.2, 1.1, 0.3),   fn = llbkw,   gr = grbkw,   data = data,   method = \"Nelder-Mead\",   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\", \"gamma\", \"delta\")  # Hessian at MLE hessian_at_mle <- hsbkw(par = mle, data = data) cat(\"\\nHessian at MLE:\\n\") #>  #> Hessian at MLE: print(hessian_at_mle, digits = 4) #>        [,1]   [,2]   [,3]   [,4] #> [1,]  337.7 -205.4  516.6 -433.8 #> [2,] -205.4  203.8 -273.5  433.1 #> [3,]  516.6 -273.5  816.6 -576.4 #> [4,] -433.8  433.1 -576.4  920.9  # Compare with optim's numerical Hessian cat(\"\\nComparison with optim Hessian:\\n\") #>  #> Comparison with optim Hessian: cat(\"Max absolute difference:\",     max(abs(hessian_at_mle - fit$hessian)), \"\\n\") #> Max absolute difference: 0.0007850156   # Eigenvalue analysis eigenvals <- eigen(hessian_at_mle, only.values = TRUE)$values cat(\"\\nEigenvalues:\\n\") #>  #> Eigenvalues: print(eigenvals) #> [1] 1932.6299085  345.0426785    1.2086682    0.1217554  cat(\"\\nPositive definite:\", all(eigenvals > 0), \"\\n\") #>  #> Positive definite: TRUE  cat(\"Condition number:\", max(eigenvals) / min(eigenvals), \"\\n\") #> Condition number: 15873.05    ## Example 3: Standard Errors and Confidence Intervals  # Observed information matrix obs_info <- hessian_at_mle  # Variance-covariance matrix vcov_matrix <- solve(obs_info) cat(\"\\nVariance-Covariance Matrix:\\n\") #>  #> Variance-Covariance Matrix: print(vcov_matrix, digits = 6) #>             [,1]       [,2]       [,3]        [,4] #> [1,]  0.63827083  0.1882004 -0.3421762 -0.00197877 #> [2,]  0.18820037  6.7563286 -0.0657884 -3.13009829 #> [3,] -0.34217618 -0.0657884  0.1858182 -0.01396138 #> [4,] -0.00197877 -3.1300983 -0.0139614  1.46353994  # Standard errors se <- sqrt(diag(vcov_matrix)) names(se) <- c(\"alpha\", \"beta\", \"gamma\", \"delta\")  # Correlation matrix corr_matrix <- cov2cor(vcov_matrix) cat(\"\\nCorrelation Matrix:\\n\") #>  #> Correlation Matrix: print(corr_matrix, digits = 4) #>           [,1]     [,2]     [,3]      [,4] #> [1,]  1.000000  0.09063 -0.99358 -0.002047 #> [2,]  0.090628  1.00000 -0.05872 -0.995406 #> [3,] -0.993581 -0.05872  1.00000 -0.026772 #> [4,] -0.002047 -0.99541 -0.02677  1.000000  # Confidence intervals z_crit <- qnorm(0.975) results <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"gamma\", \"delta\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - z_crit * se,   CI_Upper = mle + z_crit * se ) print(results, digits = 4) #>       Parameter True     MLE     SE CI_Lower CI_Upper #> alpha     alpha  2.0 2.57049 0.7989   1.0046    4.136 #> beta       beta  1.5 2.33192 2.5993  -2.7626    7.426 #> gamma     gamma  1.5 1.12226 0.4311   0.2774    1.967 #> delta     delta  0.5 0.06702 1.2098  -2.3041    2.438   ## Example 4: Determinant and Trace Analysis  # Compute at different points test_params <- rbind(   c(1.5, 1.0, 1.0, 0.3),   c(2.0, 1.5, 1.5, 0.5),   mle,   c(2.5, 2.0, 2.0, 0.7) )  hess_properties <- data.frame(   Alpha = numeric(),   Beta = numeric(),   Gamma = numeric(),   Delta = numeric(),   Determinant = numeric(),   Trace = numeric(),   Min_Eigenval = numeric(),   Max_Eigenval = numeric(),   Cond_Number = numeric(),   stringsAsFactors = FALSE )  for (i in 1:nrow(test_params)) {   H <- hsbkw(par = test_params[i, ], data = data)   eigs <- eigen(H, only.values = TRUE)$values    hess_properties <- rbind(hess_properties, data.frame(     Alpha = test_params[i, 1],     Beta = test_params[i, 2],     Gamma = test_params[i, 3],     Delta = test_params[i, 4],     Determinant = det(H),     Trace = sum(diag(H)),     Min_Eigenval = min(eigs),     Max_Eigenval = max(eigs),     Cond_Number = max(eigs) / min(eigs)   )) }  cat(\"\\nHessian Properties at Different Points:\\n\") #>  #> Hessian Properties at Different Points: print(hess_properties, digits = 4, row.names = FALSE) #>  Alpha  Beta Gamma   Delta Determinant Trace Min_Eigenval Max_Eigenval #>   1.50 1.000 1.000 0.30000  -6.191e+10  3261    -134.1926         2027 #>   2.00 1.500 1.500 0.50000  -2.362e+08  2265     -15.8487         1990 #>   2.57 2.332 1.122 0.06702   9.813e+04  2279       0.1218         1933 #>   2.50 2.000 2.000 0.70000  -1.510e+09  1805    -118.6118         1662 #>  Cond_Number #>       -15.10 #>      -125.59 #>     15873.05 #>       -14.01   ## Example 5: Curvature Visualization (Selected pairs)  # Create grids around MLE with wider range (±1.5) alpha_grid <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = 25) beta_grid <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = 25) gamma_grid <- seq(mle[3] - 1.5, mle[3] + 1.5, length.out = 25) delta_grid <- seq(mle[4] - 1.5, mle[4] + 1.5, length.out = 25)  alpha_grid <- alpha_grid[alpha_grid > 0] beta_grid <- beta_grid[beta_grid > 0] gamma_grid <- gamma_grid[gamma_grid > 0] delta_grid <- delta_grid[delta_grid > 0]  # Compute curvature measures for selected pairs determinant_surface_ab <- matrix(NA, nrow = length(alpha_grid), ncol = length(beta_grid)) trace_surface_ab <- matrix(NA, nrow = length(alpha_grid), ncol = length(beta_grid))  determinant_surface_ag <- matrix(NA, nrow = length(alpha_grid), ncol = length(gamma_grid)) trace_surface_ag <- matrix(NA, nrow = length(alpha_grid), ncol = length(gamma_grid))  determinant_surface_bd <- matrix(NA, nrow = length(beta_grid), ncol = length(delta_grid)) trace_surface_bd <- matrix(NA, nrow = length(beta_grid), ncol = length(delta_grid))  # Alpha vs Beta for (i in seq_along(alpha_grid)) {   for (j in seq_along(beta_grid)) {     H <- hsbkw(c(alpha_grid[i], beta_grid[j], mle[3], mle[4]), data)     determinant_surface_ab[i, j] <- det(H)     trace_surface_ab[i, j] <- sum(diag(H))   } }  # Alpha vs Gamma for (i in seq_along(alpha_grid)) {   for (j in seq_along(gamma_grid)) {     H <- hsbkw(c(alpha_grid[i], mle[2], gamma_grid[j], mle[4]), data)     determinant_surface_ag[i, j] <- det(H)     trace_surface_ag[i, j] <- sum(diag(H))   } }  # Beta vs Delta for (i in seq_along(beta_grid)) {   for (j in seq_along(delta_grid)) {     H <- hsbkw(c(mle[1], beta_grid[i], mle[3], delta_grid[j]), data)     determinant_surface_bd[i, j] <- det(H)     trace_surface_bd[i, j] <- sum(diag(H))   } }  # Plot selected curvature surfaces par(mfrow = c(2, 3), mar = c(4, 4, 3, 1))  # Determinant plots contour(alpha_grid, beta_grid, determinant_surface_ab,         xlab = expression(alpha), ylab = expression(beta),         main = \"Determinant: Alpha vs Beta\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(alpha_grid, gamma_grid, determinant_surface_ag,         xlab = expression(alpha), ylab = expression(gamma),         main = \"Determinant: Alpha vs Gamma\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(beta_grid, delta_grid, determinant_surface_bd,         xlab = expression(beta), ylab = expression(delta),         main = \"Determinant: Beta vs Delta\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[2], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[4], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Trace plots contour(alpha_grid, beta_grid, trace_surface_ab,         xlab = expression(alpha), ylab = expression(beta),         main = \"Trace: Alpha vs Beta\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(alpha_grid, gamma_grid, trace_surface_ag,         xlab = expression(alpha), ylab = expression(gamma),         main = \"Trace: Alpha vs Gamma\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(beta_grid, delta_grid, trace_surface_bd,         xlab = expression(beta), ylab = expression(delta),         main = \"Trace: Beta vs Delta\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[2], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[4], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  legend(\"topright\",        legend = c(\"MLE\", \"True\"),        col = c(\"#8B0000\", \"#006400\"),        pch = c(19, 17),        bty = \"n\", cex = 0.8)   par(mfrow = c(1, 1))   ## Example 6: Confidence Ellipses (Selected pairs)  # Extract selected 2x2 submatrices vcov_ab <- vcov_matrix[1:2, 1:2] vcov_ag <- vcov_matrix[c(1, 3), c(1, 3)] vcov_bd <- vcov_matrix[c(2, 4), c(2, 4)]  # Create confidence ellipses theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  # Alpha vs Beta ellipse eig_decomp_ab <- eigen(vcov_ab) ellipse_ab <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_ab[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp_ab$vectors %*% diag(sqrt(eig_decomp_ab$values)) %*% v) }  # Alpha vs Gamma ellipse eig_decomp_ag <- eigen(vcov_ag) ellipse_ag <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_ag[i, ] <- mle[c(1, 3)] + sqrt(chi2_val) *     (eig_decomp_ag$vectors %*% diag(sqrt(eig_decomp_ag$values)) %*% v) }  # Beta vs Delta ellipse eig_decomp_bd <- eigen(vcov_bd) ellipse_bd <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_bd[i, ] <- mle[c(2, 4)] + sqrt(chi2_val) *     (eig_decomp_bd$vectors %*% diag(sqrt(eig_decomp_bd$values)) %*% v) }  # Marginal confidence intervals se_ab <- sqrt(diag(vcov_ab)) ci_alpha_ab <- mle[1] + c(-1, 1) * 1.96 * se_ab[1] ci_beta_ab <- mle[2] + c(-1, 1) * 1.96 * se_ab[2]  se_ag <- sqrt(diag(vcov_ag)) ci_alpha_ag <- mle[1] + c(-1, 1) * 1.96 * se_ag[1] ci_gamma_ag <- mle[3] + c(-1, 1) * 1.96 * se_ag[2]  se_bd <- sqrt(diag(vcov_bd)) ci_beta_bd <- mle[2] + c(-1, 1) * 1.96 * se_bd[1] ci_delta_bd <- mle[4] + c(-1, 1) * 1.96 * se_bd[2]  # Plot selected ellipses side by side par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Alpha vs Beta plot(ellipse_ab[, 1], ellipse_ab[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"Alpha vs Beta\", las = 1, xlim = range(ellipse_ab[, 1], ci_alpha_ab),      ylim = range(ellipse_ab[, 2], ci_beta_ab)) abline(v = ci_alpha_ab, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_beta_ab, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Alpha vs Gamma plot(ellipse_ag[, 1], ellipse_ag[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(gamma),      main = \"Alpha vs Gamma\", las = 1, xlim = range(ellipse_ag[, 1], ci_alpha_ag),      ylim = range(ellipse_ag[, 2], ci_gamma_ag)) abline(v = ci_alpha_ag, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_gamma_ag, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Beta vs Delta plot(ellipse_bd[, 1], ellipse_bd[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = expression(delta),      main = \"Beta vs Delta\", las = 1, xlim = range(ellipse_bd[, 1], ci_beta_bd),      ylim = range(ellipse_bd[, 2], ci_delta_bd)) abline(v = ci_beta_bd, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_delta_bd, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[2], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[4], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\", cex = 0.8)   par(mfrow = c(1, 1))  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsekw.html","id":null,"dir":"Reference","previous_headings":"","what":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","title":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","text":"Computes analytic 3x3 Hessian matrix (matrix second partial derivatives) negative log-likelihood function Exponentiated Kumaraswamy (EKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\) \\(\\delta = 0\\). Hessian useful estimating standard errors optimization algorithms.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsekw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","text":"","code":"hsekw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsekw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","text":"par numeric vector length 3 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsekw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","text":"Returns 3x3 numeric matrix representing Hessian matrix negative log-likelihood function, \\(-\\partial^2 \\ell / (\\partial \\theta_i \\partial \\theta_j)\\), \\(\\theta = (\\alpha, \\beta, \\lambda)\\). Returns 3x3 matrix populated NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsekw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","text":"function calculates analytic second partial derivatives negative log-likelihood function based EKw log-likelihood (\\(\\gamma=1, \\delta=0\\) case GKw, see llekw): $$ \\ell(\\theta | \\mathbf{x}) = n[\\ln(\\lambda) + \\ln(\\alpha) + \\ln(\\beta)] + \\sum_{=1}^{n} [(\\alpha-1)\\ln(x_i) + (\\beta-1)\\ln(v_i) + (\\lambda-1)\\ln(w_i)] $$ \\(\\theta = (\\alpha, \\beta, \\lambda)\\) intermediate terms : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) Hessian matrix returned contains elements \\(- \\frac{\\partial^2 \\ell(\\theta | \\mathbf{x})}{\\partial \\theta_i \\partial \\theta_j}\\) \\(\\theta_i, \\theta_j \\\\{\\alpha, \\beta, \\lambda\\}\\). Key properties returned matrix: Dimensions: 3x3. Symmetry: matrix symmetric. Ordering: Rows columns correspond parameters order \\(\\alpha, \\beta, \\lambda\\). Content: Analytic second derivatives negative log-likelihood. corresponds relevant 3x3 submatrix 5x5 GKw Hessian (hsgkw) evaluated \\(\\gamma=1, \\delta=0\\). exact analytical formulas implemented directly.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsekw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","text":"Nadarajah, S., Cordeiro, G. M., & Ortega, E. M. (2012). exponentiated Kumaraswamy distribution. Journal Franklin Institute, 349(3), Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. (Note: Specific Hessian formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/hsekw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsekw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hessian Matrix of the Negative Log-Likelihood for the EKw Distribution — hsekw","text":"","code":"# \\donttest{ ## Example 1: Basic Hessian Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.5, beta = 3.5, lambda = 2.0) data <- rekw(n, alpha = true_params[1], beta = true_params[2],              lambda = true_params[3])  # Evaluate Hessian at true parameters hess_true <- hsekw(par = true_params, data = data) cat(\"Hessian matrix at true parameters:\\n\") #> Hessian matrix at true parameters: print(hess_true, digits = 4) #>        [,1]   [,2]   [,3] #> [1,]  580.9 -252.7  373.8 #> [2,] -252.7  147.8 -143.5 #> [3,]  373.8 -143.5  250.0  # Check symmetry cat(\"\\nSymmetry check (max |H - H^T|):\",     max(abs(hess_true - t(hess_true))), \"\\n\") #>  #> Symmetry check (max |H - H^T|): 0    ## Example 2: Hessian Properties at MLE  # Fit model fit <- optim(   par = c(2, 3, 1.5),   fn = llekw,   gr = grekw,   data = data,   method = \"BFGS\",   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\", \"lambda\")  # Hessian at MLE hessian_at_mle <- hsekw(par = mle, data = data) cat(\"\\nHessian at MLE:\\n\") #>  #> Hessian at MLE: print(hessian_at_mle, digits = 4) #>        [,1]   [,2]   [,3] #> [1,]  516.8 -220.6  379.5 #> [2,] -220.6  126.7 -141.6 #> [3,]  379.5 -141.6  294.5  # Compare with optim's numerical Hessian cat(\"\\nComparison with optim Hessian:\\n\") #>  #> Comparison with optim Hessian: cat(\"Max absolute difference:\",     max(abs(hessian_at_mle - fit$hessian)), \"\\n\") #> Max absolute difference: 8.670364e-05   # Eigenvalue analysis eigenvals <- eigen(hessian_at_mle, only.values = TRUE)$values cat(\"\\nEigenvalues:\\n\") #>  #> Eigenvalues: print(eigenvals) #> [1] 890.657538  46.071259   1.226785  cat(\"\\nPositive definite:\", all(eigenvals > 0), \"\\n\") #>  #> Positive definite: TRUE  cat(\"Condition number:\", max(eigenvals) / min(eigenvals), \"\\n\") #> Condition number: 726.0095    ## Example 3: Standard Errors and Confidence Intervals  # Observed information matrix obs_info <- hessian_at_mle  # Variance-covariance matrix vcov_matrix <- solve(obs_info) cat(\"\\nVariance-Covariance Matrix:\\n\") #>  #> Variance-Covariance Matrix: print(vcov_matrix, digits = 6) #>           [,1]      [,2]      [,3] #> [1,]  0.342459  0.222633 -0.334305 #> [2,]  0.222633  0.161814 -0.209116 #> [3,] -0.334305 -0.209116  0.333694  # Standard errors se <- sqrt(diag(vcov_matrix)) names(se) <- c(\"alpha\", \"beta\", \"lambda\")  # Correlation matrix corr_matrix <- cov2cor(vcov_matrix) cat(\"\\nCorrelation Matrix:\\n\") #>  #> Correlation Matrix: print(corr_matrix, digits = 4) #>         [,1]    [,2]    [,3] #> [1,]  1.0000  0.9458 -0.9889 #> [2,]  0.9458  1.0000 -0.8999 #> [3,] -0.9889 -0.8999  1.0000  # Confidence intervals z_crit <- qnorm(0.975) results <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"lambda\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - z_crit * se,   CI_Upper = mle + z_crit * se ) print(results, digits = 4) #>        Parameter True   MLE     SE CI_Lower CI_Upper #> alpha      alpha  2.5 2.663 0.5852   1.5156    3.810 #> beta        beta  3.5 3.653 0.4023   2.8643    4.441 #> lambda    lambda  2.0 1.843 0.5777   0.7107    2.975   ## Example 4: Determinant and Trace Analysis  # Compute at different points test_params <- rbind(   c(2.0, 3.0, 1.5),   c(2.5, 3.5, 2.0),   mle,   c(3.0, 4.0, 2.5) )  hess_properties <- data.frame(   Alpha = numeric(),   Beta = numeric(),   Lambda = numeric(),   Determinant = numeric(),   Trace = numeric(),   Min_Eigenval = numeric(),   Max_Eigenval = numeric(),   Cond_Number = numeric(),   stringsAsFactors = FALSE )  for (i in 1:nrow(test_params)) {   H <- hsekw(par = test_params[i, ], data = data)   eigs <- eigen(H, only.values = TRUE)$values    hess_properties <- rbind(hess_properties, data.frame(     Alpha = test_params[i, 1],     Beta = test_params[i, 2],     Lambda = test_params[i, 3],     Determinant = det(H),     Trace = sum(diag(H)),     Min_Eigenval = min(eigs),     Max_Eigenval = max(eigs),     Cond_Number = max(eigs) / min(eigs)   )) }  cat(\"\\nHessian Properties at Different Points:\\n\") #>  #> Hessian Properties at Different Points: print(hess_properties, digits = 4, row.names = FALSE) #>  Alpha  Beta Lambda Determinant  Trace Min_Eigenval Max_Eigenval Cond_Number #>  2.000 3.000  1.500     2892647 1346.0      11.8385       1115.0      94.187 #>  2.500 3.500  2.000       -4566  978.7      -0.1039        931.7   -8963.582 #>  2.663 3.653  1.843       50340  938.0       1.2268        890.7     726.010 #>  3.000 4.000  2.500    -4431331  780.2    -101.4440        829.0      -8.172   ## Example 5: Curvature Visualization (Alpha vs Beta)  # Create grid around MLE alpha_grid <- seq(mle[1] - 0.5, mle[1] + 0.5, length.out = 25) beta_grid <- seq(mle[2] - 0.5, mle[2] + 0.5, length.out = 25) alpha_grid <- alpha_grid[alpha_grid > 0] beta_grid <- beta_grid[beta_grid > 0]  # Compute curvature measures determinant_surface <- matrix(NA, nrow = length(alpha_grid),                                ncol = length(beta_grid)) trace_surface <- matrix(NA, nrow = length(alpha_grid),                          ncol = length(beta_grid))  for (i in seq_along(alpha_grid)) {   for (j in seq_along(beta_grid)) {     H <- hsekw(c(alpha_grid[i], beta_grid[j], mle[3]), data)     determinant_surface[i, j] <- det(H)     trace_surface[i, j] <- sum(diag(H))   } }  # Plot par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))  contour(alpha_grid, beta_grid, determinant_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"Hessian Determinant\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(alpha_grid, beta_grid, trace_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"Hessian Trace\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  par(mfrow = c(1,1))  ## Example 6: Confidence Ellipse (Alpha vs Beta) par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Extract 2x2 submatrix for alpha and beta vcov_2d <- vcov_matrix[1:2, 1:2]  # Create confidence ellipse theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  eig_decomp <- eigen(vcov_2d) ellipse <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Marginal confidence intervals se_2d <- sqrt(diag(vcov_2d)) ci_alpha <- mle[1] + c(-1, 1) * 1.96 * se_2d[1] ci_beta <- mle[2] + c(-1, 1) * 1.96 * se_2d[2]  # Plot # par(mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"95% Confidence Ellipse (Alpha vs Beta)\", las = 1)  # Add marginal CIs abline(v = ci_alpha, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_beta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   ## Example 7: Confidence Ellipse (Alpha vs Lambda)  # Extract 2x2 submatrix for alpha and lambda vcov_2d_al <- vcov_matrix[c(1, 3), c(1, 3)]  # Create confidence ellipse eig_decomp_al <- eigen(vcov_2d_al) ellipse_al <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_al[i, ] <- mle[c(1, 3)] + sqrt(chi2_val) *     (eig_decomp_al$vectors %*% diag(sqrt(eig_decomp_al$values)) %*% v) }  # Marginal confidence intervals se_2d_al <- sqrt(diag(vcov_2d_al)) ci_alpha_2 <- mle[1] + c(-1, 1) * 1.96 * se_2d_al[1] ci_lambda <- mle[3] + c(-1, 1) * 1.96 * se_2d_al[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse_al[, 1], ellipse_al[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(lambda),      main = \"95% Confidence Ellipse (Alpha vs Lambda)\", las = 1)  # Add marginal CIs abline(v = ci_alpha_2, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_lambda, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   ## Example 8: Confidence Ellipse (Beta vs Lambda)  # Extract 2x2 submatrix for beta and lambda vcov_2d_bl <- vcov_matrix[2:3, 2:3]  # Create confidence ellipse eig_decomp_bl <- eigen(vcov_2d_bl) ellipse_bl <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_bl[i, ] <- mle[2:3] + sqrt(chi2_val) *     (eig_decomp_bl$vectors %*% diag(sqrt(eig_decomp_bl$values)) %*% v) }  # Marginal confidence intervals se_2d_bl <- sqrt(diag(vcov_2d_bl)) ci_beta_2 <- mle[2] + c(-1, 1) * 1.96 * se_2d_bl[1] ci_lambda_2 <- mle[3] + c(-1, 1) * 1.96 * se_2d_bl[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse_bl[, 1], ellipse_bl[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = expression(lambda),      main = \"95% Confidence Ellipse (Beta vs Lambda)\", las = 1)  # Add marginal CIs abline(v = ci_beta_2, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_lambda_2, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[2], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[3], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsgkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","title":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","text":"Computes analytic Hessian matrix (matrix second partial derivatives) negative log-likelihood function five-parameter Generalized Kumaraswamy (GKw) distribution. typically used estimate standard errors maximum likelihood estimates optimization algorithms.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsgkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","text":"","code":"hsgkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsgkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","text":"par numeric vector length 5 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsgkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","text":"Returns 5x5 numeric matrix representing Hessian matrix negative log-likelihood function, .e., matrix second partial derivatives \\(-\\partial^2 \\ell / (\\partial \\theta_i \\partial \\theta_j)\\). Returns 5x5 matrix populated NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsgkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","text":"function calculates analytic second partial derivatives negative log-likelihood function based GKw PDF (see dgkw). log-likelihood function \\(\\ell(\\theta | \\mathbf{x})\\) given : $$ \\ell(\\theta) = n \\ln(\\lambda\\alpha\\beta) - n \\ln B(\\gamma, \\delta+1) + \\sum_{=1}^{n} [(\\alpha-1) \\ln(x_i) + (\\beta-1) \\ln(v_i) + (\\gamma\\lambda - 1) \\ln(w_i) + \\delta \\ln(z_i)] $$ \\(\\theta = (\\alpha, \\beta, \\gamma, \\delta, \\lambda)\\), \\(B(,b)\\) Beta function (beta), intermediate terms : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) \\(z_i = 1 - w_i^{\\lambda} = 1 - [1-(1-x_i^{\\alpha})^{\\beta}]^{\\lambda}\\) Hessian matrix returned contains elements \\(- \\frac{\\partial^2 \\ell(\\theta | \\mathbf{x})}{\\partial \\theta_i \\partial \\theta_j}\\). Key properties returned matrix: Dimensions: 5x5. Symmetry: matrix symmetric. Ordering: Rows columns correspond parameters order \\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\). Content: Analytic second derivatives negative log-likelihood. exact analytical formulas second derivatives implemented directly (often derived using symbolic differentiation) accuracy efficiency, typically using C++.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsgkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/hsgkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsgkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hessian Matrix of the Negative Log-Likelihood for the GKw Distribution — hsgkw","text":"","code":"# \\donttest{ ## Example 1: Basic Hessian Evaluation  # Generate sample data set.seed(2323) n <- 1000 true_params <- c(alpha = 1.5, beta = 2.0, gamma = 0.8, delta = 1.2, lambda = 0.5) data <- rgkw(n, alpha = true_params[1], beta = true_params[2],              gamma = true_params[3], delta = true_params[4],              lambda = true_params[5])  # Evaluate Hessian at true parameters hess_true <- hsgkw(par = true_params, data = data) cat(\"Hessian matrix at true parameters:\\n\") #> Hessian matrix at true parameters: print(hess_true, digits = 4) #>        [,1]    [,2]   [,3]   [,4]   [,5] #> [1,] 1151.3 -223.17 1494.9 -363.7 2991.8 #> [2,] -223.2   81.76 -232.3  118.9 -503.5 #> [3,] 1494.9 -232.35 1904.5 -394.9 3895.1 #> [4,] -363.7  118.90 -394.9  178.0 -838.3 #> [5,] 2991.8 -503.54 3895.1 -838.3 7494.0  # Check symmetry cat(\"\\nSymmetry check (max |H - H^T|):\",     max(abs(hess_true - t(hess_true))), \"\\n\") #>  #> Symmetry check (max |H - H^T|): 0    ## Example 2: Hessian Properties at MLE  # Fit model fit <- optim(   par = c(1.2, 2.0, 0.5, 1.5, 0.2),   fn = llgkw,   gr = grgkw,   data = data,   method = \"Nelder-Mead\",   hessian = TRUE,   control = list(     maxit = 2000,     factr = 1e-15,     pgtol = 1e-15,     trace = FALSE     ) )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\")  # Hessian at MLE hessian_at_mle <- hsgkw(par = mle, data = data) cat(\"\\nHessian at MLE:\\n\") #>  #> Hessian at MLE: print(hessian_at_mle, digits = 4) #>        [,1]    [,2]    [,3]    [,4]    [,5] #> [1,] 1015.9 -127.58  819.93  -604.1  4306.7 #> [2,] -127.6   31.57  -80.71   119.0  -433.1 #> [3,]  819.9  -80.71  700.52  -420.2  3656.0 #> [4,] -604.1  118.96 -420.20   486.9 -2238.2 #> [5,] 4306.7 -433.11 3655.96 -2238.2 19117.5  # Compare with optim's numerical Hessian cat(\"\\nComparison with optim Hessian:\\n\") #>  #> Comparison with optim Hessian: cat(\"Max absolute difference:\",     max(abs(hessian_at_mle - fit$hessian)), \"\\n\") #> Max absolute difference: 0.2576065   # Eigenvalue analysis eigenvals <- eigen(hessian_at_mle, only.values = TRUE)$values cat(\"\\nEigenvalues:\\n\") #>  #> Eigenvalues: print(eigenvals) #> [1] 2.106856e+04 2.806373e+02 1.660194e+00 9.013023e-01 6.584820e-01  cat(\"\\nPositive definite:\", all(eigenvals > 0), \"\\n\") #>  #> Positive definite: TRUE  cat(\"Condition number:\", max(eigenvals) / min(eigenvals), \"\\n\") #> Condition number: 31995.65    ## Example 3: Standard Errors and Confidence Intervals  # Observed information matrix obs_info <- hessian_at_mle  # Variance-covariance matrix vcov_matrix <- solve(obs_info) cat(\"\\nVariance-Covariance Matrix:\\n\") #>  #> Variance-Covariance Matrix: print(vcov_matrix, digits = 6) #>            [,1]       [,2]       [,3]       [,4]       [,5] #> [1,]  0.7976392 -0.2111590  0.0877811  0.4153406 -0.1526331 #> [2,] -0.2111590  1.0707453  0.2160549 -0.4263221 -0.0194034 #> [3,]  0.0877811  0.2160549  0.9776437 -0.0606497 -0.2089422 #> [4,]  0.4153406 -0.4263221 -0.0606497  0.3204520 -0.0541086 #> [5,] -0.1526331 -0.0194034 -0.2089422 -0.0541086  0.0676199  # Standard errors se <- sqrt(diag(vcov_matrix)) names(se) <- c(\"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\")  # Correlation matrix corr_matrix <- cov2cor(vcov_matrix) cat(\"\\nCorrelation Matrix:\\n\") #>  #> Correlation Matrix: print(corr_matrix, digits = 4) #>         [,1]     [,2]    [,3]    [,4]     [,5] #> [1,]  1.0000 -0.22849  0.0994  0.8215 -0.65722 #> [2,] -0.2285  1.00000  0.2112 -0.7278 -0.07211 #> [3,]  0.0994  0.21117  1.0000 -0.1084 -0.81264 #> [4,]  0.8215 -0.72780 -0.1084  1.0000 -0.36758 #> [5,] -0.6572 -0.07211 -0.8126 -0.3676  1.00000  # Confidence intervals z_crit <- qnorm(0.975) results <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - z_crit * se,   CI_Upper = mle + z_crit * se ) print(results, digits = 4) #>        Parameter True    MLE     SE CI_Lower CI_Upper #> alpha      alpha  1.5 1.5556 0.8931  -0.1948   3.3061 #> beta        beta  2.0 3.1089 1.0348   1.0808   5.1370 #> gamma      gamma  0.8 1.3114 0.9888  -0.6265   3.2494 #> delta      delta  1.2 0.5344 0.5661  -0.5751   1.6439 #> lambda    lambda  0.5 0.2778 0.2600  -0.2319   0.7875   ## Example 4: Determinant and Trace Analysis  # Compute at different points test_params <- rbind(   c(1.5, 2.5, 1.2, 1.5, 1.5),   c(2.0, 3.0, 1.5, 2.0, 1.8),   mle,   c(2.5, 3.5, 1.8, 2.5, 2.0) )  hess_properties <- data.frame(   Alpha = numeric(),   Beta = numeric(),   Gamma = numeric(),   Delta = numeric(),   Lambda = numeric(),   Determinant = numeric(),   Trace = numeric(),   Min_Eigenval = numeric(),   Max_Eigenval = numeric(),   Cond_Number = numeric(),   stringsAsFactors = FALSE )  for (i in 1:nrow(test_params)) {   H <- hsgkw(par = test_params[i, ], data = data)   eigs <- eigen(H, only.values = TRUE)$values    hess_properties <- rbind(hess_properties, data.frame(     Alpha = test_params[i, 1],     Beta = test_params[i, 2],     Gamma = test_params[i, 3],     Delta = test_params[i, 4],     Lambda = test_params[i, 5],     Determinant = det(H),     Trace = sum(diag(H)),     Min_Eigenval = min(eigs),     Max_Eigenval = max(eigs),     Cond_Number = max(eigs) / min(eigs)   )) }  cat(\"\\nHessian Properties at Different Points:\\n\") #>  #> Hessian Properties at Different Points: print(hess_properties, digits = 4, row.names = FALSE) #>  Alpha  Beta Gamma  Delta Lambda Determinant Trace Min_Eigenval Max_Eigenval #>  1.500 2.500 1.200 1.5000 1.5000   3.379e+15  3357   -3370.0013         8989 #>  2.000 3.000 1.500 2.0000 1.8000   8.321e+15  2282   -4797.5735        10666 #>  1.556 3.109 1.311 0.5344 0.2778   5.826e+06 21352       0.6585        21069 #>  2.500 3.500 1.800 2.5000 2.0000   1.311e+16  1729   -6018.0712        12386 #>  Cond_Number #>       -2.667 #>       -2.223 #>    31995.650 #>       -2.058   ## Example 5: Curvature Visualization (Alpha vs Beta)  xd <- 2 # Create grid around MLE alpha_grid <- seq(mle[1] - xd, mle[1] + xd, length.out = round(n/4)) beta_grid <- seq(mle[2] - xd, mle[2] + xd, length.out = round(n/4)) alpha_grid <- alpha_grid[alpha_grid > 0] beta_grid <- beta_grid[beta_grid > 0]  # Compute curvature measures determinant_surface <- matrix(NA, nrow = length(alpha_grid),                                ncol = length(beta_grid)) trace_surface <- matrix(NA, nrow = length(alpha_grid),                          ncol = length(beta_grid))  for (i in seq_along(alpha_grid)) {   for (j in seq_along(beta_grid)) {     H <- hsgkw(c(alpha_grid[i], beta_grid[j], mle[3], mle[4], mle[5]), data)     determinant_surface[i, j] <- det(H)     trace_surface[i, j] <- sum(diag(H))   } }  # Plot par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))  contour(alpha_grid, beta_grid, determinant_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"Hessian Determinant\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(alpha_grid, beta_grid, trace_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"Hessian Trace\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")   par(mfrow = c(1, 1))   ## Example 6: Confidence Ellipse (Alpha vs Beta)  # Extract 2x2 submatrix for alpha and beta vcov_2d <- vcov_matrix[1:2, 1:2]  # Create confidence ellipse theta <- seq(0, 2 * pi, length.out = round(n/4)) chi2_val <- qchisq(0.95, df = 2)  eig_decomp <- eigen(vcov_2d) ellipse <- matrix(NA, nrow = round(n/4), ncol = 2) for (i in 1:round(n/4)) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Marginal confidence intervals se_2d <- sqrt(diag(vcov_2d)) ci_alpha <- mle[1] + c(-1, 1) * 1.96 * se_2d[1] ci_beta <- mle[2] + c(-1, 1) * 1.96 * se_2d[2]  # Plot par(mfrow = c(1, 3), mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"95% Confidence Ellipse (Alpha vs Beta)\", las = 1)  # Add marginal CIs abline(v = ci_alpha, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_beta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   ## Example 7: Confidence Ellipse (Gamma vs Delta)  # Extract 2x2 submatrix for gamma and delta vcov_2d_gd <- vcov_matrix[3:4, 3:4]  # Create confidence ellipse eig_decomp_gd <- eigen(vcov_2d_gd) ellipse_gd <- matrix(NA, nrow = round(n/4), ncol = 2) for (i in 1:round(n/4)) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_gd[i, ] <- mle[3:4] + sqrt(chi2_val) *     (eig_decomp_gd$vectors %*% diag(sqrt(eig_decomp_gd$values)) %*% v) }  # Marginal confidence intervals se_2d_gd <- sqrt(diag(vcov_2d_gd)) ci_gamma <- mle[3] + c(-1, 1) * 1.96 * se_2d_gd[1] ci_delta <- mle[4] + c(-1, 1) * 1.96 * se_2d_gd[2]  # Plot # par(mar = c(4, 4, 3, 1)) plot(ellipse_gd[, 1], ellipse_gd[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = expression(delta),      main = \"95% Confidence Ellipse (Gamma vs Delta)\", las = 1)  # Add marginal CIs abline(v = ci_gamma, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_delta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[3], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[3], true_params[4], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   ## Example 8: Confidence Ellipse (Delta vs Lambda)  # Extract 2x2 submatrix for delta and lambda vcov_2d_dl <- vcov_matrix[4:5, 4:5]  # Create confidence ellipse eig_decomp_dl <- eigen(vcov_2d_dl) ellipse_dl <- matrix(NA, nrow = round(n/4), ncol = 2) for (i in 1:round(n/4)) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_dl[i, ] <- mle[4:5] + sqrt(chi2_val) *     (eig_decomp_dl$vectors %*% diag(sqrt(eig_decomp_dl$values)) %*% v) }  # Marginal confidence intervals se_2d_dl <- sqrt(diag(vcov_2d_dl)) ci_delta_2 <- mle[4] + c(-1, 1) * 1.96 * se_2d_dl[1] ci_lambda <- mle[5] + c(-1, 1) * 1.96 * se_2d_dl[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse_dl[, 1], ellipse_dl[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(delta), ylab = expression(lambda),      main = \"95% Confidence Ellipse (Delta vs Lambda)\", las = 1)  # Add marginal CIs abline(v = ci_delta_2, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_lambda, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[4], mle[5], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[4], true_params[5], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/hskkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","title":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","text":"Computes analytic 4x4 Hessian matrix (matrix second partial derivatives) negative log-likelihood function Kumaraswamy-Kumaraswamy (kkw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\). Hessian useful estimating standard errors optimization algorithms.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","text":"","code":"hskkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/hskkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","text":"par numeric vector length 4 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","text":"Returns 4x4 numeric matrix representing Hessian matrix negative log-likelihood function, \\(-\\partial^2 \\ell / (\\partial \\theta_i \\partial \\theta_j)\\), \\(\\theta = (\\alpha, \\beta, \\delta, \\lambda)\\). Returns 4x4 matrix populated NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","text":"function calculates analytic second partial derivatives negative log-likelihood function based kkw log-likelihood (\\(\\gamma=1\\) case GKw, see llkkw): $$ \\ell(\\theta | \\mathbf{x}) = n[\\ln(\\delta+1) + \\ln(\\lambda) + \\ln(\\alpha) + \\ln(\\beta)] + \\sum_{=1}^{n} [(\\alpha-1)\\ln(x_i) + (\\beta-1)\\ln(v_i) + (\\lambda-1)\\ln(w_i) + \\delta\\ln(z_i)] $$ \\(\\theta = (\\alpha, \\beta, \\delta, \\lambda)\\) intermediate terms : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) \\(z_i = 1 - w_i^{\\lambda} = 1 - [1-(1-x_i^{\\alpha})^{\\beta}]^{\\lambda}\\) Hessian matrix returned contains elements \\(- \\frac{\\partial^2 \\ell(\\theta | \\mathbf{x})}{\\partial \\theta_i \\partial \\theta_j}\\) \\(\\theta_i, \\theta_j \\\\{\\alpha, \\beta, \\delta, \\lambda\\}\\). Key properties returned matrix: Dimensions: 4x4. Symmetry: matrix symmetric. Ordering: Rows columns correspond parameters order \\(\\alpha, \\beta, \\delta, \\lambda\\). Content: Analytic second derivatives negative log-likelihood. corresponds relevant submatrix 5x5 GKw Hessian (hsgkw) evaluated \\(\\gamma=1\\). exact analytical formulas implemented directly.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/hskkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hessian Matrix of the Negative Log-Likelihood for the kkw Distribution — hskkw","text":"","code":"# \\donttest{ ## Example 1: Basic Hessian Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.0, beta = 3.0, delta = 1.5, lambda = 2.0) data <- rkkw(n, alpha = true_params[1], beta = true_params[2],              delta = true_params[3], lambda = true_params[4])  # Evaluate Hessian at true parameters hess_true <- hskkw(par = true_params, data = data) cat(\"Hessian matrix at true parameters:\\n\") #> Hessian matrix at true parameters: print(hess_true, digits = 4) #>        [,1]   [,2]   [,3]   [,4] #> [1,] 1557.6 -564.6 -425.5  910.9 #> [2,] -564.6  247.6  195.1 -307.5 #> [3,] -425.5  195.1  160.0 -225.7 #> [4,]  910.9 -307.5 -225.7  541.1  # Check symmetry cat(\"\\nSymmetry check (max |H - H^T|):\",     max(abs(hess_true - t(hess_true))), \"\\n\") #>  #> Symmetry check (max |H - H^T|): 0    ## Example 2: Hessian Properties at MLE  # Fit model fit <- optim(   par = c(1.5, 2.5, 1.0, 1.5),   fn = llkkw,   gr = grkkw,   data = data,   method = \"BFGS\",   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\", \"delta\", \"lambda\")  # Hessian at MLE hessian_at_mle <- hskkw(par = mle, data = data) cat(\"\\nHessian at MLE:\\n\") #>  #> Hessian at MLE: print(hessian_at_mle, digits = 4) #>        [,1]   [,2]   [,3]   [,4] #> [1,] 1188.9 -371.1 -423.3  881.2 #> [2,] -371.1  140.8  168.0 -251.3 #> [3,] -423.3  168.0  202.5 -280.4 #> [4,]  881.2 -251.3 -280.4  678.3  # Compare with optim's numerical Hessian cat(\"\\nComparison with optim Hessian:\\n\") #>  #> Comparison with optim Hessian: cat(\"Max absolute difference:\",     max(abs(hessian_at_mle - fit$hessian)), \"\\n\") #> Max absolute difference: 0.0003078667   # Eigenvalue analysis eigenvals <- eigen(hessian_at_mle, only.values = TRUE)$values cat(\"\\nEigenvalues:\\n\") #>  #> Eigenvalues: print(eigenvals) #> [1] 2.109731e+03 9.911840e+01 1.552331e+00 9.866428e-03  cat(\"\\nPositive definite:\", all(eigenvals > 0), \"\\n\") #>  #> Positive definite: TRUE  cat(\"Condition number:\", max(eigenvals) / min(eigenvals), \"\\n\") #> Condition number: 213829.2    ## Example 3: Standard Errors and Confidence Intervals  # Observed information matrix obs_info <- hessian_at_mle  # Variance-covariance matrix vcov_matrix <- solve(obs_info) cat(\"\\nVariance-Covariance Matrix:\\n\") #>  #> Variance-Covariance Matrix: print(vcov_matrix, digits = 6) #>          [,1]     [,2]      [,3]      [,4] #> [1,]  4.72527  17.8381  -9.97973  -3.65563 #> [2,] 17.83805  71.2209 -40.54649 -13.54957 #> [3,] -9.97973 -40.5465  23.21460   7.54000 #> [4,] -3.65563 -13.5496   7.54000   2.84775  # Standard errors se <- sqrt(diag(vcov_matrix)) names(se) <- c(\"alpha\", \"beta\", \"delta\", \"lambda\")  # Correlation matrix corr_matrix <- cov2cor(vcov_matrix) cat(\"\\nCorrelation Matrix:\\n\") #>  #> Correlation Matrix: print(corr_matrix, digits = 4) #>         [,1]    [,2]    [,3]    [,4] #> [1,]  1.0000  0.9724 -0.9529 -0.9965 #> [2,]  0.9724  1.0000 -0.9972 -0.9514 #> [3,] -0.9529 -0.9972  1.0000  0.9273 #> [4,] -0.9965 -0.9514  0.9273  1.0000  # Confidence intervals z_crit <- qnorm(0.975) results <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"delta\", \"lambda\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - z_crit * se,   CI_Upper = mle + z_crit * se ) print(results, digits = 4) #>        Parameter True   MLE    SE CI_Lower CI_Upper #> alpha      alpha  2.0 2.304 2.174   -1.956    6.565 #> beta        beta  3.0 3.610 8.439  -12.931   20.150 #> delta      delta  1.5 1.222 4.818   -8.221   10.666 #> lambda    lambda  2.0 1.705 1.688   -1.603    5.012   ## Example 4: Determinant and Trace Analysis  # Compute at different points test_params <- rbind(   c(1.5, 2.5, 1.0, 1.5),   c(2.0, 3.0, 1.5, 2.0),   mle,   c(2.5, 3.5, 2.0, 2.5) )  hess_properties <- data.frame(   Alpha = numeric(),   Beta = numeric(),   Delta = numeric(),   Lambda = numeric(),   Determinant = numeric(),   Trace = numeric(),   Min_Eigenval = numeric(),   Max_Eigenval = numeric(),   Cond_Number = numeric(),   stringsAsFactors = FALSE )  for (i in 1:nrow(test_params)) {   H <- hskkw(par = test_params[i, ], data = data)   eigs <- eigen(H, only.values = TRUE)$values    hess_properties <- rbind(hess_properties, data.frame(     Alpha = test_params[i, 1],     Beta = test_params[i, 2],     Delta = test_params[i, 3],     Lambda = test_params[i, 4],     Determinant = det(H),     Trace = sum(diag(H)),     Min_Eigenval = min(eigs),     Max_Eigenval = max(eigs),     Cond_Number = max(eigs) / min(eigs)   )) }  cat(\"\\nHessian Properties at Different Points:\\n\") #>  #> Hessian Properties at Different Points: print(hess_properties, digits = 4, row.names = FALSE) #>  Alpha Beta Delta Lambda Determinant Trace Min_Eigenval Max_Eigenval #>  1.500 2.50 1.000  1.500  -5.769e+09  3399   -1.056e+02         3061 #>  2.000 3.00 1.500  2.000  -1.317e+06  2506   -2.387e+00         2413 #>  2.304 3.61 1.222  1.705   3.203e+03  2210    9.866e-03         2110 #>  2.500 3.50 2.000  2.500  -2.204e+09  1873   -2.309e+02         1954 #>  Cond_Number #>      -28.985 #>    -1011.104 #>   213829.226 #>       -8.462   ## Example 5: Curvature Visualization (Alpha vs Beta)  # Create grid around MLE alpha_grid <- seq(mle[1] - 1, mle[1] + 1, length.out = round(n/4)) beta_grid <- seq(mle[2] - 1, mle[2] + 1, length.out = round(n/4)) alpha_grid <- alpha_grid[alpha_grid > 0] beta_grid <- beta_grid[beta_grid > 0]  # Compute curvature measures determinant_surface <- matrix(NA, nrow = length(alpha_grid),                                ncol = length(beta_grid)) trace_surface <- matrix(NA, nrow = length(alpha_grid),                          ncol = length(beta_grid))  for (i in seq_along(alpha_grid)) {   for (j in seq_along(beta_grid)) {     H <- hskkw(c(alpha_grid[i], beta_grid[j], mle[3], mle[4]), data)     determinant_surface[i, j] <- det(H)     trace_surface[i, j] <- sum(diag(H))   } }  # Plot par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))  contour(alpha_grid, beta_grid, determinant_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"Hessian Determinant\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(alpha_grid, beta_grid, trace_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"Hessian Trace\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")   par(mfrow = c(1, 1))   ## Example 6: Confidence Ellipse (Alpha vs Beta)  # Extract 2x2 submatrix for alpha and beta vcov_2d <- vcov_matrix[1:2, 1:2]  # Create confidence ellipse theta <- seq(0, 2 * pi, length.out = round(n/2)) chi2_val <- qchisq(0.95, df = 2)  eig_decomp <- eigen(vcov_2d) ellipse <- matrix(NA, nrow = round(n/2), ncol = 2) for (i in 1:round(n/2)) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Marginal confidence intervals se_2d <- sqrt(diag(vcov_2d)) ci_alpha <- mle[1] + c(-1, 1) * 1.96 * se_2d[1] ci_beta <- mle[2] + c(-1, 1) * 1.96 * se_2d[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"95% Confidence Ellipse (Alpha vs Beta)\", las = 1)  # Add marginal CIs abline(v = ci_alpha, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_beta, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")    ## Example 7: Confidence Ellipse (Delta vs Lambda)  # Extract 2x2 submatrix for delta and lambda vcov_2d_dl <- vcov_matrix[3:4, 3:4]  # Create confidence ellipse eig_decomp_dl <- eigen(vcov_2d_dl) ellipse_dl <- matrix(NA, nrow = round(n/2), ncol = 2) for (i in 1:round(n/2)) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_dl[i, ] <- mle[3:4] + sqrt(chi2_val) *     (eig_decomp_dl$vectors %*% diag(sqrt(eig_decomp_dl$values)) %*% v) }  # Marginal confidence intervals se_2d_dl <- sqrt(diag(vcov_2d_dl)) ci_delta <- mle[3] + c(-1, 1) * 1.96 * se_2d_dl[1] ci_lambda <- mle[4] + c(-1, 1) * 1.96 * se_2d_dl[2]  # Plot par(mar = c(4, 4, 3, 1)) plot(ellipse_dl[, 1], ellipse_dl[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(delta), ylab = expression(lambda),      main = \"95% Confidence Ellipse (Delta vs Lambda)\", las = 1)  # Add marginal CIs abline(v = ci_delta, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_lambda, col = \"#808080\", lty = 3, lwd = 1.5)  points(mle[3], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[3], true_params[4], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\") grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/hskw.html","id":null,"dir":"Reference","previous_headings":"","what":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","title":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","text":"Computes analytic 2x2 Hessian matrix (matrix second partial derivatives) negative log-likelihood function two-parameter Kumaraswamy (Kw) distribution parameters alpha (\\(\\alpha\\)) beta (\\(\\beta\\)). Hessian useful estimating standard errors optimization algorithms.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","text":"","code":"hskw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/hskw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","text":"par numeric vector length 2 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","text":"Returns 2x2 numeric matrix representing Hessian matrix negative log-likelihood function, \\(-\\partial^2 \\ell / (\\partial \\theta_i \\partial \\theta_j)\\), \\(\\theta = (\\alpha, \\beta)\\). Returns 2x2 matrix populated NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","text":"function calculates analytic second partial derivatives negative log-likelihood function (\\(-\\ell(\\theta|\\mathbf{x})\\)). components negative second derivatives log-likelihood \\(\\ell\\) (derived PDF dkw). Let \\(v_i = 1 - x_i^{\\alpha}\\). second derivatives positive log-likelihood (\\(\\ell\\)) : $$ \\frac{\\partial^2 \\ell}{\\partial \\alpha^2} = -\\frac{n}{\\alpha^2} - (\\beta-1)\\sum_{=1}^{n}\\frac{x_i^{\\alpha}(\\ln(x_i))^2}{v_i^2} $$ $$ \\frac{\\partial^2 \\ell}{\\partial \\alpha \\partial \\beta} = - \\sum_{=1}^{n}\\frac{x_i^{\\alpha}\\ln(x_i)}{v_i} $$ $$ \\frac{\\partial^2 \\ell}{\\partial \\beta^2} = -\\frac{n}{\\beta^2} $$ function returns Hessian matrix containing negative values. Key properties returned matrix: Dimensions: 2x2. Symmetry: matrix symmetric. Ordering: Rows columns correspond parameters order \\(\\alpha, \\beta\\). Content: Analytic second derivatives negative log-likelihood. corresponds relevant 2x2 submatrix 5x5 GKw Hessian (hsgkw) evaluated \\(\\gamma=1, \\delta=0, \\lambda=1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","text":"Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81. (Note: Specific Hessian formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/hskw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hskw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hessian Matrix of the Negative Log-Likelihood for the Kw Distribution — hskw","text":"","code":"# \\donttest{ ## Example 1: Basic Hessian Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.5, beta = 3.5) data <- rkw(n, alpha = true_params[1], beta = true_params[2])  # Evaluate Hessian at true parameters hess_true <- hskw(par = true_params, data = data) cat(\"Hessian matrix at true parameters:\\n\") #> Hessian matrix at true parameters: print(hess_true, digits = 4) #>        [,1]    [,2] #> [1,]  449.7 -153.72 #> [2,] -153.7   81.63  # Check symmetry cat(\"\\nSymmetry check (max |H - H^T|):\",     max(abs(hess_true - t(hess_true))), \"\\n\") #>  #> Symmetry check (max |H - H^T|): 0    ## Example 2: Hessian Properties at MLE  # Fit model fit <- optim(   par = c(2, 2),   fn = llkw,   gr = grkw,   data = data,   method = \"BFGS\",   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\")  # Hessian at MLE hessian_at_mle <- hskw(par = mle, data = data) cat(\"\\nHessian at MLE:\\n\") #>  #> Hessian at MLE: print(hessian_at_mle, digits = 4) #>        [,1]    [,2] #> [1,]  453.2 -152.43 #> [2,] -152.4   78.43  # Compare with optim's numerical Hessian cat(\"\\nComparison with optim Hessian:\\n\") #>  #> Comparison with optim Hessian: cat(\"Max absolute difference:\",     max(abs(hessian_at_mle - fit$hessian)), \"\\n\") #> Max absolute difference: 8.859191e-05   # Eigenvalue analysis eigenvals <- eigen(hessian_at_mle, only.values = TRUE)$values cat(\"\\nEigenvalues:\\n\") #>  #> Eigenvalues: print(eigenvals) #> [1] 507.36836  24.25944  cat(\"\\nPositive definite:\", all(eigenvals > 0), \"\\n\") #>  #> Positive definite: TRUE  cat(\"Condition number:\", max(eigenvals) / min(eigenvals), \"\\n\") #> Condition number: 20.91426    ## Example 3: Standard Errors and Confidence Intervals  # Observed information matrix (negative Hessian for neg-loglik) obs_info <- hessian_at_mle  # Variance-covariance matrix vcov_matrix <- solve(obs_info) cat(\"\\nVariance-Covariance Matrix:\\n\") #>  #> Variance-Covariance Matrix: print(vcov_matrix, digits = 6) #>           [,1]      [,2] #> [1,] 0.0063718 0.0123841 #> [2,] 0.0123841 0.0368202  # Standard errors se <- sqrt(diag(vcov_matrix)) names(se) <- c(\"alpha\", \"beta\")  # Correlation matrix corr_matrix <- cov2cor(vcov_matrix) cat(\"\\nCorrelation Matrix:\\n\") #>  #> Correlation Matrix: print(corr_matrix, digits = 4) #>        [,1]   [,2] #> [1,] 1.0000 0.8085 #> [2,] 0.8085 1.0000  # Confidence intervals z_crit <- qnorm(0.975) results <- data.frame(   Parameter = c(\"alpha\", \"beta\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - z_crit * se,   CI_Upper = mle + z_crit * se ) print(results, digits = 4) #>       Parameter True   MLE      SE CI_Lower CI_Upper #> alpha     alpha  2.5 2.511 0.07982    2.355    2.668 #> beta       beta  3.5 3.571 0.19189    3.195    3.947   ## Example 4: Determinant and Trace Analysis  # Compute at different points test_params <- rbind(   c(1.5, 2.5),   c(2.0, 3.0),   mle,   c(3.0, 4.0) )  hess_properties <- data.frame(   Alpha = numeric(),   Beta = numeric(),   Determinant = numeric(),   Trace = numeric(),   Min_Eigenval = numeric(),   Max_Eigenval = numeric(),   Cond_Number = numeric(),   stringsAsFactors = FALSE )  for (i in 1:nrow(test_params)) {   H <- hskw(par = test_params[i, ], data = data)   eigs <- eigen(H, only.values = TRUE)$values    hess_properties <- rbind(hess_properties, data.frame(     Alpha = test_params[i, 1],     Beta = test_params[i, 2],     Determinant = det(H),     Trace = sum(diag(H)),     Min_Eigenval = min(eigs),     Max_Eigenval = max(eigs),     Cond_Number = max(eigs) / min(eigs)   )) }  cat(\"\\nHessian Properties at Different Points:\\n\") #>  #> Hessian Properties at Different Points: print(hess_properties, digits = 4, row.names = FALSE) #>  Alpha  Beta Determinant  Trace Min_Eigenval Max_Eigenval Cond_Number #>  1.500 2.500       27209 1185.6        23.41       1162.2       49.64 #>  2.000 3.000       19189  760.5        26.13        734.3       28.10 #>  2.511 3.571       12308  531.6        24.26        507.4       20.91 #>  3.000 4.000        8945  391.2        24.39        366.8       15.04   ## Example 5: Curvature Visualization  # Create grid around MLE alpha_grid <- seq(mle[1] - 0.5, mle[1] + 0.5, length.out = 30) beta_grid <- seq(mle[2] - 0.5, mle[2] + 0.5, length.out = 30) alpha_grid <- alpha_grid[alpha_grid > 0] beta_grid <- beta_grid[beta_grid > 0]  # Compute curvature measures determinant_surface <- matrix(NA, nrow = length(alpha_grid),                                ncol = length(beta_grid)) trace_surface <- matrix(NA, nrow = length(alpha_grid),                          ncol = length(beta_grid))  for (i in seq_along(alpha_grid)) {   for (j in seq_along(beta_grid)) {     H <- hskw(c(alpha_grid[i], beta_grid[j]), data)     determinant_surface[i, j] <- det(H)     trace_surface[i, j] <- sum(diag(H))   } }  # Plot par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))  contour(alpha_grid, beta_grid, determinant_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"Hessian Determinant\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(alpha_grid, beta_grid, trace_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"Hessian Trace\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")   par(mfrow = c(1, 1))   ## Example 6: Fisher Information and Asymptotic Efficiency  # Observed information (at MLE) obs_fisher <- hessian_at_mle  # Asymptotic covariance matrix asymp_cov <- solve(obs_fisher)  cat(\"\\nAsymptotic Standard Errors:\\n\") #>  #> Asymptotic Standard Errors: cat(\"SE(alpha):\", sqrt(asymp_cov[1, 1]), \"\\n\") #> SE(alpha): 0.07982353  cat(\"SE(beta):\", sqrt(asymp_cov[2, 2]), \"\\n\") #> SE(beta): 0.191886   # Cramér-Rao Lower Bound cat(\"\\nCramér-Rao Lower Bounds:\\n\") #>  #> Cramér-Rao Lower Bounds: cat(\"CRLB(alpha):\", sqrt(asymp_cov[1, 1]), \"\\n\") #> CRLB(alpha): 0.07982353  cat(\"CRLB(beta):\", sqrt(asymp_cov[2, 2]), \"\\n\") #> CRLB(beta): 0.191886   # Efficiency ellipse (95% confidence region) theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  # Eigendecomposition eig_decomp <- eigen(asymp_cov)  # Ellipse points ellipse <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse[i, ] <- mle + sqrt(chi2_val) *     (eig_decomp$vectors %*% diag(sqrt(eig_decomp$values)) %*% v) }  # Plot confidence ellipse par(mar = c(4, 4, 3, 1)) plot(ellipse[, 1], ellipse[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = expression(beta),      main = \"95% Confidence Ellipse\", las = 1) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\"),        pch = c(19, 17, NA), lty = c(NA, NA, 1),        lwd = c(NA, NA, 2), bty = \"n\") grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","title":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","text":"Computes analytic 3x3 Hessian matrix (matrix second partial derivatives) negative log-likelihood function McDonald (Mc) distribution (also known Beta Power) parameters gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\alpha = 1\\) \\(\\beta = 1\\). Hessian useful estimating standard errors optimization algorithms.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","text":"","code":"hsmc(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/hsmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","text":"par numeric vector length 3 containing distribution parameters order: gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","text":"Returns 3x3 numeric matrix representing Hessian matrix negative log-likelihood function, \\(-\\partial^2 \\ell / (\\partial \\theta_i \\partial \\theta_j)\\), \\(\\theta = (\\gamma, \\delta, \\lambda)\\). Returns 3x3 matrix populated NaN parameter values invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","text":"function calculates analytic second partial derivatives negative log-likelihood function (\\(-\\ell(\\theta|\\mathbf{x})\\)). components based second derivatives log-likelihood \\(\\ell\\) (derived PDF dmc). Note: formulas represent second derivatives positive log-likelihood (\\(\\ell\\)). function returns negative values. Users verify formulas independently using critical applications. $$ \\frac{\\partial^2 \\ell}{\\partial \\gamma^2} = -n[\\psi'(\\gamma) - \\psi'(\\gamma+\\delta+1)] $$ $$ \\frac{\\partial^2 \\ell}{\\partial \\gamma \\partial \\delta} = -n\\psi'(\\gamma+\\delta+1) $$ $$ \\frac{\\partial^2 \\ell}{\\partial \\gamma \\partial \\lambda} = \\sum_{=1}^{n}\\ln(x_i) $$ $$ \\frac{\\partial^2 \\ell}{\\partial \\delta^2} = -n[\\psi'(\\delta+1) - \\psi'(\\gamma+\\delta+1)] $$ $$ \\frac{\\partial^2 \\ell}{\\partial \\delta \\partial \\lambda} = -\\sum_{=1}^{n}\\frac{x_i^{\\lambda}\\ln(x_i)}{1-x_i^{\\lambda}} $$ $$ \\frac{\\partial^2 \\ell}{\\partial \\lambda^2} = -\\frac{n}{\\lambda^2} - \\delta\\sum_{=1}^{n}\\frac{x_i^{\\lambda}[\\ln(x_i)]^2}{(1-x_i^{\\lambda})^2} $$ \\(\\psi'(\\cdot)\\) trigamma function (trigamma). (Note: formula \\(\\partial^2 \\ell / \\partial \\lambda^2\\) provided source comment different potentially related expected information matrix; formula shown derived gradient provided earlier. Verification recommended.) returned matrix symmetric, rows/columns corresponding \\(\\gamma, \\delta, \\lambda\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","text":"McDonald, J. B. (1984). generalized functions size distribution income. Econometrica, 52(3), 647-663. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, (Note: Specific Hessian formulas might derived sourced additional references).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/hsmc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/hsmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Hessian Matrix of the Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — hsmc","text":"","code":"# \\donttest{ ## Example 1: Basic Hessian Evaluation  # Generate sample data with more stable parameters set.seed(123) n <- 1000 true_params <- c(gamma = 2.0, delta = 2.5, lambda = 1.5) data <- rmc(n, gamma = true_params[1], delta = true_params[2],             lambda = true_params[3])  # Evaluate Hessian at true parameters hess_true <- hsmc(par = true_params, data = data) cat(\"Hessian matrix at true parameters:\\n\") #> Hessian matrix at true parameters: print(hess_true, digits = 4) #>        [,1]   [,2]   [,3] #> [1,]  445.6 -199.3  783.2 #> [2,] -199.3  131.0 -369.8 #> [3,]  783.2 -369.8 1416.2  # Check symmetry cat(\"\\nSymmetry check (max |H - H^T|):\",     max(abs(hess_true - t(hess_true))), \"\\n\") #>  #> Symmetry check (max |H - H^T|): 0    ## Example 2: Hessian Properties at MLE  # Fit model fit <- optim(   par = c(1.5, 2.0, 1.0),   fn = llmc,   gr = grmc,   data = data,   method = \"BFGS\",   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"gamma\", \"delta\", \"lambda\")  # Hessian at MLE hessian_at_mle <- hsmc(par = mle, data = data) cat(\"\\nHessian at MLE:\\n\") #>  #> Hessian at MLE: print(hessian_at_mle, digits = 4) #>        [,1]    [,2]   [,3] #> [1,]  754.3 -216.43  783.2 #> [2,] -216.4   99.01 -238.6 #> [3,]  783.2 -238.57  820.1  # Compare with optim's numerical Hessian cat(\"\\nComparison with optim Hessian:\\n\") #>  #> Comparison with optim Hessian: cat(\"Max absolute difference:\",     max(abs(hessian_at_mle - fit$hessian)), \"\\n\") #> Max absolute difference: 0.0002574136   # Eigenvalue analysis eigenvals <- eigen(hessian_at_mle, only.values = TRUE)$values cat(\"\\nEigenvalues:\\n\") #>  #> Eigenvalues: print(eigenvals) #> [1] 1638.4186859   34.1207859    0.8213602  cat(\"\\nPositive definite:\", all(eigenvals > 0), \"\\n\") #>  #> Positive definite: TRUE  cat(\"Condition number:\", max(eigenvals) / min(eigenvals), \"\\n\") #> Condition number: 1994.763    ## Example 3: Standard Errors and Confidence Intervals  # Observed information matrix obs_info <- hessian_at_mle  # Variance-covariance matrix vcov_matrix <- solve(obs_info) cat(\"\\nVariance-Covariance Matrix:\\n\") #>  #> Variance-Covariance Matrix: print(vcov_matrix, digits = 6) #>           [,1]      [,2]      [,3] #> [1,]  0.528826 -0.203770 -0.564330 #> [2,] -0.203770  0.112290  0.227275 #> [3,] -0.564330  0.227275  0.606294  # Standard errors se <- sqrt(diag(vcov_matrix)) names(se) <- c(\"gamma\", \"delta\", \"lambda\")  # Correlation matrix corr_matrix <- cov2cor(vcov_matrix) cat(\"\\nCorrelation Matrix:\\n\") #>  #> Correlation Matrix: print(corr_matrix, digits = 4) #>         [,1]    [,2]    [,3] #> [1,]  1.0000 -0.8362 -0.9966 #> [2,] -0.8362  1.0000  0.8710 #> [3,] -0.9966  0.8710  1.0000  # Confidence intervals z_crit <- qnorm(0.975) results <- data.frame(   Parameter = c(\"gamma\", \"delta\", \"lambda\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - z_crit * se,   CI_Upper = mle + z_crit * se ) print(results, digits = 4) #>        Parameter True   MLE     SE CI_Lower CI_Upper #> gamma      gamma  2.0 1.458 0.7272  0.03292    2.884 #> delta      delta  2.5 2.644 0.3351  1.98755    3.301 #> lambda    lambda  1.5 1.956 0.7786  0.42971    3.482   ## Example 4: Determinant and Trace Analysis  # Compute at different points test_params <- rbind(   c(1.5, 2.0, 1.0),   c(2.0, 2.5, 1.5),   mle,   c(2.5, 3.0, 2.0) )  hess_properties <- data.frame(   Gamma = numeric(),   Delta = numeric(),   Lambda = numeric(),   Determinant = numeric(),   Trace = numeric(),   Min_Eigenval = numeric(),   Max_Eigenval = numeric(),   Cond_Number = numeric(),   stringsAsFactors = FALSE )  for (i in 1:nrow(test_params)) {   H <- hsmc(par = test_params[i, ], data = data)   eigs <- eigen(H, only.values = TRUE)$values    hess_properties <- rbind(hess_properties, data.frame(     Gamma = test_params[i, 1],     Delta = test_params[i, 2],     Lambda = test_params[i, 3],     Determinant = det(H),     Trace = sum(diag(H)),     Min_Eigenval = min(eigs),     Max_Eigenval = max(eigs),     Cond_Number = max(eigs) / min(eigs)   )) }  cat(\"\\nHessian Properties at Different Points:\\n\") #>  #> Hessian Properties at Different Points: print(hess_properties, digits = 4, row.names = FALSE) #>  Gamma Delta Lambda Determinant Trace Min_Eigenval Max_Eigenval Cond_Number #>  1.500 2.000  1.000   -28036436  3709     -19.4941         3292    -168.864 #>  2.000 2.500  1.500      569493  1993       8.3039         1949     234.745 #>  1.458 2.644  1.956       45917  1673       0.8214         1638    1994.763 #>  2.500 3.000  2.000   -20506346  1293    -238.7457         1473      -6.171   ## Example 5: Curvature Visualization (All pairs side by side)  # Create grids around MLE with wider range (±1.5) gamma_grid <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = 25) delta_grid <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = 25) lambda_grid <- seq(mle[3] - 1.5, mle[3] + 1.5, length.out = 25)  gamma_grid <- gamma_grid[gamma_grid > 0] delta_grid <- delta_grid[delta_grid > 0] lambda_grid <- lambda_grid[lambda_grid > 0]  # Compute curvature measures for all pairs determinant_surface_gd <- matrix(NA, nrow = length(gamma_grid), ncol = length(delta_grid)) trace_surface_gd <- matrix(NA, nrow = length(gamma_grid), ncol = length(delta_grid))  determinant_surface_gl <- matrix(NA, nrow = length(gamma_grid), ncol = length(lambda_grid)) trace_surface_gl <- matrix(NA, nrow = length(gamma_grid), ncol = length(lambda_grid))  determinant_surface_dl <- matrix(NA, nrow = length(delta_grid), ncol = length(lambda_grid)) trace_surface_dl <- matrix(NA, nrow = length(delta_grid), ncol = length(lambda_grid))  # Gamma vs Delta for (i in seq_along(gamma_grid)) {   for (j in seq_along(delta_grid)) {     H <- hsmc(c(gamma_grid[i], delta_grid[j], mle[3]), data)     determinant_surface_gd[i, j] <- det(H)     trace_surface_gd[i, j] <- sum(diag(H))   } }  # Gamma vs Lambda for (i in seq_along(gamma_grid)) {   for (j in seq_along(lambda_grid)) {     H <- hsmc(c(gamma_grid[i], mle[2], lambda_grid[j]), data)     determinant_surface_gl[i, j] <- det(H)     trace_surface_gl[i, j] <- sum(diag(H))   } }  # Delta vs Lambda for (i in seq_along(delta_grid)) {   for (j in seq_along(lambda_grid)) {     H <- hsmc(c(mle[1], delta_grid[i], lambda_grid[j]), data)     determinant_surface_dl[i, j] <- det(H)     trace_surface_dl[i, j] <- sum(diag(H))   } }  # Plot all curvature surfaces side by side par(mfrow = c(2, 3), mar = c(4, 4, 3, 1))  # Determinant plots contour(gamma_grid, delta_grid, determinant_surface_gd,         xlab = expression(gamma), ylab = expression(delta),         main = \"Determinant: Gamma vs Delta\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(gamma_grid, lambda_grid, determinant_surface_gl,         xlab = expression(gamma), ylab = expression(lambda),         main = \"Determinant: Gamma vs Lambda\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(delta_grid, lambda_grid, determinant_surface_dl,         xlab = expression(delta), ylab = expression(lambda),         main = \"Determinant: Delta vs Lambda\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[2], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Trace plots contour(gamma_grid, delta_grid, trace_surface_gd,         xlab = expression(gamma), ylab = expression(delta),         main = \"Trace: Gamma vs Delta\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(gamma_grid, lambda_grid, trace_surface_gl,         xlab = expression(gamma), ylab = expression(lambda),         main = \"Trace: Gamma vs Lambda\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  contour(delta_grid, lambda_grid, trace_surface_dl,         xlab = expression(delta), ylab = expression(lambda),         main = \"Trace: Delta vs Lambda\", las = 1,         col = \"#2E4057\", lwd = 1.5, nlevels = 15) points(mle[2], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  legend(\"topright\",        legend = c(\"MLE\", \"True\"),        col = c(\"#8B0000\", \"#006400\"),        pch = c(19, 17),        bty = \"n\", cex = 0.8)   par(mfrow = c(1, 1))   ## Example 6: Confidence Ellipses (All pairs side by side)  # Extract all 2x2 submatrices vcov_gd <- vcov_matrix[1:2, 1:2] vcov_gl <- vcov_matrix[c(1, 3), c(1, 3)] vcov_dl <- vcov_matrix[2:3, 2:3]  # Create confidence ellipses theta <- seq(0, 2 * pi, length.out = 100) chi2_val <- qchisq(0.95, df = 2)  # Gamma vs Delta ellipse eig_decomp_gd <- eigen(vcov_gd) ellipse_gd <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_gd[i, ] <- mle[1:2] + sqrt(chi2_val) *     (eig_decomp_gd$vectors %*% diag(sqrt(eig_decomp_gd$values)) %*% v) }  # Gamma vs Lambda ellipse eig_decomp_gl <- eigen(vcov_gl) ellipse_gl <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_gl[i, ] <- mle[c(1, 3)] + sqrt(chi2_val) *     (eig_decomp_gl$vectors %*% diag(sqrt(eig_decomp_gl$values)) %*% v) }  # Delta vs Lambda ellipse eig_decomp_dl <- eigen(vcov_dl) ellipse_dl <- matrix(NA, nrow = 100, ncol = 2) for (i in 1:100) {   v <- c(cos(theta[i]), sin(theta[i]))   ellipse_dl[i, ] <- mle[2:3] + sqrt(chi2_val) *     (eig_decomp_dl$vectors %*% diag(sqrt(eig_decomp_dl$values)) %*% v) }  # Marginal confidence intervals se_gd <- sqrt(diag(vcov_gd)) ci_gamma_gd <- mle[1] + c(-1, 1) * 1.96 * se_gd[1] ci_delta_gd <- mle[2] + c(-1, 1) * 1.96 * se_gd[2]  se_gl <- sqrt(diag(vcov_gl)) ci_gamma_gl <- mle[1] + c(-1, 1) * 1.96 * se_gl[1] ci_lambda_gl <- mle[3] + c(-1, 1) * 1.96 * se_gl[2]  se_dl <- sqrt(diag(vcov_dl)) ci_delta_dl <- mle[2] + c(-1, 1) * 1.96 * se_dl[1] ci_lambda_dl <- mle[3] + c(-1, 1) * 1.96 * se_dl[2]  # Plot all three ellipses side by side par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Gamma vs Delta plot(ellipse_gd[, 1], ellipse_gd[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = expression(delta),      main = \"Gamma vs Delta\", las = 1, xlim = range(ellipse_gd[, 1], ci_gamma_gd),      ylim = range(ellipse_gd[, 2], ci_delta_gd)) abline(v = ci_gamma_gd, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_delta_gd, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Gamma vs Lambda plot(ellipse_gl[, 1], ellipse_gl[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = expression(lambda),      main = \"Gamma vs Lambda\", las = 1, xlim = range(ellipse_gl[, 1], ci_gamma_gl),      ylim = range(ellipse_gl[, 2], ci_lambda_gl)) abline(v = ci_gamma_gl, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_lambda_gl, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Delta vs Lambda plot(ellipse_dl[, 1], ellipse_dl[, 2], type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(delta), ylab = expression(lambda),      main = \"Delta vs Lambda\", las = 1, xlim = range(ellipse_dl[, 1], ci_delta_dl),      ylim = range(ellipse_dl[, 2], ci_lambda_dl)) abline(v = ci_delta_dl, col = \"#808080\", lty = 3, lwd = 1.5) abline(h = ci_lambda_dl, col = \"#808080\", lty = 3, lwd = 1.5) points(mle[2], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\", \"Marginal 95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\", \"#808080\"),        pch = c(19, 17, NA, NA),        lty = c(NA, NA, 1, 3),        lwd = c(NA, NA, 2, 1.5),        bty = \"n\", cex = 0.8)   par(mfrow = c(1, 1))  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/llbeta.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","title":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","text":"Computes negative log-likelihood function standard Beta distribution, using parameterization common generalized distribution families. distribution parameterized gamma (\\(\\gamma\\)) delta (\\(\\delta\\)), corresponding standard Beta distribution shape parameters shape1 = gamma shape2 = delta + 1. function suitable maximum likelihood estimation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbeta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","text":"","code":"llbeta(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/llbeta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","text":"par numeric vector length 2 containing distribution parameters order: gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbeta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","text":"Returns single double value representing negative log-likelihood (\\(-\\ell(\\theta|\\mathbf{x})\\)). Returns Inf parameter values par invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbeta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","text":"function calculates negative log-likelihood Beta distribution parameters shape1 = gamma (\\(\\gamma\\)) shape2 = delta + 1 (\\(\\delta+1\\)). probability density function (PDF) : $$ f(x | \\gamma, \\delta) = \\frac{x^{\\gamma-1} (1-x)^{\\delta}}{B(\\gamma, \\delta+1)} $$ \\(0 < x < 1\\), \\(B(,b)\\) Beta function (beta). log-likelihood function \\(\\ell(\\theta | \\mathbf{x})\\) sample \\(\\mathbf{x} = (x_1, \\dots, x_n)\\) \\(\\sum_{=1}^n \\ln f(x_i | \\theta)\\): $$ \\ell(\\theta | \\mathbf{x}) = \\sum_{=1}^{n} [(\\gamma-1)\\ln(x_i) + \\delta\\ln(1-x_i)] - n \\ln B(\\gamma, \\delta+1) $$ \\(\\theta = (\\gamma, \\delta)\\). function computes returns negative log-likelihood, \\(-\\ell(\\theta|\\mathbf{x})\\), suitable minimization using optimization routines like optim. equivalent negative log-likelihood GKw distribution (llgkw) evaluated \\(\\alpha=1, \\beta=1, \\lambda=1\\), also negative log-likelihood McDonald distribution (llmc) evaluated \\(\\lambda=1\\). term \\(\\ln B(\\gamma, \\delta+1)\\) typically computed using log-gamma functions (lgamma) numerical stability.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbeta.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","text":"Johnson, N. L., Kotz, S., & Balakrishnan, N. (1995). Continuous Univariate Distributions, Volume 2 (2nd ed.). Wiley. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation,","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/llbeta.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbeta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative Log-Likelihood for the Beta Distribution (gamma, delta+1 Parameterization) — llbeta","text":"","code":"# \\donttest{ ## Example 1: Basic Log-Likelihood Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(gamma = 2.0, delta = 3.0) data <- rbeta_(n, gamma = true_params[1], delta = true_params[2])  # Evaluate negative log-likelihood at true parameters nll_true <- llbeta(par = true_params, data = data) cat(\"Negative log-likelihood at true parameters:\", nll_true, \"\\n\") #> Negative log-likelihood at true parameters: -359.6415   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 2.5),   c(2.0, 3.0),   c(2.5, 3.5) )  nll_values <- apply(test_params, 1, function(p) llbeta(p, data)) results <- data.frame(   Gamma = test_params[, 1],   Delta = test_params[, 2],   NegLogLik = nll_values ) print(results, digits = 4) #>   Gamma Delta NegLogLik #> 1   1.5   2.5    -324.4 #> 2   2.0   3.0    -359.6 #> 3   2.5   3.5    -342.2   ## Example 2: Maximum Likelihood Estimation  # Optimization using L-BFGS-B with bounds fit <- optim(   par = c(1.5, 2.5),   fn = llbeta,   gr = grbeta,   data = data,   method = \"L-BFGS-B\",   lower = c(0.01, 0.01),   upper = c(100, 100),   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"gamma\", \"delta\") se <- sqrt(diag(solve(fit$hessian)))  results <- data.frame(   Parameter = c(\"gamma\", \"delta\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - 1.96 * se,   CI_Upper = mle + 1.96 * se ) print(results, digits = 4) #>       Parameter True   MLE      SE CI_Lower CI_Upper #> gamma     gamma    2 2.029 0.08495    1.862    2.195 #> delta     delta    3 2.997 0.17769    2.649    3.346  cat(sprintf(\"\\nMLE corresponds approx to Beta(%.2f, %.2f)\\n\",     mle[1], mle[2] + 1)) #>  #> MLE corresponds approx to Beta(2.03, 4.00) cat(\"True corresponds to Beta(%.2f, %.2f)\\n\",     true_params[1], true_params[2] + 1) #> True corresponds to Beta(%.2f, %.2f) #>  2 4  cat(\"\\nNegative log-likelihood at MLE:\", fit$value, \"\\n\") #>  #> Negative log-likelihood at MLE: -359.8439  cat(\"AIC:\", 2 * fit$value + 2 * length(mle), \"\\n\") #> AIC: -715.6878  cat(\"BIC:\", 2 * fit$value + length(mle) * log(n), \"\\n\") #> BIC: -705.8723    ## Example 3: Comparing Optimization Methods  methods <- c(\"BFGS\", \"L-BFGS-B\", \"Nelder-Mead\", \"CG\") start_params <- c(1.5, 2.5)  comparison <- data.frame(   Method = character(),   Gamma = numeric(),   Delta = numeric(),   NegLogLik = numeric(),   Convergence = integer(),   stringsAsFactors = FALSE )  for (method in methods) {   if (method %in% c(\"BFGS\", \"CG\")) {     fit_temp <- optim(       par = start_params,       fn = llbeta,       gr = grbeta,       data = data,       method = method     )   } else if (method == \"L-BFGS-B\") {     fit_temp <- optim(       par = start_params,       fn = llbeta,       gr = grbeta,       data = data,       method = method,       lower = c(0.01, 0.01),       upper = c(100, 100)     )   } else {     fit_temp <- optim(       par = start_params,       fn = llbeta,       data = data,       method = method     )   }    comparison <- rbind(comparison, data.frame(     Method = method,     Gamma = fit_temp$par[1],     Delta = fit_temp$par[2],     NegLogLik = fit_temp$value,     Convergence = fit_temp$convergence,     stringsAsFactors = FALSE   )) }  print(comparison, digits = 4, row.names = FALSE) #>       Method Gamma Delta NegLogLik Convergence #>         BFGS 2.029 2.997    -359.8           0 #>     L-BFGS-B 2.029 2.997    -359.8           0 #>  Nelder-Mead 2.029 2.997    -359.8           0 #>           CG 2.029 2.997    -359.8           0   ## Example 4: Likelihood Ratio Test  # Test H0: delta = 3 vs H1: delta free loglik_full <- -fit$value  restricted_ll <- function(params_restricted, data, delta_fixed) {   llbeta(par = c(params_restricted[1], delta_fixed), data = data) }  fit_restricted <- optim(   par = mle[1],   fn = restricted_ll,   data = data,   delta_fixed = 3,   method = \"BFGS\" )  loglik_restricted <- -fit_restricted$value lr_stat <- 2 * (loglik_full - loglik_restricted) p_value <- pchisq(lr_stat, df = 1, lower.tail = FALSE)  cat(\"LR Statistic:\", round(lr_stat, 4), \"\\n\") #> LR Statistic: 2e-04  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 0.9884    ## Example 5: Univariate Profile Likelihoods  # Profile for gamma gamma_grid <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = 50) gamma_grid <- gamma_grid[gamma_grid > 0] profile_ll_gamma <- numeric(length(gamma_grid))  for (i in seq_along(gamma_grid)) {   profile_fit <- optim(     par = mle[2],     fn = function(p) llbeta(c(gamma_grid[i], p), data),     method = \"BFGS\"   )   profile_ll_gamma[i] <- -profile_fit$value }  # Profile for delta delta_grid <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = 50) delta_grid <- delta_grid[delta_grid > 0] profile_ll_delta <- numeric(length(delta_grid))  for (i in seq_along(delta_grid)) {   profile_fit <- optim(     par = mle[1],     fn = function(p) llbeta(c(p, delta_grid[i]), data),     method = \"BFGS\"   )   profile_ll_delta[i] <- -profile_fit$value }  # 95% confidence threshold chi_crit <- qchisq(0.95, df = 1) threshold <- max(profile_ll_gamma) - chi_crit / 2  # Plot all profiles par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))  plot(gamma_grid, profile_ll_gamma, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", gamma)), las = 1) abline(v = mle[1], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[1], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  plot(delta_grid, profile_ll_delta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(delta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", delta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[2], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")   par(mfrow = c(1, 1))   ## Example 6: 2D Log-Likelihood Surface (Gamma vs Delta)  # Create 2D grid with wider range (±1.5) gamma_2d <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = round(n/25)) delta_2d <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = round(n/25)) gamma_2d <- gamma_2d[gamma_2d > 0] delta_2d <- delta_2d[delta_2d > 0]  # Compute log-likelihood surface ll_surface_gd <- matrix(NA, nrow = length(gamma_2d), ncol = length(delta_2d))  for (i in seq_along(gamma_2d)) {   for (j in seq_along(delta_2d)) {     ll_surface_gd[i, j] <- -llbeta(c(gamma_2d[i], delta_2d[j]), data)   } }  # Confidence region levels max_ll_gd <- max(ll_surface_gd, na.rm = TRUE) levels_90_gd <- max_ll_gd - qchisq(0.90, df = 2) / 2 levels_95_gd <- max_ll_gd - qchisq(0.95, df = 2) / 2 levels_99_gd <- max_ll_gd - qchisq(0.99, df = 2) / 2  # Plot contour par(mar = c(4, 4, 3, 1)) contour(gamma_2d, delta_2d, ll_surface_gd,         xlab = expression(gamma), ylab = expression(delta),         main = \"2D Log-Likelihood: Gamma vs Delta\",         levels = seq(min(ll_surface_gd, na.rm = TRUE), max_ll_gd, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(gamma_2d, delta_2d, ll_surface_gd,         levels = c(levels_90_gd, levels_95_gd, levels_99_gd),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/llbkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","title":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","text":"Computes negative log-likelihood function Beta-Kumaraswamy (BKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), given vector observations. distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\lambda = 1\\). function typically used maximum likelihood estimation via numerical optimization.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","text":"","code":"llbkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/llbkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","text":"par numeric vector length 4 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","text":"Returns single double value representing negative log-likelihood (\\(-\\ell(\\theta|\\mathbf{x})\\)). Returns Inf parameter values par invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","text":"Beta-Kumaraswamy (BKw) distribution GKw distribution (dgkw) \\(\\lambda=1\\). probability density function (PDF) : $$ f(x | \\theta) = \\frac{\\alpha \\beta}{B(\\gamma, \\delta+1)} x^{\\alpha - 1} \\bigl(1 - x^\\alpha\\bigr)^{\\beta(\\delta+1) - 1} \\bigl[1 - \\bigl(1 - x^\\alpha\\bigr)^\\beta\\bigr]^{\\gamma - 1} $$ \\(0 < x < 1\\), \\(\\theta = (\\alpha, \\beta, \\gamma, \\delta)\\), \\(B(,b)\\) Beta function (beta). log-likelihood function \\(\\ell(\\theta | \\mathbf{x})\\) sample \\(\\mathbf{x} = (x_1, \\dots, x_n)\\) \\(\\sum_{=1}^n \\ln f(x_i | \\theta)\\): $$ \\ell(\\theta | \\mathbf{x}) = n[\\ln(\\alpha) + \\ln(\\beta) - \\ln B(\\gamma, \\delta+1)] + \\sum_{=1}^{n} [(\\alpha-1)\\ln(x_i) + (\\beta(\\delta+1)-1)\\ln(v_i) + (\\gamma-1)\\ln(w_i)] $$ : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) function computes returns negative log-likelihood, \\(-\\ell(\\theta|\\mathbf{x})\\), suitable minimization using optimization routines like optim. Numerical stability maintained similarly llgkw.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/llbkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llbkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative Log-Likelihood for Beta-Kumaraswamy (BKw) Distribution — llbkw","text":"","code":"# \\donttest{ ## Example 1: Basic Log-Likelihood Evaluation  # Generate sample data set.seed(2203) n <- 1000 true_params <- c(alpha = 2.0, beta = 1.5, gamma = 1.5, delta = 0.5) data <- rbkw(n, alpha = true_params[1], beta = true_params[2],              gamma = true_params[3], delta = true_params[4])  # Evaluate negative log-likelihood at true parameters nll_true <- llbkw(par = true_params, data = data) cat(\"Negative log-likelihood at true parameters:\", nll_true, \"\\n\") #> Negative log-likelihood at true parameters: -268.3902   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 1.0, 1.0, 0.3),   c(2.0, 1.5, 1.5, 0.5),   c(2.5, 2.0, 2.0, 0.7) )  nll_values <- apply(test_params, 1, function(p) llbkw(p, data)) results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Gamma = test_params[, 3],   Delta = test_params[, 4],   NegLogLik = nll_values ) print(results, digits = 4) #>   Alpha Beta Gamma Delta NegLogLik #> 1   1.5  1.0   1.0   0.3    -145.5 #> 2   2.0  1.5   1.5   0.5    -268.4 #> 3   2.5  2.0   2.0   0.7    -162.6   ## Example 2: Maximum Likelihood Estimation  # Optimization using BFGS with no analytical gradient fit <- optim(   par = c(0.5, 1, 1.1, 0.3),   fn = llbkw,   # gr = grbkw,   data = data,   method = \"BFGS\",   control = list(maxit = 2000),   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\", \"gamma\", \"delta\") se <- sqrt(diag(solve(fit$hessian)))  results <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"gamma\", \"delta\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - 1.96 * se,   CI_Upper = mle + 1.96 * se ) print(results, digits = 4) #>       Parameter True     MLE     SE CI_Lower CI_Upper #> alpha     alpha  2.0 2.51814 0.7638   1.0211    4.015 #> beta       beta  1.5 2.36948 4.7050  -6.8524   11.591 #> gamma     gamma  1.5 1.15022 0.4221   0.3228    1.978 #> delta     delta  0.5 0.04233 2.0842  -4.0427    4.127  cat(\"\\nNegative log-likelihood at MLE:\", fit$value, \"\\n\") #>  #> Negative log-likelihood at MLE: -270.2379  cat(\"AIC:\", 2 * fit$value + 2 * length(mle), \"\\n\") #> AIC: -532.4758  cat(\"BIC:\", 2 * fit$value + length(mle) * log(n), \"\\n\") #> BIC: -512.8448    ## Example 3: Comparing Optimization Methods  methods <- c(\"BFGS\", \"L-BFGS-B\", \"Nelder-Mead\", \"CG\") start_params <- c(1.8, 1.2, 1.1, 0.3)  comparison <- data.frame(   Method = character(),   Alpha = numeric(),   Beta = numeric(),   Gamma = numeric(),   Delta = numeric(),   NegLogLik = numeric(),   Convergence = integer(),   stringsAsFactors = FALSE )  for (method in methods) {   if (method %in% c(\"BFGS\", \"CG\")) {     fit_temp <- optim(       par = start_params,       fn = llbkw,       gr = grbkw,       data = data,       method = method     )   } else if (method == \"L-BFGS-B\") {     fit_temp <- optim(       par = start_params,       fn = llbkw,       gr = grbkw,       data = data,       method = method,       lower = c(0.01, 0.01, 0.01, 0.01),       upper = c(100, 100, 100, 100)     )   } else {     fit_temp <- optim(       par = start_params,       fn = llbkw,       data = data,       method = method     )   }    comparison <- rbind(comparison, data.frame(     Method = method,     Alpha = fit_temp$par[1],     Beta = fit_temp$par[2],     Gamma = fit_temp$par[3],     Delta = fit_temp$par[4],     NegLogLik = fit_temp$value,     Convergence = fit_temp$convergence,     stringsAsFactors = FALSE   )) }  print(comparison, digits = 4, row.names = FALSE) #>       Method Alpha  Beta Gamma     Delta NegLogLik Convergence #>         BFGS 2.528 2.470 1.145 0.0001526    -270.2           0 #>     L-BFGS-B 2.528 2.446 1.145 0.0100000    -270.2           0 #>  Nelder-Mead 2.570 2.332 1.122 0.0670160    -270.2           1 #>           CG 2.516 1.603 1.147 0.5552087    -270.2           1   ## Example 4: Likelihood Ratio Test  # Test H0: delta = 0.5 vs H1: delta free loglik_full <- -fit$value  restricted_ll <- function(params_restricted, data, delta_fixed) {   llbkw(par = c(params_restricted[1], params_restricted[2],                 params_restricted[3], delta_fixed), data = data) }  fit_restricted <- optim(   par = mle[1:3],   fn = restricted_ll,   data = data,   delta_fixed = 0.5,   method = \"Nelder-Mead\" )  loglik_restricted <- -fit_restricted$value lr_stat <- 2 * (loglik_full - loglik_restricted) p_value <- pchisq(lr_stat, df = 1, lower.tail = FALSE)  cat(\"LR Statistic:\", round(lr_stat, 4), \"\\n\") #> LR Statistic: 0.0493  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 0.8244    ## Example 5: Univariate Profile Likelihoods  # Profile for alpha alpha_grid <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = 50) alpha_grid <- alpha_grid[alpha_grid > 0] profile_ll_alpha <- numeric(length(alpha_grid))  for (i in seq_along(alpha_grid)) {   profile_fit <- optim(     par = mle[-1],     fn = function(p) llbkw(c(alpha_grid[i], p), data),     method = \"Nelder-Mead\"   )   profile_ll_alpha[i] <- -profile_fit$value }  # Profile for beta beta_grid <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = 50) beta_grid <- beta_grid[beta_grid > 0] profile_ll_beta <- numeric(length(beta_grid))  for (i in seq_along(beta_grid)) {   profile_fit <- optim(     par = c(mle[1], mle[3], mle[4]),     fn = function(p) llbkw(c(mle[1], beta_grid[i], p[1], p[2]), data),     method = \"Nelder-Mead\"   )   profile_ll_beta[i] <- -profile_fit$value }  # Profile for gamma gamma_grid <- seq(mle[3] - 1.5, mle[3] + 1.5, length.out = 50) gamma_grid <- gamma_grid[gamma_grid > 0] profile_ll_gamma <- numeric(length(gamma_grid))  for (i in seq_along(gamma_grid)) {   profile_fit <- optim(     par = c(mle[1], mle[2], mle[4]),     fn = function(p) llbkw(c(p[1], mle[2], gamma_grid[i], p[2]), data),     method = \"Nelder-Mead\"   )   profile_ll_gamma[i] <- -profile_fit$value }  # Profile for delta delta_grid <- seq(mle[4] - 1.5, mle[4] + 1.5, length.out = 50) delta_grid <- delta_grid[delta_grid > 0] profile_ll_delta <- numeric(length(delta_grid))  for (i in seq_along(delta_grid)) {   profile_fit <- optim(     par = mle[-4],     fn = function(p) llbkw(c(p[1], p[2], p[3], delta_grid[i]), data),     method = \"Nelder-Mead\"   )   profile_ll_delta[i] <- -profile_fit$value }  # 95% confidence threshold chi_crit <- qchisq(0.95, df = 1) threshold <- max(profile_ll_alpha) - chi_crit / 2  # Plot all profiles par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))  plot(alpha_grid, profile_ll_alpha, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", alpha)), las = 1) abline(v = mle[1], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[1], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  plot(beta_grid, profile_ll_beta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", beta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[2], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  plot(gamma_grid, profile_ll_gamma, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", gamma)), las = 1) abline(v = mle[3], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[3], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  plot(delta_grid, profile_ll_delta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(delta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", delta)), las = 1) abline(v = mle[4], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[4], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")   par(mfrow = c(1, 1))   ## Example 6: 2D Log-Likelihood Surfaces (Selected pairs)  # Create 2D grids with wider range (±1.5) alpha_2d <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = round(n/25)) beta_2d <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = round(n/25)) gamma_2d <- seq(mle[3] - 1.5, mle[3] + 1.5, length.out = round(n/25)) delta_2d <- seq(mle[4] - 1.5, mle[4] + 1.5, length.out = round(n/25))  alpha_2d <- alpha_2d[alpha_2d > 0] beta_2d <- beta_2d[beta_2d > 0] gamma_2d <- gamma_2d[gamma_2d > 0] delta_2d <- delta_2d[delta_2d > 0]  # Compute selected log-likelihood surfaces ll_surface_ab <- matrix(NA, nrow = length(alpha_2d), ncol = length(beta_2d)) ll_surface_ag <- matrix(NA, nrow = length(alpha_2d), ncol = length(gamma_2d)) ll_surface_bd <- matrix(NA, nrow = length(beta_2d), ncol = length(delta_2d))  # Alpha vs Beta for (i in seq_along(alpha_2d)) {   for (j in seq_along(beta_2d)) {     ll_surface_ab[i, j] <- -llbkw(c(alpha_2d[i], beta_2d[j], mle[3], mle[4]), data)   } }  # Alpha vs Gamma for (i in seq_along(alpha_2d)) {   for (j in seq_along(gamma_2d)) {     ll_surface_ag[i, j] <- -llbkw(c(alpha_2d[i], mle[2], gamma_2d[j], mle[4]), data)   } }  # Beta vs Delta for (i in seq_along(beta_2d)) {   for (j in seq_along(delta_2d)) {     ll_surface_bd[i, j] <- -llbkw(c(mle[1], beta_2d[i], mle[3], delta_2d[j]), data)   } }  # Confidence region levels max_ll_ab <- max(ll_surface_ab, na.rm = TRUE) max_ll_ag <- max(ll_surface_ag, na.rm = TRUE) max_ll_bd <- max(ll_surface_bd, na.rm = TRUE)  levels_95_ab <- max_ll_ab - qchisq(0.95, df = 2) / 2 levels_95_ag <- max_ll_ag - qchisq(0.95, df = 2) / 2 levels_95_bd <- max_ll_bd - qchisq(0.95, df = 2) / 2  # Plot selected surfaces side by side par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Alpha vs Beta contour(alpha_2d, beta_2d, ll_surface_ab,         xlab = expression(alpha), ylab = expression(beta),         main = \"Alpha vs Beta\", las = 1,         levels = seq(min(ll_surface_ab, na.rm = TRUE), max_ll_ab, length.out = 20),         col = \"#2E4057\", lwd = 1) contour(alpha_2d, beta_2d, ll_surface_ab,         levels = levels_95_ab, col = \"#FF6347\", lwd = 2.5, lty = 1, add = TRUE) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Alpha vs Gamma contour(alpha_2d, gamma_2d, ll_surface_ag,         xlab = expression(alpha), ylab = expression(gamma),         main = \"Alpha vs Gamma\", las = 1,         levels = seq(min(ll_surface_ag, na.rm = TRUE), max_ll_ag, length.out = 20),         col = \"#2E4057\", lwd = 1) contour(alpha_2d, gamma_2d, ll_surface_ag,         levels = levels_95_ag, col = \"#FF6347\", lwd = 2.5, lty = 1, add = TRUE) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Beta vs Delta contour(beta_2d, delta_2d, ll_surface_bd,         xlab = expression(beta), ylab = expression(delta),         main = \"Beta vs Delta\", las = 1,         levels = seq(min(ll_surface_bd, na.rm = TRUE), max_ll_bd, length.out = 20),         col = \"#2E4057\", lwd = 1) contour(beta_2d, delta_2d, ll_surface_bd,         levels = levels_95_bd, col = \"#FF6347\", lwd = 2.5, lty = 1, add = TRUE) points(mle[2], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[4], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FF6347\"),        pch = c(19, 17, NA),        lty = c(NA, NA, 1),        lwd = c(NA, NA, 2.5),        bty = \"n\", cex = 0.8)   par(mfrow = c(1, 1))  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/llekw.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","title":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","text":"Computes negative log-likelihood function Exponentiated Kumaraswamy (EKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), lambda (\\(\\lambda\\)), given vector observations. distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\) \\(\\delta = 0\\). function suitable maximum likelihood estimation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llekw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","text":"","code":"llekw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/llekw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","text":"par numeric vector length 3 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llekw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","text":"Returns single double value representing negative log-likelihood (\\(-\\ell(\\theta|\\mathbf{x})\\)). Returns Inf parameter values par invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llekw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","text":"Exponentiated Kumaraswamy (EKw) distribution GKw distribution (dekw) \\(\\gamma=1\\) \\(\\delta=0\\). probability density function (PDF) : $$ f(x | \\theta) = \\lambda \\alpha \\beta x^{\\alpha-1} (1 - x^\\alpha)^{\\beta-1} \\bigl[1 - (1 - x^\\alpha)^\\beta \\bigr]^{\\lambda - 1} $$ \\(0 < x < 1\\) \\(\\theta = (\\alpha, \\beta, \\lambda)\\). log-likelihood function \\(\\ell(\\theta | \\mathbf{x})\\) sample \\(\\mathbf{x} = (x_1, \\dots, x_n)\\) \\(\\sum_{=1}^n \\ln f(x_i | \\theta)\\): $$ \\ell(\\theta | \\mathbf{x}) = n[\\ln(\\lambda) + \\ln(\\alpha) + \\ln(\\beta)] + \\sum_{=1}^{n} [(\\alpha-1)\\ln(x_i) + (\\beta-1)\\ln(v_i) + (\\lambda-1)\\ln(w_i)] $$ : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) function computes returns negative log-likelihood, \\(-\\ell(\\theta|\\mathbf{x})\\), suitable minimization using optimization routines like optim. Numerical stability maintained similarly llgkw.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llekw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","text":"Nadarajah, S., Cordeiro, G. M., & Ortega, E. M. (2012). exponentiated Kumaraswamy distribution. Journal Franklin Institute, 349(3), Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/llekw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llekw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative Log-Likelihood for the Exponentiated Kumaraswamy (EKw) Distribution — llekw","text":"","code":"# \\donttest{ ## Example 1: Basic Log-Likelihood Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.5, beta = 3.5, lambda = 2.0) data <- rekw(n, alpha = true_params[1], beta = true_params[2],              lambda = true_params[3])  # Evaluate negative log-likelihood at true parameters nll_true <- llekw(par = true_params, data = data) cat(\"Negative log-likelihood at true parameters:\", nll_true, \"\\n\") #> Negative log-likelihood at true parameters: -491.1647   # Evaluate at different parameter values test_params <- rbind(   c(2.0, 3.0, 1.5),   c(2.5, 3.5, 2.0),   c(3.0, 4.0, 2.5) )  nll_values <- apply(test_params, 1, function(p) llekw(p, data)) results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Lambda = test_params[, 3],   NegLogLik = nll_values ) print(results, digits = 4) #>   Alpha Beta Lambda NegLogLik #> 1   2.0  3.0    1.5    -371.3 #> 2   2.5  3.5    2.0    -491.2 #> 3   3.0  4.0    2.5    -375.3   ## Example 2: Maximum Likelihood Estimation  # Optimization using BFGS with analytical gradient fit <- optim(   par = c(2, 3, 1.5),   fn = llekw,   gr = grekw,   data = data,   method = \"BFGS\",   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\", \"lambda\") se <- sqrt(diag(solve(fit$hessian)))  results <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"lambda\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - 1.96 * se,   CI_Upper = mle + 1.96 * se ) print(results, digits = 4) #>        Parameter True   MLE     SE CI_Lower CI_Upper #> alpha      alpha  2.5 2.663 0.5852   1.5156    3.810 #> beta        beta  3.5 3.653 0.4023   2.8643    4.441 #> lambda    lambda  2.0 1.843 0.5776   0.7107    2.975  cat(\"\\nNegative log-likelihood at MLE:\", fit$value, \"\\n\") #>  #> Negative log-likelihood at MLE: -491.2984  cat(\"AIC:\", 2 * fit$value + 2 * length(mle), \"\\n\") #> AIC: -976.5968  cat(\"BIC:\", 2 * fit$value + length(mle) * log(n), \"\\n\") #> BIC: -961.8735    ## Example 3: Comparing Optimization Methods  methods <- c(\"BFGS\", \"L-BFGS-B\", \"Nelder-Mead\", \"CG\") start_params <- c(2, 3, 1.5)  comparison <- data.frame(   Method = character(),   Alpha = numeric(),   Beta = numeric(),   Lambda = numeric(),   NegLogLik = numeric(),   Convergence = integer(),   stringsAsFactors = FALSE )  for (method in methods) {   if (method %in% c(\"BFGS\", \"CG\")) {     fit_temp <- optim(       par = start_params,       fn = llekw,       gr = grekw,       data = data,       method = method     )   } else if (method == \"L-BFGS-B\") {     fit_temp <- optim(       par = start_params,       fn = llekw,       gr = grekw,       data = data,       method = method,       lower = c(0.01, 0.01, 0.01),       upper = c(100, 100, 100)     )   } else {     fit_temp <- optim(       par = start_params,       fn = llekw,       data = data,       method = method     )   }    comparison <- rbind(comparison, data.frame(     Method = method,     Alpha = fit_temp$par[1],     Beta = fit_temp$par[2],     Lambda = fit_temp$par[3],     NegLogLik = fit_temp$value,     Convergence = fit_temp$convergence,     stringsAsFactors = FALSE   )) }  print(comparison, digits = 4, row.names = FALSE) #>       Method Alpha  Beta Lambda NegLogLik Convergence #>         BFGS 2.663 3.653  1.843    -491.3           0 #>     L-BFGS-B 2.663 3.653  1.843    -491.3           0 #>  Nelder-Mead 2.662 3.652  1.843    -491.3           0 #>           CG 2.505 3.552  2.008    -491.3           1   ## Example 4: Likelihood Ratio Test  # Test H0: lambda = 2 vs H1: lambda free loglik_full <- -fit$value  restricted_ll <- function(params_restricted, data, lambda_fixed) {   llekw(par = c(params_restricted[1], params_restricted[2],                 lambda_fixed), data = data) }  fit_restricted <- optim(   par = c(mle[1], mle[2]),   fn = restricted_ll,   data = data,   lambda_fixed = 2,   method = \"BFGS\" )  loglik_restricted <- -fit_restricted$value lr_stat <- 2 * (loglik_full - loglik_restricted) p_value <- pchisq(lr_stat, df = 1, lower.tail = FALSE)  cat(\"LR Statistic:\", round(lr_stat, 4), \"\\n\") #> LR Statistic: 0.0657  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 0.7977    ## Example 5: Univariate Profile Likelihoods  # Profile for alpha alpha_grid <- seq(mle[1] - 1, mle[1] + 1, length.out = 50) alpha_grid <- alpha_grid[alpha_grid > 0] profile_ll_alpha <- numeric(length(alpha_grid))  for (i in seq_along(alpha_grid)) {   profile_fit <- optim(     par = mle[-1],     fn = function(p) llekw(c(alpha_grid[i], p), data),     method = \"BFGS\"   )   profile_ll_alpha[i] <- -profile_fit$value }  # Profile for beta beta_grid <- seq(mle[2] - 1, mle[2] + 1, length.out = 50) beta_grid <- beta_grid[beta_grid > 0] profile_ll_beta <- numeric(length(beta_grid))  for (i in seq_along(beta_grid)) {   profile_fit <- optim(     par = mle[-2],     fn = function(p) llekw(c(p[1], beta_grid[i], p[2]), data),     method = \"BFGS\"   )   profile_ll_beta[i] <- -profile_fit$value }  # Profile for lambda lambda_grid <- seq(mle[3] - 1, mle[3] + 1, length.out = 50) lambda_grid <- lambda_grid[lambda_grid > 0] profile_ll_lambda <- numeric(length(lambda_grid))  for (i in seq_along(lambda_grid)) {   profile_fit <- optim(     par = mle[-3],     fn = function(p) llekw(c(p[1], p[2], lambda_grid[i]), data),     method = \"BFGS\"   )   profile_ll_lambda[i] <- -profile_fit$value }  # 95% confidence threshold chi_crit <- qchisq(0.95, df = 1) threshold <- max(profile_ll_alpha) - chi_crit / 2  # Plot all profiles par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  plot(alpha_grid, profile_ll_alpha, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", alpha)), las = 1) abline(v = mle[1], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[1], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  plot(beta_grid, profile_ll_beta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", beta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[2], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  plot(lambda_grid, profile_ll_lambda, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(lambda), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", lambda)), las = 1) abline(v = mle[3], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[3], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")   par(mfrow = c(1, 1))   ## Example 6: 2D Log-Likelihood Surface (Alpha vs Beta)  par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Create 2D grid alpha_2d <- seq(mle[1] - 0.8, mle[1] + 0.8, length.out = round(n/25)) beta_2d <- seq(mle[2] - 0.8, mle[2] + 0.8, length.out = round(n/25)) alpha_2d <- alpha_2d[alpha_2d > 0] beta_2d <- beta_2d[beta_2d > 0]  # Compute log-likelihood surface ll_surface_ab <- matrix(NA, nrow = length(alpha_2d), ncol = length(beta_2d))  for (i in seq_along(alpha_2d)) {   for (j in seq_along(beta_2d)) {     ll_surface_ab[i, j] <- -llekw(c(alpha_2d[i], beta_2d[j], mle[3]), data)   } }  # Confidence region levels max_ll_ab <- max(ll_surface_ab, na.rm = TRUE) levels_90_ab <- max_ll_ab - qchisq(0.90, df = 2) / 2 levels_95_ab <- max_ll_ab - qchisq(0.95, df = 2) / 2 levels_99_ab <- max_ll_ab - qchisq(0.99, df = 2) / 2  # Plot contour contour(alpha_2d, beta_2d, ll_surface_ab,         xlab = expression(alpha), ylab = expression(beta),         main = \"2D Log-Likelihood: Alpha vs Beta\",         levels = seq(min(ll_surface_ab, na.rm = TRUE), max_ll_ab, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(alpha_2d, beta_2d, ll_surface_ab,         levels = c(levels_90_ab, levels_95_ab, levels_99_ab),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   ## Example 7: 2D Log-Likelihood Surface (Alpha vs Lambda)  # Create 2D grid alpha_2d_2 <- seq(mle[1] - 0.8, mle[1] + 0.8, length.out = round(n/25)) lambda_2d <- seq(mle[3] - 0.8, mle[3] + 0.8, length.out = round(n/25)) alpha_2d_2 <- alpha_2d_2[alpha_2d_2 > 0] lambda_2d <- lambda_2d[lambda_2d > 0]  # Compute log-likelihood surface ll_surface_al <- matrix(NA, nrow = length(alpha_2d_2), ncol = length(lambda_2d))  for (i in seq_along(alpha_2d_2)) {   for (j in seq_along(lambda_2d)) {     ll_surface_al[i, j] <- -llekw(c(alpha_2d_2[i], mle[2], lambda_2d[j]), data)   } }  # Confidence region levels max_ll_al <- max(ll_surface_al, na.rm = TRUE) levels_90_al <- max_ll_al - qchisq(0.90, df = 2) / 2 levels_95_al <- max_ll_al - qchisq(0.95, df = 2) / 2 levels_99_al <- max_ll_al - qchisq(0.99, df = 2) / 2  # Plot contour contour(alpha_2d_2, lambda_2d, ll_surface_al,         xlab = expression(alpha), ylab = expression(lambda),         main = \"2D Log-Likelihood: Alpha vs Lambda\",         levels = seq(min(ll_surface_al, na.rm = TRUE), max_ll_al, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(alpha_2d_2, lambda_2d, ll_surface_al,         levels = c(levels_90_al, levels_95_al, levels_99_al),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   ## Example 8: 2D Log-Likelihood Surface (Beta vs Lambda)  # Create 2D grid beta_2d_2 <- seq(mle[2] - 0.8, mle[2] + 0.8, length.out = round(n/25)) lambda_2d_2 <- seq(mle[3] - 0.8, mle[3] + 0.8, length.out = round(n/25)) beta_2d_2 <- beta_2d_2[beta_2d_2 > 0] lambda_2d_2 <- lambda_2d_2[lambda_2d_2 > 0]  # Compute log-likelihood surface ll_surface_bl <- matrix(NA, nrow = length(beta_2d_2), ncol = length(lambda_2d_2))  for (i in seq_along(beta_2d_2)) {   for (j in seq_along(lambda_2d_2)) {     ll_surface_bl[i, j] <- -llekw(c(mle[1], beta_2d_2[i], lambda_2d_2[j]), data)   } }  # Confidence region levels max_ll_bl <- max(ll_surface_bl, na.rm = TRUE) levels_90_bl <- max_ll_bl - qchisq(0.90, df = 2) / 2 levels_95_bl <- max_ll_bl - qchisq(0.95, df = 2) / 2 levels_99_bl <- max_ll_bl - qchisq(0.99, df = 2) / 2  # Plot contour contour(beta_2d_2, lambda_2d_2, ll_surface_bl,         xlab = expression(beta), ylab = expression(lambda),         main = \"2D Log-Likelihood: Beta vs Lambda\",         levels = seq(min(ll_surface_bl, na.rm = TRUE), max_ll_bl, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(beta_2d_2, lambda_2d_2, ll_surface_bl,         levels = c(levels_90_bl, levels_95_bl, levels_99_bl),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[2], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[3], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/llgkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","title":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","text":"Computes negative log-likelihood function five-parameter Generalized Kumaraswamy (GKw) distribution given vector observations. function designed use optimization routines (e.g., maximum likelihood estimation).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llgkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","text":"","code":"llgkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/llgkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","text":"par numeric vector length 5 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llgkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","text":"Returns single double value representing negative log-likelihood (\\(-\\ell(\\theta|\\mathbf{x})\\)). Returns large positive value (e.g., Inf) parameter values par invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llgkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","text":"probability density function (PDF) GKw distribution given dgkw. log-likelihood function \\(\\ell(\\theta)\\) sample \\(\\mathbf{x} = (x_1, \\dots, x_n)\\) : $$ \\ell(\\theta | \\mathbf{x}) = n\\ln(\\lambda\\alpha\\beta) - n\\ln B(\\gamma,\\delta+1) +   \\sum_{=1}^{n} [(\\alpha-1)\\ln(x_i) + (\\beta-1)\\ln(v_i) + (\\gamma\\lambda-1)\\ln(w_i) + \\delta\\ln(z_i)] $$ \\(\\theta = (\\alpha, \\beta, \\gamma, \\delta, \\lambda)\\), \\(B(,b)\\) Beta function (beta), : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) \\(z_i = 1 - w_i^{\\lambda} = 1 - [1-(1-x_i^{\\alpha})^{\\beta}]^{\\lambda}\\) function computes \\(-\\ell(\\theta|\\mathbf{x})\\). Numerical stability prioritized using: lbeta function log-Beta term. Log-transformations intermediate terms (\\(v_i, w_i, z_i\\)) use log1p appropriate handle values close 0 1 accurately. Checks invalid parameters data.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llgkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/llgkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llgkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative Log-Likelihood for the Generalized Kumaraswamy Distribution — llgkw","text":"","code":"# \\donttest{ ## Example 1: Basic Log-Likelihood Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.0, beta = 3.0, gamma = 1.5, delta = 2.0, lambda = 1.8) data <- rgkw(n, alpha = true_params[1], beta = true_params[2],              gamma = true_params[3], delta = true_params[4],              lambda = true_params[5])  # Evaluate negative log-likelihood at true parameters nll_true <- llgkw(par = true_params, data = data) cat(\"Negative log-likelihood at true parameters:\", nll_true, \"\\n\") #> Negative log-likelihood at true parameters: -703.5634   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 2.5, 1.2, 1.5, 1.5),   c(2.0, 3.0, 1.5, 2.0, 1.8),   c(2.5, 3.5, 1.8, 2.5, 2.0) )  nll_values <- apply(test_params, 1, function(p) llgkw(p, data)) results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Gamma = test_params[, 3],   Delta = test_params[, 4],   Lambda = test_params[, 5],   NegLogLik = nll_values ) print(results, digits = 4) #>   Alpha Beta Gamma Delta Lambda NegLogLik #> 1   1.5  2.5   1.2   1.5    1.5    -376.1 #> 2   2.0  3.0   1.5   2.0    1.8    -703.6 #> 3   2.5  3.5   1.8   2.5    2.0    -425.3   ## Example 2: Maximum Likelihood Estimation  # Optimization using BFGS with analytical gradient fit <- optim(   par = c(1.5, 2.5, 1.2, 1.5, 1.5),   fn = llgkw,   gr = grgkw,   data = data,   method = \"BFGS\",   hessian = TRUE,   control = list(maxit = 1000) )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\") se <- sqrt(diag(solve(fit$hessian)))  results <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"gamma\", \"delta\", \"lambda\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - 1.96 * se,   CI_Upper = mle + 1.96 * se ) print(results, digits = 4) #>        Parameter True     MLE     SE CI_Lower CI_Upper #> alpha      alpha  2.0  1.3491  2.383  -3.3210    6.019 #> beta        beta  3.0  3.6261  5.065  -6.3019   13.554 #> gamma      gamma  1.5  0.3486  0.367  -0.3706    1.068 #> delta      delta  2.0  1.2537  2.807  -4.2485    6.756 #> lambda    lambda  1.8 13.3084 25.690 -37.0446   63.662  cat(\"\\nNegative log-likelihood at MLE:\", fit$value, \"\\n\") #>  #> Negative log-likelihood at MLE: -704.3269  cat(\"AIC:\", 2 * fit$value + 2 * length(mle), \"\\n\") #> AIC: -1398.654  cat(\"BIC:\", 2 * fit$value + length(mle) * log(n), \"\\n\") #> BIC: -1374.115    ## Example 3: Comparing Optimization Methods  methods <- c(\"BFGS\", \"Nelder-Mead\") start_params <- c(1.5, 2.5, 1.2, 1.5, 1.5)  comparison <- data.frame(   Method = character(),   Alpha = numeric(),   Beta = numeric(),   Gamma = numeric(),   Delta = numeric(),   Lambda = numeric(),   NegLogLik = numeric(),   Convergence = integer(),   stringsAsFactors = FALSE )  for (method in methods) {   if (method == \"BFGS\") {     fit_temp <- optim(       par = start_params,       fn = llgkw,       gr = grgkw,       data = data,       method = method,       control = list(maxit = 1000)     )   } else if (method == \"L-BFGS-B\") {     fit_temp <- optim(       par = start_params,       fn = llgkw,       gr = grgkw,       data = data,       method = method,       lower = rep(0.001, 5),       upper = rep(20, 5),       control = list(maxit = 1000)     )   } else {     fit_temp <- optim(       par = start_params,       fn = llgkw,       data = data,       method = method,       control = list(maxit = 1000)     )   }    comparison <- rbind(comparison, data.frame(     Method = method,     Alpha = fit_temp$par[1],     Beta = fit_temp$par[2],     Gamma = fit_temp$par[3],     Delta = fit_temp$par[4],     Lambda = fit_temp$par[5],     NegLogLik = fit_temp$value,     Convergence = fit_temp$convergence,     stringsAsFactors = FALSE   )) }  print(comparison, digits = 4, row.names = FALSE) #>       Method Alpha  Beta  Gamma Delta Lambda NegLogLik Convergence #>         BFGS 1.349 3.626 0.3486 1.254 13.308    -704.3           0 #>  Nelder-Mead 1.868 3.136 1.0095 1.870  2.826    -704.0           0   ## Example 4: Likelihood Ratio Test  # Test H0: gamma = 1.5 vs H1: gamma free loglik_full <- -fit$value  restricted_ll <- function(params_restricted, data, gamma_fixed) {   llgkw(par = c(params_restricted[1], params_restricted[2],                 gamma_fixed, params_restricted[3], params_restricted[4]),         data = data) }  fit_restricted <- optim(   par = c(mle[1], mle[2], mle[4], mle[5]),   fn = restricted_ll,   data = data,   gamma_fixed = 1.5,   method = \"Nelder-Mead\",   control = list(maxit = 1000) )  loglik_restricted <- -fit_restricted$value lr_stat <- 2 * (loglik_full - loglik_restricted) p_value <- pchisq(lr_stat, df = 1, lower.tail = FALSE)  cat(\"LR Statistic:\", round(lr_stat, 4), \"\\n\") #> LR Statistic: 0.7391  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 0.39    ## Example 5: Univariate Profile Likelihoods  # Profile for alpha xd <- 1 alpha_grid <- seq(mle[1] - xd, mle[1] + xd, length.out = 35) alpha_grid <- alpha_grid[alpha_grid > 0] profile_ll_alpha <- numeric(length(alpha_grid))  for (i in seq_along(alpha_grid)) {   profile_fit <- optim(     par = mle[-1],     fn = function(p) llgkw(c(alpha_grid[i], p), data),     method = \"Nelder-Mead\",     control = list(maxit = 500)   )   profile_ll_alpha[i] <- -profile_fit$value }  # Profile for beta beta_grid <- seq(mle[2] - xd, mle[2] + xd, length.out = 35) beta_grid <- beta_grid[beta_grid > 0] profile_ll_beta <- numeric(length(beta_grid))  for (i in seq_along(beta_grid)) {   profile_fit <- optim(     par = mle[-2],     fn = function(p) llgkw(c(p[1], beta_grid[i], p[2], p[3], p[4]), data),     method = \"Nelder-Mead\",     control = list(maxit = 500)   )   profile_ll_beta[i] <- -profile_fit$value }  # Profile for gamma gamma_grid <- seq(mle[3] - xd, mle[3] + xd, length.out = 35) gamma_grid <- gamma_grid[gamma_grid > 0] profile_ll_gamma <- numeric(length(gamma_grid))  for (i in seq_along(gamma_grid)) {   profile_fit <- optim(     par = mle[-3],     fn = function(p) llgkw(c(p[1], p[2], gamma_grid[i], p[3], p[4]), data),     method = \"Nelder-Mead\",     control = list(maxit = 500)   )   profile_ll_gamma[i] <- -profile_fit$value }  # Profile for delta delta_grid <- seq(mle[4] - xd, mle[4] + xd, length.out = 35) delta_grid <- delta_grid[delta_grid > 0] profile_ll_delta <- numeric(length(delta_grid))  for (i in seq_along(delta_grid)) {   profile_fit <- optim(     par = mle[-4],     fn = function(p) llgkw(c(p[1], p[2], p[3], delta_grid[i], p[4]), data),     method = \"Nelder-Mead\",     control = list(maxit = 500)   )   profile_ll_delta[i] <- -profile_fit$value }  # Profile for lambda lambda_grid <- seq(mle[5] - xd, mle[5] + xd, length.out = 35) lambda_grid <- lambda_grid[lambda_grid > 0] profile_ll_lambda <- numeric(length(lambda_grid))  for (i in seq_along(lambda_grid)) {   profile_fit <- optim(     par = mle[-5],     fn = function(p) llgkw(c(p[1], p[2], p[3], p[4], lambda_grid[i]), data),     method = \"Nelder-Mead\",     control = list(maxit = 500)   )   profile_ll_lambda[i] <- -profile_fit$value }  # 95% confidence threshold chi_crit <- qchisq(0.95, df = 1) threshold <- max(profile_ll_alpha) - chi_crit / 2  # Plot all profiles par(mfrow = c(2, 3), mar = c(4, 4, 3, 1))  plot(alpha_grid, profile_ll_alpha, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", alpha)), las = 1) abline(v = mle[1], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[1], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.6) grid(col = \"gray90\")  plot(beta_grid, profile_ll_beta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", beta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[2], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.6) grid(col = \"gray90\")  plot(gamma_grid, profile_ll_gamma, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", gamma)), las = 1) abline(v = mle[3], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[3], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.6) grid(col = \"gray90\")  plot(delta_grid, profile_ll_delta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(delta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", delta)), las = 1) abline(v = mle[4], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[4], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.6) grid(col = \"gray90\")  plot(lambda_grid, profile_ll_lambda, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(lambda), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", lambda)), las = 1) abline(v = mle[5], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[5], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.6) grid(col = \"gray90\")  par(mfrow = c(1, 1))    ## Example 6: 2D Log-Likelihood Surface (Alpha vs Beta) # Plot all profiles par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Create 2D grid alpha_2d <- seq(mle[1] - xd, mle[1] + xd, length.out = round(n/4)) beta_2d <- seq(mle[2] - xd, mle[2] + xd, length.out = round(n/4)) alpha_2d <- alpha_2d[alpha_2d > 0] beta_2d <- beta_2d[beta_2d > 0]  # Compute log-likelihood surface ll_surface_ab <- matrix(NA, nrow = length(alpha_2d), ncol = length(beta_2d))  for (i in seq_along(alpha_2d)) {   for (j in seq_along(beta_2d)) {     ll_surface_ab[i, j] <- llgkw(c(alpha_2d[i], beta_2d[j],                                      mle[3], mle[4], mle[5]), data)   } }  # Confidence region levels max_ll_ab <- max(ll_surface_ab, na.rm = TRUE) levels_90_ab <- max_ll_ab - qchisq(0.90, df = 2) / 2 levels_95_ab <- max_ll_ab - qchisq(0.95, df = 2) / 2 levels_99_ab <- max_ll_ab - qchisq(0.99, df = 2) / 2  # Plot contour contour(alpha_2d, beta_2d, ll_surface_ab,         xlab = expression(alpha), ylab = expression(beta),         main = \"2D Log-Likelihood: Alpha vs Beta\",         levels = seq(min(ll_surface_ab, na.rm = TRUE), max_ll_ab, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(alpha_2d, beta_2d, ll_surface_ab,         levels = c(levels_90_ab, levels_95_ab, levels_99_ab),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   ## Example 7: 2D Log-Likelihood Surface (Gamma vs Delta)  # Create 2D grid gamma_2d <- seq(mle[3] - xd, mle[3] + xd, length.out = round(n/4)) delta_2d <- seq(mle[4] - xd, mle[4] + xd, length.out = round(n/4)) gamma_2d <- gamma_2d[gamma_2d > 0] delta_2d <- delta_2d[delta_2d > 0]  # Compute log-likelihood surface ll_surface_gd <- matrix(NA, nrow = length(gamma_2d), ncol = length(delta_2d))  for (i in seq_along(gamma_2d)) {   for (j in seq_along(delta_2d)) {     ll_surface_gd[i, j] <- -llgkw(c(mle[1], mle[2], gamma_2d[i],                                      delta_2d[j], mle[5]), data)   } }  # Confidence region levels max_ll_gd <- max(ll_surface_gd, na.rm = TRUE) levels_90_gd <- max_ll_gd - qchisq(0.90, df = 2) / 2 levels_95_gd <- max_ll_gd - qchisq(0.95, df = 2) / 2 levels_99_gd <- max_ll_gd - qchisq(0.99, df = 2) / 2  # Plot contour contour(gamma_2d, delta_2d, ll_surface_gd,         xlab = expression(gamma), ylab = expression(delta),         main = \"2D Log-Likelihood: Gamma vs Delta\",         levels = seq(min(ll_surface_gd, na.rm = TRUE), max_ll_gd, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(gamma_2d, delta_2d, ll_surface_gd,         levels = c(levels_90_gd, levels_95_gd, levels_99_gd),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[3], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[3], true_params[4], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   ## Example 8: 2D Log-Likelihood Surface (Delta vs Lambda)  # Create 2D grid delta_2d_2 <- seq(mle[4] - xd, mle[4] + xd, length.out = round(n/30)) lambda_2d <- seq(mle[5] - xd, mle[5] + xd, length.out = round(n/30)) delta_2d_2 <- delta_2d_2[delta_2d_2 > 0] lambda_2d <- lambda_2d[lambda_2d > 0]  # Compute log-likelihood surface ll_surface_dl <- matrix(NA, nrow = length(delta_2d_2), ncol = length(lambda_2d))  for (i in seq_along(delta_2d_2)) {   for (j in seq_along(lambda_2d)) {     ll_surface_dl[i, j] <- -llgkw(c(mle[1], mle[2], mle[3],                                      delta_2d_2[i], lambda_2d[j]), data)   } }  # Confidence region levels max_ll_dl <- max(ll_surface_dl, na.rm = TRUE) levels_90_dl <- max_ll_dl - qchisq(0.90, df = 2) / 2 levels_95_dl <- max_ll_dl - qchisq(0.95, df = 2) / 2 levels_99_dl <- max_ll_dl - qchisq(0.99, df = 2) / 2  # Plot contour contour(delta_2d_2, lambda_2d, ll_surface_dl,         xlab = expression(delta), ylab = expression(lambda),         main = \"2D Log-Likelihood: Delta vs Lambda\",         levels = seq(min(ll_surface_dl, na.rm = TRUE), max_ll_dl, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(delta_2d_2, lambda_2d, ll_surface_dl,         levels = c(levels_90_dl, levels_95_dl, levels_99_dl),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[4], mle[5], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[4], true_params[5], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/llkkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative Log-Likelihood for the kkw Distribution — llkkw","title":"Negative Log-Likelihood for the kkw Distribution — llkkw","text":"Computes negative log-likelihood function Kumaraswamy-Kumaraswamy (kkw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)), given vector observations. distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative Log-Likelihood for the kkw Distribution — llkkw","text":"","code":"llkkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/llkkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative Log-Likelihood for the kkw Distribution — llkkw","text":"par numeric vector length 4 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative Log-Likelihood for the kkw Distribution — llkkw","text":"Returns single double value representing negative log-likelihood (\\(-\\ell(\\theta|\\mathbf{x})\\)). Returns Inf parameter values par invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative Log-Likelihood for the kkw Distribution — llkkw","text":"kkw distribution GKw distribution (dgkw) \\(\\gamma=1\\). probability density function (PDF) : $$ f(x | \\theta) = (\\delta + 1) \\lambda \\alpha \\beta x^{\\alpha - 1} (1 - x^\\alpha)^{\\beta - 1} \\bigl[1 - (1 - x^\\alpha)^\\beta\\bigr]^{\\lambda - 1} \\bigl\\{1 - \\bigl[1 - (1 - x^\\alpha)^\\beta\\bigr]^\\lambda\\bigr\\}^{\\delta} $$ \\(0 < x < 1\\) \\(\\theta = (\\alpha, \\beta, \\delta, \\lambda)\\). log-likelihood function \\(\\ell(\\theta | \\mathbf{x})\\) sample \\(\\mathbf{x} = (x_1, \\dots, x_n)\\) \\(\\sum_{=1}^n \\ln f(x_i | \\theta)\\): $$ \\ell(\\theta | \\mathbf{x}) = n[\\ln(\\delta+1) + \\ln(\\lambda) + \\ln(\\alpha) + \\ln(\\beta)] + \\sum_{=1}^{n} [(\\alpha-1)\\ln(x_i) + (\\beta-1)\\ln(v_i) + (\\lambda-1)\\ln(w_i) + \\delta\\ln(z_i)] $$ : \\(v_i = 1 - x_i^{\\alpha}\\) \\(w_i = 1 - v_i^{\\beta} = 1 - (1-x_i^{\\alpha})^{\\beta}\\) \\(z_i = 1 - w_i^{\\lambda} = 1 - [1-(1-x_i^{\\alpha})^{\\beta}]^{\\lambda}\\) function computes returns negative log-likelihood, \\(-\\ell(\\theta|\\mathbf{x})\\), suitable minimization using optimization routines like optim. Numerical stability maintained similarly llgkw.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Negative Log-Likelihood for the kkw Distribution — llkkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/llkkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Negative Log-Likelihood for the kkw Distribution — llkkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative Log-Likelihood for the kkw Distribution — llkkw","text":"","code":"# \\donttest{ ## Example 1: Basic Log-Likelihood Evaluation  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.0, beta = 3.0, delta = 1.5, lambda = 2.0) data <- rkkw(n, alpha = true_params[1], beta = true_params[2],              delta = true_params[3], lambda = true_params[4])  # Evaluate negative log-likelihood at true parameters nll_true <- llkkw(par = true_params, data = data) cat(\"Negative log-likelihood at true parameters:\", nll_true, \"\\n\") #> Negative log-likelihood at true parameters: -586.4032   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 2.5, 1.0, 1.5),   c(2.0, 3.0, 1.5, 2.0),   c(2.5, 3.5, 2.0, 2.5) )  nll_values <- apply(test_params, 1, function(p) llkkw(p, data)) results <- data.frame(   Alpha = test_params[, 1],   Beta = test_params[, 2],   Delta = test_params[, 3],   Lambda = test_params[, 4],   NegLogLik = nll_values ) print(results, digits = 4) #>   Alpha Beta Delta Lambda NegLogLik #> 1   1.5  2.5   1.0    1.5    -390.1 #> 2   2.0  3.0   1.5    2.0    -586.4 #> 3   2.5  3.5   2.0    2.5    -368.5   ## Example 2: Maximum Likelihood Estimation  # Optimization using BFGS with analytical gradient fit <- optim(   par = c(1.5, 2.5, 1.0, 1.5),   fn = llkkw,   gr = grkkw,   data = data,   method = \"BFGS\",   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"alpha\", \"beta\", \"delta\", \"lambda\") se <- sqrt(diag(solve(fit$hessian)))  results <- data.frame(   Parameter = c(\"alpha\", \"beta\", \"delta\", \"lambda\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - 1.96 * se,   CI_Upper = mle + 1.96 * se ) print(results, digits = 4) #>        Parameter True   MLE    SE CI_Lower CI_Upper #> alpha      alpha  2.0 2.304 2.170   -1.949    6.558 #> beta        beta  3.0 3.610 8.425  -12.904   20.123 #> delta      delta  1.5 1.222 4.810   -8.206   10.651 #> lambda    lambda  2.0 1.705 1.685   -1.598    5.007  cat(\"\\nNegative log-likelihood at MLE:\", fit$value, \"\\n\") #>  #> Negative log-likelihood at MLE: -586.5422  cat(\"AIC:\", 2 * fit$value + 2 * length(mle), \"\\n\") #> AIC: -1165.084  cat(\"BIC:\", 2 * fit$value + length(mle) * log(n), \"\\n\") #> BIC: -1145.453    ## Example 3: Comparing Optimization Methods  methods <- c(\"BFGS\", \"L-BFGS-B\", \"Nelder-Mead\", \"CG\") start_params <- c(1.5, 2.5, 1.0, 1.5)  comparison <- data.frame(   Method = character(),   Alpha = numeric(),   Beta = numeric(),   Delta = numeric(),   Lambda = numeric(),   NegLogLik = numeric(),   Convergence = integer(),   stringsAsFactors = FALSE )  for (method in methods) {   if (method %in% c(\"BFGS\", \"CG\")) {     fit_temp <- optim(       par = start_params,       fn = llkkw,       gr = grkkw,       data = data,       method = method     )   } else if (method == \"L-BFGS-B\") {     fit_temp <- optim(       par = start_params,       fn = llkkw,       gr = grkkw,       data = data,       method = method,       lower = c(0.01, 0.01, 0.01, 0.01),       upper = c(100, 100, 100, 100)     )   } else {     fit_temp <- optim(       par = start_params,       fn = llkkw,       data = data,       method = method     )   }      comparison <- rbind(comparison, data.frame(     Method = method,     Alpha = fit_temp$par[1],     Beta = fit_temp$par[2],     Delta = fit_temp$par[3],     Lambda = fit_temp$par[4],     NegLogLik = fit_temp$value,     Convergence = fit_temp$convergence,     stringsAsFactors = FALSE   )) }  print(comparison, digits = 4, row.names = FALSE) #>       Method Alpha  Beta Delta Lambda NegLogLik Convergence #>         BFGS 2.304 3.610 1.222  1.705    -586.5           0 #>     L-BFGS-B 2.097 2.926 1.706  1.877    -586.5           0 #>  Nelder-Mead 2.385 3.957 1.043  1.644    -586.5           0 #>           CG 2.003 2.974 1.578  2.002    -586.5           1   ## Example 4: Likelihood Ratio Test  # Test H0: delta = 1.5 vs H1: delta free loglik_full <- -fit$value  restricted_ll <- function(params_restricted, data, delta_fixed) {   llkkw(par = c(params_restricted[1], params_restricted[2],                 delta_fixed, params_restricted[3]), data = data) }  fit_restricted <- optim(   par = c(mle[1], mle[2], mle[4]),   fn = restricted_ll,   data = data,   delta_fixed = 1.5,   method = \"BFGS\" )  loglik_restricted <- -fit_restricted$value lr_stat <- 2 * (loglik_full - loglik_restricted) p_value <- pchisq(lr_stat, df = 1, lower.tail = FALSE)  cat(\"LR Statistic:\", round(lr_stat, 4), \"\\n\") #> LR Statistic: 0.0066  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 0.9352    ## Example 5: Univariate Profile Likelihoods  # Profile for alpha alpha_grid <- seq(mle[1] - 1, mle[1] + 1, length.out = 40) alpha_grid <- alpha_grid[alpha_grid > 0] profile_ll_alpha <- numeric(length(alpha_grid))  for (i in seq_along(alpha_grid)) {   profile_fit <- optim(     par = mle[-1],     fn = function(p) llkkw(c(alpha_grid[i], p), data),     method = \"Nelder-Mead\"   )   profile_ll_alpha[i] <- -profile_fit$value }  # Profile for beta beta_grid <- seq(mle[2] - 1, mle[2] + 1, length.out = 40) beta_grid <- beta_grid[beta_grid > 0] profile_ll_beta <- numeric(length(beta_grid))  for (i in seq_along(beta_grid)) {   profile_fit <- optim(     par = mle[-2],     fn = function(p) llkkw(c(p[1], beta_grid[i], p[2], p[3]), data),     method = \"Nelder-Mead\"   )   profile_ll_beta[i] <- -profile_fit$value }  # Profile for delta delta_grid <- seq(mle[3] - 0.8, mle[3] + 0.8, length.out = 40) delta_grid <- delta_grid[delta_grid > 0] profile_ll_delta <- numeric(length(delta_grid))  for (i in seq_along(delta_grid)) {   profile_fit <- optim(     par = mle[-3],     fn = function(p) llkkw(c(p[1], p[2], delta_grid[i], p[3]), data),     method = \"Nelder-Mead\"   )   profile_ll_delta[i] <- -profile_fit$value }  # Profile for lambda lambda_grid <- seq(mle[4] - 1, mle[4] + 1, length.out = 40) lambda_grid <- lambda_grid[lambda_grid > 0] profile_ll_lambda <- numeric(length(lambda_grid))  for (i in seq_along(lambda_grid)) {   profile_fit <- optim(     par = mle[-4],     fn = function(p) llkkw(c(p[1], p[2], p[3], lambda_grid[i]), data),     method = \"Nelder-Mead\"   )   profile_ll_lambda[i] <- -profile_fit$value }  # 95% confidence threshold chi_crit <- qchisq(0.95, df = 1) threshold <- max(profile_ll_alpha) - chi_crit / 2  # Plot all profiles par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))  plot(alpha_grid, profile_ll_alpha, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", alpha)), las = 1) abline(v = mle[1], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[1], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.7) grid(col = \"gray90\")  plot(beta_grid, profile_ll_beta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", beta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[2], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.7) grid(col = \"gray90\")  plot(delta_grid, profile_ll_delta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(delta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", delta)), las = 1) abline(v = mle[3], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[3], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.7) grid(col = \"gray90\")  plot(lambda_grid, profile_ll_lambda, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(lambda), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", lambda)), las = 1) abline(v = mle[4], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[4], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.7) grid(col = \"gray90\")   par(mfrow = c(1, 1))   ## Example 6: 2D Log-Likelihood Surface (Alpha vs Beta)  par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))  # Create 2D grid alpha_2d <- seq(mle[1] - 0.8, mle[1] + 0.8, length.out = round(n/25)) beta_2d <- seq(mle[2] - 0.8, mle[2] + 0.8, length.out = round(n/25)) alpha_2d <- alpha_2d[alpha_2d > 0] beta_2d <- beta_2d[beta_2d > 0]  # Compute log-likelihood surface ll_surface <- matrix(NA, nrow = length(alpha_2d), ncol = length(beta_2d))  for (i in seq_along(alpha_2d)) {   for (j in seq_along(beta_2d)) {     ll_surface[i, j] <- -llkkw(c(alpha_2d[i], beta_2d[j], mle[3], mle[4]), data)   } }  # Confidence region levels max_ll <- max(ll_surface, na.rm = TRUE) levels_90 <- max_ll - qchisq(0.90, df = 2) / 2 levels_95 <- max_ll - qchisq(0.95, df = 2) / 2 levels_99 <- max_ll - qchisq(0.99, df = 2) / 2  # Plot contour contour(alpha_2d, beta_2d, ll_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"2D Log-Likelihood: Alpha vs Beta\",         levels = seq(min(ll_surface, na.rm = TRUE), max_ll, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(alpha_2d, beta_2d, ll_surface,         levels = c(levels_90, levels_95, levels_99),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   ## Example 7: 2D Log-Likelihood Surface (Delta vs Lambda)  # Create 2D grid delta_2d <- seq(mle[3] - 0.6, mle[3] + 0.6, length.out = round(n/25)) lambda_2d <- seq(mle[4] - 0.8, mle[4] + 0.8, length.out = round(n/25)) delta_2d <- delta_2d[delta_2d > 0] lambda_2d <- lambda_2d[lambda_2d > 0]  # Compute log-likelihood surface ll_surface2 <- matrix(NA, nrow = length(delta_2d), ncol = length(lambda_2d))  for (i in seq_along(delta_2d)) {   for (j in seq_along(lambda_2d)) {     ll_surface2[i, j] <- -llkkw(c(mle[1], mle[2], delta_2d[i], lambda_2d[j]), data)   } }  # Confidence region levels max_ll2 <- max(ll_surface2, na.rm = TRUE) levels2_90 <- max_ll2 - qchisq(0.90, df = 2) / 2 levels2_95 <- max_ll2 - qchisq(0.95, df = 2) / 2 levels2_99 <- max_ll2 - qchisq(0.99, df = 2) / 2  # Plot contour contour(delta_2d, lambda_2d, ll_surface2,         xlab = expression(delta), ylab = expression(lambda),         main = \"2D Log-Likelihood: Delta vs Lambda\",         levels = seq(min(ll_surface2, na.rm = TRUE), max_ll2, length.out = 20),         col = \"#2E4057\", las = 1, lwd = 1)  contour(delta_2d, lambda_2d, ll_surface2,         levels = c(levels2_90, levels2_95, levels2_99),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  points(mle[3], mle[4], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[3], true_params[4], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/llkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","title":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","text":"Computes negative log-likelihood function two-parameter Kumaraswamy (Kw) distribution parameters alpha (\\(\\alpha\\)) beta (\\(\\beta\\)), given vector observations. function suitable maximum likelihood estimation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","text":"","code":"llkw(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/llkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","text":"par numeric vector length 2 containing distribution parameters order: alpha (\\(\\alpha > 0\\)), beta (\\(\\beta > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","text":"Returns single double value representing negative log-likelihood (\\(-\\ell(\\theta|\\mathbf{x})\\)). Returns Inf parameter values par invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","text":"Kumaraswamy (Kw) distribution's probability density function (PDF) (see dkw): $$ f(x | \\theta) = \\alpha \\beta x^{\\alpha-1} (1 - x^\\alpha)^{\\beta-1} $$ \\(0 < x < 1\\) \\(\\theta = (\\alpha, \\beta)\\). log-likelihood function \\(\\ell(\\theta | \\mathbf{x})\\) sample \\(\\mathbf{x} = (x_1, \\dots, x_n)\\) \\(\\sum_{=1}^n \\ln f(x_i | \\theta)\\): $$ \\ell(\\theta | \\mathbf{x}) = n[\\ln(\\alpha) + \\ln(\\beta)] + \\sum_{=1}^{n} [(\\alpha-1)\\ln(x_i) + (\\beta-1)\\ln(v_i)] $$ \\(v_i = 1 - x_i^{\\alpha}\\). function computes returns negative log-likelihood, \\(-\\ell(\\theta|\\mathbf{x})\\), suitable minimization using optimization routines like optim. equivalent negative log-likelihood GKw distribution (llgkw) evaluated \\(\\gamma=1, \\delta=0, \\lambda=1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","text":"Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/llkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative Log-Likelihood of the Kumaraswamy (Kw) Distribution — llkw","text":"","code":"# \\donttest{ ## Example 1: Maximum Likelihood Estimation with Analytical Gradient  # Generate sample data set.seed(123) n <- 1000 true_params <- c(alpha = 2.5, beta = 3.5) data <- rkw(n, alpha = true_params[1], beta = true_params[2])  # Optimization using BFGS with analytical gradient fit <- optim(   par = c(2, 2),   fn = llkw,   gr = grkw,   data = data,   method = \"BFGS\",   hessian = TRUE )  # Extract results mle <- fit$par names(mle) <- c(\"alpha\", \"beta\") se <- sqrt(diag(solve(fit$hessian))) ci_lower <- mle - 1.96 * se ci_upper <- mle + 1.96 * se  # Summary table results <- data.frame(   Parameter = c(\"alpha\", \"beta\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = ci_lower,   CI_Upper = ci_upper ) print(results, digits = 4) #>       Parameter True   MLE      SE CI_Lower CI_Upper #> alpha     alpha  2.5 2.511 0.07982    2.355    2.668 #> beta       beta  3.5 3.571 0.19189    3.195    3.947  ## Example 2: Verifying Gradient at MLE  # At MLE, gradient should be approximately zero gradient_at_mle <- grkw(par = mle, data = data) print(gradient_at_mle) #> [1]  2.071782e-05 -1.146518e-05 cat(\"Max absolute score:\", max(abs(gradient_at_mle)), \"\\n\") #> Max absolute score: 2.071782e-05   ## Example 3: Checking Hessian Properties  # Hessian at MLE hessian_at_mle <- hskw(par = mle, data = data) print(hessian_at_mle, digits = 4) #>        [,1]    [,2] #> [1,]  453.2 -152.43 #> [2,] -152.4   78.43  # Check positive definiteness via eigenvalues eigenvals <- eigen(hessian_at_mle, only.values = TRUE)$values print(eigenvals) #> [1] 507.36836  24.25944 all(eigenvals > 0) #> [1] TRUE  # Condition number cond_number <- max(eigenvals) / min(eigenvals) cat(\"Condition number:\", format(cond_number, scientific = TRUE), \"\\n\") #> Condition number: 2.091426e+01   ## Example 4: Comparing Optimization Methods  methods <- c(\"BFGS\", \"L-BFGS-B\", \"Nelder-Mead\", \"CG\") start_params <- c(2, 2)  comparison <- data.frame(   Method = character(),   Alpha_Est = numeric(),   Beta_Est = numeric(),   NegLogLik = numeric(),   Convergence = integer(),   stringsAsFactors = FALSE )  for (method in methods) {   if (method %in% c(\"BFGS\", \"CG\")) {     fit_temp <- optim(       par = start_params,       fn = llkw,       gr = grkw,       data = data,       method = method     )   } else if (method == \"L-BFGS-B\") {     fit_temp <- optim(       par = start_params,       fn = llkw,       gr = grkw,       data = data,       method = method,       lower = c(0.01, 0.01),       upper = c(100, 100)     )   } else {     fit_temp <- optim(       par = start_params,       fn = llkw,       data = data,       method = method     )   }      comparison <- rbind(comparison, data.frame(     Method = method,     Alpha_Est = fit_temp$par[1],     Beta_Est = fit_temp$par[2],     NegLogLik = fit_temp$value,     Convergence = fit_temp$convergence,     stringsAsFactors = FALSE   )) }  print(comparison, digits = 4, row.names = FALSE) #>       Method Alpha_Est Beta_Est NegLogLik Convergence #>         BFGS     2.511    3.571    -279.6           0 #>     L-BFGS-B     2.511    3.571    -279.6           0 #>  Nelder-Mead     2.511    3.571    -279.6           0 #>           CG     2.511    3.571    -279.6           0  ## Example 5: Likelihood Ratio Test  # Test H0: beta = 3 vs H1: beta free loglik_full <- -fit$value  # Restricted model: fix beta = 3 restricted_ll <- function(alpha, data, beta_fixed) {   llkw(par = c(alpha, beta_fixed), data = data) }  fit_restricted <- optimize(   f = restricted_ll,   interval = c(0.1, 10),   data = data,   beta_fixed = 3,   maximum = FALSE )  loglik_restricted <- -fit_restricted$objective lr_stat <- 2 * (loglik_full - loglik_restricted) p_value <- pchisq(lr_stat, df = 1, lower.tail = FALSE)  cat(\"LR Statistic:\", round(lr_stat, 4), \"\\n\") #> LR Statistic: 10.3649  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 0.001284   ## Example 6: Univariate Profile Likelihoods  # Grid for alpha alpha_grid <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = 50) alpha_grid <- alpha_grid[alpha_grid > 0] profile_ll_alpha <- numeric(length(alpha_grid))  for (i in seq_along(alpha_grid)) {   profile_fit <- optimize(     f = function(beta) llkw(c(alpha_grid[i], beta), data),     interval = c(0.1, 10),     maximum = FALSE   )   profile_ll_alpha[i] <- -profile_fit$objective }  # Grid for beta beta_grid <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = 50) beta_grid <- beta_grid[beta_grid > 0] profile_ll_beta <- numeric(length(beta_grid))  for (i in seq_along(beta_grid)) {   profile_fit <- optimize(     f = function(alpha) llkw(c(alpha, beta_grid[i]), data),     interval = c(0.1, 10),     maximum = FALSE   )   profile_ll_beta[i] <- -profile_fit$objective }  # 95% confidence threshold chi_crit <- qchisq(0.95, df = 1) threshold <- max(profile_ll_alpha) - chi_crit / 2  # Plot side by side par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))  # Profile for alpha plot(alpha_grid, profile_ll_alpha, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile Likelihood: \", alpha)), las = 1) abline(v = mle[1], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[1], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  # Profile for beta plot(beta_grid, profile_ll_beta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile Likelihood: \", beta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[2], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")   par(mfrow = c(1, 1))  ## Example 7: 2D Profile Likelihood Surface  # Create 2D grid alpha_2d <- seq(mle[1] - 1, mle[1] + 1, length.out = round(n/4)) beta_2d <- seq(mle[2] - 1, mle[2] + 1, length.out = round(n/4)) alpha_2d <- alpha_2d[alpha_2d > 0] beta_2d <- beta_2d[beta_2d > 0]  # Compute log-likelihood surface ll_surface <- matrix(NA, nrow = length(alpha_2d), ncol = length(beta_2d))  for (i in seq_along(alpha_2d)) {   for (j in seq_along(beta_2d)) {     ll_surface[i, j] <- -llkw(c(alpha_2d[i], beta_2d[j]), data)   } }  # Confidence region levels max_ll <- max(ll_surface, na.rm = TRUE) levels_90 <- max_ll - qchisq(0.90, df = 2) / 2 levels_95 <- max_ll - qchisq(0.95, df = 2) / 2 levels_99 <- max_ll - qchisq(0.99, df = 2) / 2  # Plot contour contour(alpha_2d, beta_2d, ll_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"2D Profile Log-Likelihood\",         levels = seq(min(ll_surface, na.rm = TRUE), max_ll, length.out = round(n/4)),         col = \"#2E4057\", las = 1, lwd = 1)  # Add confidence region contours contour(alpha_2d, beta_2d, ll_surface,         levels = c(levels_90, levels_95, levels_99),         col = c(\"#FFA07A\", \"#FF6347\", \"#8B0000\"),         lwd = c(2, 2.5, 3), lty = c(3, 2, 1),         add = TRUE, labcex = 0.8)  # Mark points points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5)  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"90% CR\", \"95% CR\", \"99% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FFA07A\", \"#FF6347\", \"#8B0000\"),        pch = c(19, 17, NA, NA, NA),        lty = c(NA, NA, 3, 2, 1),        lwd = c(NA, NA, 2, 2.5, 3),        bty = \"n\", cex = 0.8) grid(col = \"gray90\")   ## Example 8: Combined View - Profiles with 2D Surface  par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))  # Top left: Profile for alpha plot(alpha_grid, profile_ll_alpha, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(alpha), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", alpha)), las = 1) abline(v = mle[1], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[1], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3) grid(col = \"gray90\")  # Top right: Profile for beta plot(beta_grid, profile_ll_beta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(beta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", beta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[2], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3) grid(col = \"gray90\")  # Bottom left: 2D contour contour(alpha_2d, beta_2d, ll_surface,         xlab = expression(alpha), ylab = expression(beta),         main = \"2D Log-Likelihood Surface\",         levels = seq(min(ll_surface, na.rm = TRUE), max_ll, length.out = 15),         col = \"#2E4057\", las = 1, lwd = 1) contour(alpha_2d, beta_2d, ll_surface,         levels = c(levels_95),         col = \"#8B0000\", lwd = 2.5, add = TRUE) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\") par(mfrow = c(1, 1))   ## Example 9: Numerical Gradient Verification  # Manual finite difference gradient numerical_gradient <- function(f, x, data, h = 1e-7) {   grad <- numeric(length(x))   for (i in seq_along(x)) {     x_plus <- x_minus <- x     x_plus[i] <- x[i] + h     x_minus[i] <- x[i] - h     grad[i] <- (f(x_plus, data) - f(x_minus, data)) / (2 * h)   }   return(grad) }  # Compare grad_analytical <- grkw(par = mle, data = data) grad_numerical <- numerical_gradient(llkw, mle, data)  comparison_grad <- data.frame(   Parameter = c(\"alpha\", \"beta\"),   Analytical = grad_analytical,   Numerical = grad_numerical,   Difference = abs(grad_analytical - grad_numerical) ) print(comparison_grad, digits = 8) #>   Parameter     Analytical      Numerical    Difference #> 1     alpha  2.0717825e-05  2.1600499e-05 8.8267439e-07 #> 2      beta -1.1465180e-05 -1.0800250e-05 6.6493050e-07  ## Example 10: Bootstrap Confidence Intervals  n_boot <- round(n/4) boot_estimates <- matrix(NA, nrow = n_boot, ncol = 2)  set.seed(456) for (b in 1:n_boot) {   boot_data <- rkw(n, alpha = mle[1], beta = mle[2])   boot_fit <- optim(     par = mle,     fn = llkw,     gr = grkw,     data = boot_data,     method = \"BFGS\",     control = list(maxit = 500)   )   if (boot_fit$convergence == 0) {     boot_estimates[b, ] <- boot_fit$par   } }  boot_estimates <- boot_estimates[complete.cases(boot_estimates), ] boot_ci <- apply(boot_estimates, 2, quantile, probs = c(0.025, 0.975)) colnames(boot_ci) <- c(\"alpha\", \"beta\")  print(t(boot_ci), digits = 4) #>        2.5% 97.5% #> alpha 2.359 2.655 #> beta  3.209 3.916  # Plot bootstrap distributions par(mfrow = c(1, 2))  hist(boot_estimates[, 1], breaks = 20, col = \"#87CEEB\", border = \"white\",      main = expression(paste(\"Bootstrap: \", hat(alpha))),      xlab = expression(hat(alpha)), las = 1) abline(v = mle[1], col = \"#8B0000\", lwd = 2) abline(v = true_params[1], col = \"#006400\", lwd = 2, lty = 2) abline(v = boot_ci[, 1], col = \"#2E4057\", lwd = 2, lty = 3) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\"),        lwd = 2, lty = c(1, 2, 3), bty = \"n\")  hist(boot_estimates[, 2], breaks = 20, col = \"#FFA07A\", border = \"white\",      main = expression(paste(\"Bootstrap: \", hat(beta))),      xlab = expression(hat(beta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lwd = 2) abline(v = true_params[2], col = \"#006400\", lwd = 2, lty = 2) abline(v = boot_ci[, 2], col = \"#2E4057\", lwd = 2, lty = 3) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#2E4057\"),        lwd = 2, lty = c(1, 2, 3), bty = \"n\")   par(mfrow = c(1, 1))  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/llmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","title":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","text":"Computes negative log-likelihood function McDonald (Mc) distribution (also known Beta Power) parameters gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)), given vector observations. distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\alpha = 1\\) \\(\\beta = 1\\). function suitable maximum likelihood estimation.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","text":"","code":"llmc(par, data)"},{"path":"https://evandeilton.github.io/gkwdist/reference/llmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","text":"par numeric vector length 3 containing distribution parameters order: gamma (\\(\\gamma > 0\\)), delta (\\(\\delta \\ge 0\\)), lambda (\\(\\lambda > 0\\)). data numeric vector observations. values must strictly 0 1 (exclusive).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","text":"Returns single double value representing negative log-likelihood (\\(-\\ell(\\theta|\\mathbf{x})\\)). Returns Inf parameter values par invalid according constraints, value data interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","text":"McDonald (Mc) distribution GKw distribution (dmc) \\(\\alpha=1\\) \\(\\beta=1\\). probability density function (PDF) : $$ f(x | \\theta) = \\frac{\\lambda}{B(\\gamma,\\delta+1)} x^{\\gamma \\lambda - 1} (1 - x^\\lambda)^\\delta $$ \\(0 < x < 1\\), \\(\\theta = (\\gamma, \\delta, \\lambda)\\), \\(B(,b)\\) Beta function (beta). log-likelihood function \\(\\ell(\\theta | \\mathbf{x})\\) sample \\(\\mathbf{x} = (x_1, \\dots, x_n)\\) \\(\\sum_{=1}^n \\ln f(x_i | \\theta)\\): $$ \\ell(\\theta | \\mathbf{x}) = n[\\ln(\\lambda) - \\ln B(\\gamma, \\delta+1)] + \\sum_{=1}^{n} [(\\gamma\\lambda - 1)\\ln(x_i) + \\delta\\ln(1 - x_i^\\lambda)] $$ function computes returns negative log-likelihood, \\(-\\ell(\\theta|\\mathbf{x})\\), suitable minimization using optimization routines like optim. Numerical stability maintained, including using log-gamma function (lgamma) Beta function term.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","text":"McDonald, J. B. (1984). generalized functions size distribution income. Econometrica, 52(3), 647-663. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/llmc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/llmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Negative Log-Likelihood for the McDonald (Mc)/Beta Power Distribution — llmc","text":"","code":"# \\donttest{ ## Example 1: Basic Log-Likelihood Evaluation  # Generate sample data with more stable parameters set.seed(123) n <- 1000 true_params <- c(gamma = 2.0, delta = 2.5, lambda = 1.5) data <- rmc(n, gamma = true_params[1], delta = true_params[2],             lambda = true_params[3])  # Evaluate negative log-likelihood at true parameters nll_true <- llmc(par = true_params, data = data) cat(\"Negative log-likelihood at true parameters:\", nll_true, \"\\n\") #> Negative log-likelihood at true parameters: -309.7459   # Evaluate at different parameter values test_params <- rbind(   c(1.5, 2.0, 1.0),   c(2.0, 2.5, 1.5),   c(2.5, 3.0, 2.0) )  nll_values <- apply(test_params, 1, function(p) llmc(p, data)) results <- data.frame(   Gamma = test_params[, 1],   Delta = test_params[, 2],   Lambda = test_params[, 3],   NegLogLik = nll_values ) print(results, digits = 4) #>   Gamma Delta Lambda NegLogLik #> 1   1.5   2.0    1.0     38.79 #> 2   2.0   2.5    1.5   -309.75 #> 3   2.5   3.0    2.0    -40.96   ## Example 2: Maximum Likelihood Estimation  # Optimization using BFGS with analytical gradient fit <- optim(   par = c(1.5, 2.0, 1.0),   fn = llmc,   gr = grmc,   data = data,   method = \"BFGS\",   hessian = TRUE )  mle <- fit$par names(mle) <- c(\"gamma\", \"delta\", \"lambda\") se <- sqrt(diag(solve(fit$hessian)))  results <- data.frame(   Parameter = c(\"gamma\", \"delta\", \"lambda\"),   True = true_params,   MLE = mle,   SE = se,   CI_Lower = mle - 1.96 * se,   CI_Upper = mle + 1.96 * se ) print(results, digits = 4) #>        Parameter True   MLE     SE CI_Lower CI_Upper #> gamma      gamma  2.0 1.458 0.7271  0.03309    2.883 #> delta      delta  2.5 2.644 0.3351  1.98760    3.301 #> lambda    lambda  1.5 1.956 0.7785  0.42989    3.482  cat(\"\\nNegative log-likelihood at MLE:\", fit$value, \"\\n\") #>  #> Negative log-likelihood at MLE: -310.1013  cat(\"AIC:\", 2 * fit$value + 2 * length(mle), \"\\n\") #> AIC: -614.2026  cat(\"BIC:\", 2 * fit$value + length(mle) * log(n), \"\\n\") #> BIC: -599.4794    ## Example 3: Comparing Optimization Methods  methods <- c(\"BFGS\", \"L-BFGS-B\", \"Nelder-Mead\", \"CG\") start_params <- c(1.5, 2.0, 1.0)  comparison <- data.frame(   Method = character(),   Gamma = numeric(),   Delta = numeric(),   Lambda = numeric(),   NegLogLik = numeric(),   Convergence = integer(),   stringsAsFactors = FALSE )  for (method in methods) {   if (method %in% c(\"BFGS\", \"CG\")) {     fit_temp <- optim(       par = start_params,       fn = llmc,       gr = grmc,       data = data,       method = method     )   } else if (method == \"L-BFGS-B\") {     fit_temp <- optim(       par = start_params,       fn = llmc,       gr = grmc,       data = data,       method = method,       lower = c(0.01, 0.01, 0.01),       upper = c(100, 100, 100)     )   } else {     fit_temp <- optim(       par = start_params,       fn = llmc,       data = data,       method = method     )   }    comparison <- rbind(comparison, data.frame(     Method = method,     Gamma = fit_temp$par[1],     Delta = fit_temp$par[2],     Lambda = fit_temp$par[3],     NegLogLik = fit_temp$value,     Convergence = fit_temp$convergence,     stringsAsFactors = FALSE   )) }  print(comparison, digits = 4, row.names = FALSE) #>       Method Gamma Delta Lambda NegLogLik Convergence #>         BFGS 1.458 2.644  1.956    -310.1           0 #>     L-BFGS-B 1.460 2.644  1.954    -310.1           0 #>  Nelder-Mead 1.460 2.643  1.954    -310.1           0 #>           CG 1.878 2.522  1.596    -310.0           1   ## Example 4: Likelihood Ratio Test  # Test H0: lambda = 1.5 vs H1: lambda free loglik_full <- -fit$value  restricted_ll <- function(params_restricted, data, lambda_fixed) {   llmc(par = c(params_restricted[1], params_restricted[2],                lambda_fixed), data = data) }  fit_restricted <- optim(   par = c(mle[1], mle[2]),   fn = restricted_ll,   data = data,   lambda_fixed = 1.5,   method = \"BFGS\" )  loglik_restricted <- -fit_restricted$value lr_stat <- 2 * (loglik_full - loglik_restricted) p_value <- pchisq(lr_stat, df = 1, lower.tail = FALSE)  cat(\"LR Statistic:\", round(lr_stat, 4), \"\\n\") #> LR Statistic: 0.2939  cat(\"P-value:\", format.pval(p_value, digits = 4), \"\\n\") #> P-value: 0.5878    ## Example 5: Univariate Profile Likelihoods  # Profile for gamma gamma_grid <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = 50) gamma_grid <- gamma_grid[gamma_grid > 0] profile_ll_gamma <- numeric(length(gamma_grid))  for (i in seq_along(gamma_grid)) {   profile_fit <- optim(     par = mle[-1],     fn = function(p) llmc(c(gamma_grid[i], p), data),     method = \"BFGS\"   )   profile_ll_gamma[i] <- -profile_fit$value }  # Profile for delta delta_grid <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = 50) delta_grid <- delta_grid[delta_grid > 0] profile_ll_delta <- numeric(length(delta_grid))  for (i in seq_along(delta_grid)) {   profile_fit <- optim(     par = mle[-2],     fn = function(p) llmc(c(p[1], delta_grid[i], p[2]), data),     method = \"BFGS\"   )   profile_ll_delta[i] <- -profile_fit$value }  # Profile for lambda lambda_grid <- seq(mle[3] - 1.5, mle[3] + 1.5, length.out = 50) lambda_grid <- lambda_grid[lambda_grid > 0] profile_ll_lambda <- numeric(length(lambda_grid))  for (i in seq_along(lambda_grid)) {   profile_fit <- optim(     par = mle[-3],     fn = function(p) llmc(c(p[1], p[2], lambda_grid[i]), data),     method = \"BFGS\"   )   profile_ll_lambda[i] <- -profile_fit$value }  # 95% confidence threshold chi_crit <- qchisq(0.95, df = 1) threshold <- max(profile_ll_gamma) - chi_crit / 2  # Plot all profiles par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  plot(gamma_grid, profile_ll_gamma, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(gamma), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", gamma)), las = 1) abline(v = mle[1], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[1], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  plot(delta_grid, profile_ll_delta, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(delta), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", delta)), las = 1) abline(v = mle[2], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[2], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")  plot(lambda_grid, profile_ll_lambda, type = \"l\", lwd = 2, col = \"#2E4057\",      xlab = expression(lambda), ylab = \"Profile Log-Likelihood\",      main = expression(paste(\"Profile: \", lambda)), las = 1) abline(v = mle[3], col = \"#8B0000\", lty = 2, lwd = 2) abline(v = true_params[3], col = \"#006400\", lty = 2, lwd = 2) abline(h = threshold, col = \"#808080\", lty = 3, lwd = 1.5) legend(\"topright\", legend = c(\"MLE\", \"True\", \"95% CI\"),        col = c(\"#8B0000\", \"#006400\", \"#808080\"),        lty = c(2, 2, 3), lwd = 2, bty = \"n\", cex = 0.8) grid(col = \"gray90\")   par(mfrow = c(1, 1))   ## Example 6: 2D Log-Likelihood Surfaces (All pairs side by side)  # Create 2D grids with wider range (±1.5) gamma_2d <- seq(mle[1] - 1.5, mle[1] + 1.5, length.out = round(n/25)) delta_2d <- seq(mle[2] - 1.5, mle[2] + 1.5, length.out = round(n/25)) lambda_2d <- seq(mle[3] - 1.5, mle[3] + 1.5, length.out = round(n/25))  gamma_2d <- gamma_2d[gamma_2d > 0] delta_2d <- delta_2d[delta_2d > 0] lambda_2d <- lambda_2d[lambda_2d > 0]  # Compute all log-likelihood surfaces ll_surface_gd <- matrix(NA, nrow = length(gamma_2d), ncol = length(delta_2d)) ll_surface_gl <- matrix(NA, nrow = length(gamma_2d), ncol = length(lambda_2d)) ll_surface_dl <- matrix(NA, nrow = length(delta_2d), ncol = length(lambda_2d))  # Gamma vs Delta for (i in seq_along(gamma_2d)) {   for (j in seq_along(delta_2d)) {     ll_surface_gd[i, j] <- -llmc(c(gamma_2d[i], delta_2d[j], mle[3]), data)   } }  # Gamma vs Lambda for (i in seq_along(gamma_2d)) {   for (j in seq_along(lambda_2d)) {     ll_surface_gl[i, j] <- -llmc(c(gamma_2d[i], mle[2], lambda_2d[j]), data)   } }  # Delta vs Lambda for (i in seq_along(delta_2d)) {   for (j in seq_along(lambda_2d)) {     ll_surface_dl[i, j] <- -llmc(c(mle[1], delta_2d[i], lambda_2d[j]), data)   } }  # Confidence region levels max_ll_gd <- max(ll_surface_gd, na.rm = TRUE) max_ll_gl <- max(ll_surface_gl, na.rm = TRUE) max_ll_dl <- max(ll_surface_dl, na.rm = TRUE)  levels_95_gd <- max_ll_gd - qchisq(0.95, df = 2) / 2 levels_95_gl <- max_ll_gl - qchisq(0.95, df = 2) / 2 levels_95_dl <- max_ll_dl - qchisq(0.95, df = 2) / 2  # Plot all three surfaces side by side par(mfrow = c(1, 3), mar = c(4, 4, 3, 1))  # Gamma vs Delta contour(gamma_2d, delta_2d, ll_surface_gd,         xlab = expression(gamma), ylab = expression(delta),         main = \"Gamma vs Delta\", las = 1,         levels = seq(min(ll_surface_gd, na.rm = TRUE), max_ll_gd, length.out = 20),         col = \"#2E4057\", lwd = 1) contour(gamma_2d, delta_2d, ll_surface_gd,         levels = levels_95_gd, col = \"#FF6347\", lwd = 2.5, lty = 1, add = TRUE) points(mle[1], mle[2], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[2], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Gamma vs Lambda contour(gamma_2d, lambda_2d, ll_surface_gl,         xlab = expression(gamma), ylab = expression(lambda),         main = \"Gamma vs Lambda\", las = 1,         levels = seq(min(ll_surface_gl, na.rm = TRUE), max_ll_gl, length.out = 20),         col = \"#2E4057\", lwd = 1) contour(gamma_2d, lambda_2d, ll_surface_gl,         levels = levels_95_gl, col = \"#FF6347\", lwd = 2.5, lty = 1, add = TRUE) points(mle[1], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[1], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  # Delta vs Lambda contour(delta_2d, lambda_2d, ll_surface_dl,         xlab = expression(delta), ylab = expression(lambda),         main = \"Delta vs Lambda\", las = 1,         levels = seq(min(ll_surface_dl, na.rm = TRUE), max_ll_dl, length.out = 20),         col = \"#2E4057\", lwd = 1) contour(delta_2d, lambda_2d, ll_surface_dl,         levels = levels_95_dl, col = \"#FF6347\", lwd = 2.5, lty = 1, add = TRUE) points(mle[2], mle[3], pch = 19, col = \"#8B0000\", cex = 1.5) points(true_params[2], true_params[3], pch = 17, col = \"#006400\", cex = 1.5) grid(col = \"gray90\")  legend(\"topright\",        legend = c(\"MLE\", \"True\", \"95% CR\"),        col = c(\"#8B0000\", \"#006400\", \"#FF6347\"),        pch = c(19, 17, NA),        lty = c(NA, NA, 1),        lwd = c(NA, NA, 2.5),        bty = \"n\", cex = 0.8)   par(mfrow = c(1, 1))  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/pbeta_.html","id":null,"dir":"Reference","previous_headings":"","what":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","title":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","text":"Computes cumulative distribution function (CDF), \\(F(q) = P(X \\le q)\\), standard Beta distribution, using parameterization common generalized distribution families. distribution parameterized gamma (\\(\\gamma\\)) delta (\\(\\delta\\)), corresponding standard Beta distribution shape parameters shape1 = gamma shape2 = delta + 1.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbeta_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","text":"","code":"pbeta_(q, gamma, delta, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/pbeta_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","text":"q Vector quantiles (values generally 0 1). gamma First shape parameter (shape1), \\(\\gamma > 0\\). Can scalar vector. Default: 1.0. delta Second shape parameter delta + 1 (shape2), requires \\(\\delta \\ge 0\\) shape2 >= 1. Can scalar vector. Default: 0.0 (leading shape2 = 1). lower_tail Logical; TRUE (default), probabilities \\(P(X \\le q)\\), otherwise, \\(P(X > q)\\). log_p Logical; TRUE, probabilities \\(p\\) given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbeta_.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","text":"vector probabilities, \\(F(q)\\), logarithms/complements depending lower_tail log_p. length result determined recycling rule applied arguments (q, gamma, delta). Returns 0 (-Inf log_p = TRUE) q <= 0 1 (0 log_p = TRUE) q >= 1. Returns NaN invalid parameters.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbeta_.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","text":"function computes CDF Beta distribution parameters shape1 = gamma shape2 = delta + 1. equivalent calling stats::pbeta(q, shape1 = gamma, shape2 = delta + 1, lower.tail = lower_tail, log.p = log_p). distribution arises special case five-parameter Generalized Kumaraswamy (GKw) distribution (pgkw) obtained setting \\(\\alpha = 1\\), \\(\\beta = 1\\), \\(\\lambda = 1\\). therefore also equivalent McDonald (Mc)/Beta Power distribution (pmc) \\(\\lambda = 1\\). function likely calls R's underlying pbeta function ensures consistent parameter recycling handling within C++ environment, matching style functions related families.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbeta_.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","text":"Johnson, N. L., Kotz, S., & Balakrishnan, N. (1995). Continuous Univariate Distributions, Volume 2 (2nd ed.). Wiley. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation,","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/pbeta_.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbeta_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CDF of the Beta Distribution (gamma, delta+1 Parameterization) — pbeta_","text":"","code":"# \\donttest{ # Example values q_vals <- c(0.2, 0.5, 0.8) gamma_par <- 2.0 # Corresponds to shape1 delta_par <- 3.0 # Corresponds to shape2 - 1 shape1 <- gamma_par shape2 <- delta_par + 1  # Calculate CDF using pbeta_ probs <- pbeta_(q_vals, gamma_par, delta_par) print(probs) #> [1] 0.26272 0.81250 0.99328  # Compare with stats::pbeta probs_stats <- stats::pbeta(q_vals, shape1 = shape1, shape2 = shape2) print(paste(\"Max difference vs stats::pbeta:\", max(abs(probs - probs_stats)))) #> [1] \"Max difference vs stats::pbeta: 0\"  # Compare with pgkw setting alpha=1, beta=1, lambda=1 probs_gkw <- pgkw(q_vals, alpha = 1.0, beta = 1.0, gamma = gamma_par,                   delta = delta_par, lambda = 1.0) print(paste(\"Max difference vs pgkw:\", max(abs(probs - probs_gkw)))) #> [1] \"Max difference vs pgkw: 1.11022302462516e-16\"  # Compare with pmc setting lambda=1 probs_mc <- pmc(q_vals, gamma = gamma_par, delta = delta_par, lambda = 1.0) print(paste(\"Max difference vs pmc:\", max(abs(probs - probs_mc)))) #> [1] \"Max difference vs pmc: 0\"  # Calculate upper tail P(X > q) probs_upper <- pbeta_(q_vals, gamma_par, delta_par, lower_tail = FALSE) print(probs_upper) #> [1] 0.73728 0.18750 0.00672 print(stats::pbeta(q_vals, shape1, shape2, lower.tail = FALSE)) #> [1] 0.73728 0.18750 0.00672  # Calculate log CDF log_probs <- pbeta_(q_vals, gamma_par, delta_par, log_p = TRUE) print(log_probs) #> [1] -1.336666453 -0.207639365 -0.006742681 print(stats::pbeta(q_vals, shape1, shape2, log.p = TRUE)) #> [1] -1.336666453 -0.207639365 -0.006742681  # Plot the CDF curve_q <- seq(0.001, 0.999, length.out = 200) curve_p <- pbeta_(curve_q, gamma = 2, delta = 3) # Beta(2, 4) plot(curve_q, curve_p, type = \"l\", main = \"Beta(2, 4) CDF via pbeta_\",      xlab = \"q\", ylab = \"F(q)\", col = \"blue\") curve(stats::pbeta(x, 2, 4), add=TRUE, col=\"red\", lty=2) legend(\"bottomright\", legend=c(\"pbeta_(gamma=2, delta=3)\", \"stats::pbeta(shape1=2, shape2=4)\"),        col=c(\"blue\", \"red\"), lty=c(1,2), bty=\"n\")   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/pbkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","title":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","text":"Computes cumulative distribution function (CDF), \\(P(X \\le q)\\), Beta-Kumaraswamy (BKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)). distribution defined interval (0, 1) special case Generalized Kumaraswamy (GKw) distribution \\(\\lambda = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","text":"","code":"pbkw(q, alpha, beta, gamma, delta, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/pbkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","text":"q Vector quantiles (values generally 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lower_tail Logical; TRUE (default), probabilities \\(P(X \\le q)\\), otherwise, \\(P(X > q)\\). log_p Logical; TRUE, probabilities \\(p\\) given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","text":"vector probabilities, \\(F(q)\\), logarithms/complements depending lower_tail log_p. length result determined recycling rule applied arguments (q, alpha, beta, gamma, delta). Returns 0 (-Inf log_p = TRUE) q <= 0 1 (0 log_p = TRUE) q >= 1. Returns NaN invalid parameters.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","text":"Beta-Kumaraswamy (BKw) distribution special case five-parameter Generalized Kumaraswamy distribution (pgkw) obtained setting shape parameter \\(\\lambda = 1\\). CDF GKw distribution \\(F_{GKw}(q) = I_{y(q)}(\\gamma, \\delta+1)\\), \\(y(q) = [1-(1-q^{\\alpha})^{\\beta}]^{\\lambda}\\) \\(I_x(,b)\\) regularized incomplete beta function (pbeta). Setting \\(\\lambda=1\\) simplifies \\(y(q)\\) \\(1 - (1 - q^\\alpha)^\\beta\\), yielding BKw CDF: $$ F(q; \\alpha, \\beta, \\gamma, \\delta) = I_{1 - (1 - q^\\alpha)^\\beta}(\\gamma, \\delta+1) $$ evaluated using pbeta function.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/pbkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pbkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Distribution Function (CDF) of the Beta-Kumaraswamy (BKw) Distribution — pbkw","text":"","code":"# \\donttest{ # Example values q_vals <- c(0.2, 0.5, 0.8) alpha_par <- 2.0 beta_par <- 1.5 gamma_par <- 1.0 delta_par <- 0.5  # Calculate CDF P(X <= q) probs <- pbkw(q_vals, alpha_par, beta_par, gamma_par, delta_par) print(probs) #> [1] 0.08775756 0.47653477 0.89961227  # Calculate upper tail P(X > q) probs_upper <- pbkw(q_vals, alpha_par, beta_par, gamma_par, delta_par,                     lower_tail = FALSE) print(probs_upper) #> [1] 0.9122424 0.5234652 0.1003877 # Check: probs + probs_upper should be 1 print(probs + probs_upper) #> [1] 1 1 1  # Calculate log CDF log_probs <- pbkw(q_vals, alpha_par, beta_par, gamma_par, delta_par,                   log_p = TRUE) print(log_probs) #> [1] -2.4331773 -0.7412146 -0.1057914 # Check: should match log(probs) print(log(probs)) #> [1] -2.4331773 -0.7412146 -0.1057914  # Compare with pgkw setting lambda = 1 probs_gkw <- pgkw(q_vals, alpha_par, beta_par, gamma = gamma_par,                  delta = delta_par, lambda = 1.0) print(paste(\"Max difference:\", max(abs(probs - probs_gkw)))) # Should be near zero #> [1] \"Max difference: 0\"  # Plot the CDF curve_q <- seq(0.01, 0.99, length.out = 200) curve_p <- pbkw(curve_q, alpha = 2, beta = 3, gamma = 0.5, delta = 1) plot(curve_q, curve_p, type = \"l\", main = \"BKw CDF Example\",      xlab = \"q\", ylab = \"F(q)\", col = \"blue\", ylim = c(0, 1))  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/pekw.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","title":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","text":"Computes cumulative distribution function (CDF), \\(P(X \\le q)\\), Exponentiated Kumaraswamy (EKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), lambda (\\(\\lambda\\)). distribution defined interval (0, 1) special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\) \\(\\delta = 0\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pekw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","text":"","code":"pekw(q, alpha, beta, lambda, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/pekw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","text":"q Vector quantiles (values generally 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. lambda Shape parameter lambda > 0 (exponent parameter). Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(P(X \\le q)\\), otherwise, \\(P(X > q)\\). log_p Logical; TRUE, probabilities \\(p\\) given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pekw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","text":"vector probabilities, \\(F(q)\\), logarithms/complements depending lower_tail log_p. length result determined recycling rule applied arguments (q, alpha, beta, lambda). Returns 0 (-Inf log_p = TRUE) q <= 0 1 (0 log_p = TRUE) q >= 1. Returns NaN invalid parameters.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pekw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","text":"Exponentiated Kumaraswamy (EKw) distribution special case five-parameter Generalized Kumaraswamy distribution (pgkw) obtained setting parameters \\(\\gamma = 1\\) \\(\\delta = 0\\). CDF GKw distribution \\(F_{GKw}(q) = I_{y(q)}(\\gamma, \\delta+1)\\), \\(y(q) = [1-(1-q^{\\alpha})^{\\beta}]^{\\lambda}\\) \\(I_x(,b)\\) regularized incomplete beta function (pbeta). Setting \\(\\gamma=1\\) \\(\\delta=0\\) gives \\(I_{y(q)}(1, 1)\\). Since \\(I_x(1, 1) = x\\), CDF simplifies \\(y(q)\\): $$ F(q; \\alpha, \\beta, \\lambda) = \\bigl[1 - (1 - q^\\alpha)^\\beta \\bigr]^\\lambda $$ \\(0 < q < 1\\). implementation uses closed-form expression efficiency handles lower_tail log_p arguments appropriately.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pekw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","text":"Nadarajah, S., Cordeiro, G. M., & Ortega, E. M. (2012). exponentiated Kumaraswamy distribution. Journal Franklin Institute, 349(3), Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/pekw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pekw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Distribution Function (CDF) of the EKw Distribution — pekw","text":"","code":"# \\donttest{ # Example values q_vals <- c(0.2, 0.5, 0.8) alpha_par <- 2.0 beta_par <- 3.0 lambda_par <- 1.5  # Calculate CDF P(X <= q) probs <- pekw(q_vals, alpha_par, beta_par, lambda_par) print(probs) #> [1] 0.03913276 0.43957464 0.93083875  # Calculate upper tail P(X > q) probs_upper <- pekw(q_vals, alpha_par, beta_par, lambda_par,                     lower_tail = FALSE) print(probs_upper) #> [1] 0.96086724 0.56042536 0.06916125 # Check: probs + probs_upper should be 1 print(probs + probs_upper) #> [1] 1 1 1  # Calculate log CDF log_probs <- pekw(q_vals, alpha_par, beta_par, lambda_par, log_p = TRUE) print(log_probs) #> [1] -3.24079519 -0.82194776 -0.07166921 # Check: should match log(probs) print(log(probs)) #> [1] -3.24079519 -0.82194776 -0.07166921  # Compare with pgkw setting gamma = 1, delta = 0 probs_gkw <- pgkw(q_vals, alpha_par, beta_par, gamma = 1.0, delta = 0.0,                  lambda = lambda_par) print(paste(\"Max difference:\", max(abs(probs - probs_gkw)))) # Should be near zero #> [1] \"Max difference: 1.11022302462516e-16\"  # Plot the CDF for different lambda values curve_q <- seq(0.01, 0.99, length.out = 200) curve_p1 <- pekw(curve_q, alpha = 2, beta = 3, lambda = 0.5) curve_p2 <- pekw(curve_q, alpha = 2, beta = 3, lambda = 1.0) # standard Kw curve_p3 <- pekw(curve_q, alpha = 2, beta = 3, lambda = 2.0)  plot(curve_q, curve_p2, type = \"l\", main = \"EKw CDF Examples (alpha=2, beta=3)\",      xlab = \"q\", ylab = \"F(q)\", col = \"red\", ylim = c(0, 1)) lines(curve_q, curve_p1, col = \"blue\") lines(curve_q, curve_p3, col = \"green\") legend(\"bottomright\", legend = c(\"lambda=0.5\", \"lambda=1.0 (Kw)\", \"lambda=2.0\"),        col = c(\"blue\", \"red\", \"green\"), lty = 1, bty = \"n\")  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/pgkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Kumaraswamy Distribution CDF — pgkw","title":"Generalized Kumaraswamy Distribution CDF — pgkw","text":"Computes cumulative distribution function (CDF) five-parameter Generalized Kumaraswamy (GKw) distribution, defined interval (0, 1). Calculates \\(P(X \\le q)\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pgkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Kumaraswamy Distribution CDF — pgkw","text":"","code":"pgkw(q, alpha, beta, gamma, delta, lambda, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/pgkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Kumaraswamy Distribution CDF — pgkw","text":"q Vector quantiles (values generally 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(P(X \\le q)\\), otherwise, \\(P(X > q)\\). log_p Logical; TRUE, probabilities \\(p\\) given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pgkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Kumaraswamy Distribution CDF — pgkw","text":"vector probabilities, \\(F(q)\\), logarithms log_p = TRUE. length result determined recycling rule applied arguments (q, alpha, beta, gamma, delta, lambda). Returns 0 (-Inf log_p = TRUE) q <= 0 1 (0 log_p = TRUE) q >= 1. Returns NaN invalid parameters.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pgkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Kumaraswamy Distribution CDF — pgkw","text":"cumulative distribution function (CDF) Generalized Kumaraswamy (GKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)) given : $$ F(q; \\alpha, \\beta, \\gamma, \\delta, \\lambda) =   I_{x(q)}(\\gamma, \\delta+1) $$ \\(x(q) = [1-(1-q^{\\alpha})^{\\beta}]^{\\lambda}\\) \\(I_x(, b)\\) regularized incomplete beta function, defined : $$ I_x(, b) = \\frac{B_x(, b)}{B(, b)} = \\frac{\\int_0^x t^{-1}(1-t)^{b-1} dt}{\\int_0^1 t^{-1}(1-t)^{b-1} dt} $$ corresponds pbeta function R, \\(F(q; \\alpha, \\beta, \\gamma, \\delta, \\lambda) = \\code{pbeta}(x(q), \\code{shape1} = \\gamma, \\code{shape2} = \\delta+1)\\). GKw distribution includes several special cases, Kumaraswamy, Beta, Exponentiated Kumaraswamy distributions (see dgkw details). function utilizes numerical algorithms computing regularized incomplete beta function accurately, especially near boundaries.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pgkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Kumaraswamy Distribution CDF — pgkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/pgkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized Kumaraswamy Distribution CDF — pgkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pgkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Kumaraswamy Distribution CDF — pgkw","text":"","code":"# \\donttest{ # Simple CDF evaluation prob <- pgkw(0.5, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) # Kw case print(prob) #> [1] 0.578125  # Upper tail probability P(X > q) prob_upper <- pgkw(0.5, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1,                  lower_tail = FALSE) print(prob_upper) #> [1] 0.421875 # Check: prob + prob_upper should be 1 print(prob + prob_upper) #> [1] 1  # Log probability log_prob <- pgkw(0.5, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1,                  log_p = TRUE) print(log_prob) #> [1] -0.5479652 # Check: exp(log_prob) should be prob print(exp(log_prob)) #> [1] 0.578125  # Use of vectorized parameters q_vals <- c(0.2, 0.5, 0.8) alphas_vec <- c(0.5, 1.0, 2.0) betas_vec <- c(1.0, 2.0, 3.0) # Vectorizes over q, alpha, beta pgkw(q_vals, alpha = alphas_vec, beta = betas_vec, gamma = 1, delta = 0.5, lambda = 0.5) #> [1] 0.8093429 0.9509619 0.9963730  # Plotting the CDF for special cases x_seq <- seq(0.01, 0.99, by = 0.01) # Standard Kumaraswamy CDF cdf_kw <- pgkw(x_seq, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) # Beta distribution CDF equivalent (Beta(gamma, delta+1)) cdf_beta_equiv <- pgkw(x_seq, alpha = 1, beta = 1, gamma = 2, delta = 3, lambda = 1) # Compare with stats::pbeta cdf_beta_check <- stats::pbeta(x_seq, shape1 = 2, shape2 = 3 + 1) # max(abs(cdf_beta_equiv - cdf_beta_check)) # Should be close to zero  plot(x_seq, cdf_kw, type = \"l\", ylim = c(0, 1),      main = \"GKw CDF Examples\", ylab = \"F(x)\", xlab = \"x\", col = \"blue\") lines(x_seq, cdf_beta_equiv, col = \"red\", lty = 2) legend(\"bottomright\", legend = c(\"Kw(2,3)\", \"Beta(2,4) equivalent\"),        col = c(\"blue\", \"red\"), lty = c(1, 2), bty = \"n\")  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://evandeilton.github.io/gkwdist/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","title":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","text":"Computes cumulative distribution function (CDF), \\(P(X \\le q)\\), Kumaraswamy-Kumaraswamy (kkw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","text":"","code":"pkkw(q, alpha, beta, delta, lambda, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/pkkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","text":"q Vector quantiles (values generally 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(P(X \\le q)\\), otherwise, \\(P(X > q)\\). log_p Logical; TRUE, probabilities \\(p\\) given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","text":"vector probabilities, \\(F(q)\\), logarithms/complements depending lower_tail log_p. length result determined recycling rule applied arguments (q, alpha, beta, delta, lambda). Returns 0 (-Inf log_p = TRUE) q <= 0 1 (0 log_p = TRUE) q >= 1. Returns NaN invalid parameters.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","text":"Kumaraswamy-Kumaraswamy (kkw) distribution special case five-parameter Generalized Kumaraswamy distribution (pgkw) obtained setting shape parameter \\(\\gamma = 1\\). CDF GKw distribution \\(F_{GKw}(q) = I_{y(q)}(\\gamma, \\delta+1)\\), \\(y(q) = [1-(1-q^{\\alpha})^{\\beta}]^{\\lambda}\\) \\(I_x(,b)\\) regularized incomplete beta function (pbeta). Setting \\(\\gamma=1\\) utilizes property \\(I_x(1, b) = 1 - (1-x)^b\\), yielding kkw CDF: $$ F(q; \\alpha, \\beta, \\delta, \\lambda) = 1 - \\bigl\\{1 - \\bigl[1 - (1 - q^\\alpha)^\\beta\\bigr]^\\lambda\\bigr\\}^{\\delta + 1} $$ \\(0 < q < 1\\). implementation uses closed-form expression efficiency handles lower_tail log_p arguments appropriately.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/pkkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Distribution Function (CDF) of the kkw Distribution — pkkw","text":"","code":"# \\donttest{ # Example values q_vals <- c(0.2, 0.5, 0.8) alpha_par <- 2.0 beta_par <- 3.0 delta_par <- 0.5 lambda_par <- 1.5  # Calculate CDF P(X <= q) probs <- pkkw(q_vals, alpha_par, beta_par, delta_par, lambda_par) print(probs) #> [1] 0.05812108 0.58045681 0.98181161  # Calculate upper tail P(X > q) probs_upper <- pkkw(q_vals, alpha_par, beta_par, delta_par, lambda_par,                      lower_tail = FALSE) print(probs_upper) #> [1] 0.94187892 0.41954319 0.01818839 # Check: probs + probs_upper should be 1 print(probs + probs_upper) #> [1] 1 1 1  # Calculate log CDF log_probs <- pkkw(q_vals, alpha_par, beta_par, delta_par, lambda_par,                    log_p = TRUE) print(log_probs) #> [1] -2.84522685 -0.54393988 -0.01835583 # Check: should match log(probs) print(log(probs)) #> [1] -2.84522685 -0.54393988 -0.01835583  # Compare with pgkw setting gamma = 1 probs_gkw <- pgkw(q_vals, alpha_par, beta_par, gamma = 1.0,                   delta_par, lambda_par) print(paste(\"Max difference:\", max(abs(probs - probs_gkw)))) # Should be near zero #> [1] \"Max difference: 1.11022302462516e-16\"  # Plot the CDF curve_q <- seq(0.01, 0.99, length.out = 200) curve_p <- pkkw(curve_q, alpha_par, beta_par, delta_par, lambda_par) plot(curve_q, curve_p, type = \"l\", main = \"kkw CDF Example\",      xlab = \"q\", ylab = \"F(q)\", col = \"blue\", ylim = c(0, 1))   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/pkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","title":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","text":"Computes cumulative distribution function (CDF), \\(P(X \\le q)\\), two-parameter Kumaraswamy (Kw) distribution shape parameters alpha (\\(\\alpha\\)) beta (\\(\\beta\\)). distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","text":"","code":"pkw(q, alpha, beta, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/pkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","text":"q Vector quantiles (values generally 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(P(X \\le q)\\), otherwise, \\(P(X > q)\\). log_p Logical; TRUE, probabilities \\(p\\) given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","text":"vector probabilities, \\(F(q)\\), logarithms/complements depending lower_tail log_p. length result determined recycling rule applied arguments (q, alpha, beta). Returns 0 (-Inf log_p = TRUE) q <= 0 1 (0 log_p = TRUE) q >= 1. Returns NaN invalid parameters.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","text":"cumulative distribution function (CDF) Kumaraswamy (Kw) distribution given : $$ F(x; \\alpha, \\beta) = 1 - (1 - x^\\alpha)^\\beta $$ \\(0 < x < 1\\), \\(\\alpha > 0\\), \\(\\beta > 0\\). Kw distribution special case several generalized distributions: Generalized Kumaraswamy (pgkw) \\(\\gamma=1, \\delta=0, \\lambda=1\\). Exponentiated Kumaraswamy (pekw) \\(\\lambda=1\\). Kumaraswamy-Kumaraswamy (pkkw) \\(\\delta=0, \\lambda=1\\). implementation uses closed-form expression efficiency.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","text":"Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/pkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cumulative Distribution Function (CDF) of the Kumaraswamy (Kw) Distribution — pkw","text":"","code":"# \\donttest{ # Example values q_vals <- c(0.2, 0.5, 0.8) alpha_par <- 2.0 beta_par <- 3.0  # Calculate CDF P(X <= q) using pkw probs <- pkw(q_vals, alpha_par, beta_par) print(probs) #> [1] 0.115264 0.578125 0.953344  # Calculate upper tail P(X > q) probs_upper <- pkw(q_vals, alpha_par, beta_par, lower_tail = FALSE) print(probs_upper) #> [1] 0.884736 0.421875 0.046656 # Check: probs + probs_upper should be 1 print(probs + probs_upper) #> [1] 1 1 1  # Calculate log CDF log_probs <- pkw(q_vals, alpha_par, beta_par, log_p = TRUE) print(log_probs) #> [1] -2.16053013 -0.54796517 -0.04777948 # Check: should match log(probs) print(log(probs)) #> [1] -2.16053013 -0.54796517 -0.04777948  # Compare with pgkw setting gamma = 1, delta = 0, lambda = 1 probs_gkw <- pgkw(q_vals, alpha_par, beta_par, gamma = 1.0, delta = 0.0,                   lambda = 1.0) print(paste(\"Max difference:\", max(abs(probs - probs_gkw)))) # Should be near zero #> [1] \"Max difference: 1.38777878078145e-17\"  # Plot the CDF for different shape parameter combinations curve_q <- seq(0.001, 0.999, length.out = 200) plot(curve_q, pkw(curve_q, alpha = 2, beta = 3), type = \"l\",      main = \"Kumaraswamy CDF Examples\", xlab = \"q\", ylab = \"F(q)\",      col = \"blue\", ylim = c(0, 1)) lines(curve_q, pkw(curve_q, alpha = 3, beta = 2), col = \"red\") lines(curve_q, pkw(curve_q, alpha = 0.5, beta = 0.5), col = \"green\") lines(curve_q, pkw(curve_q, alpha = 5, beta = 1), col = \"purple\") lines(curve_q, pkw(curve_q, alpha = 1, beta = 3), col = \"orange\") legend(\"bottomright\", legend = c(\"a=2, b=3\", \"a=3, b=2\", \"a=0.5, b=0.5\", \"a=5, b=1\", \"a=1, b=3\"),        col = c(\"blue\", \"red\", \"green\", \"purple\", \"orange\"), lty = 1, bty = \"n\", ncol = 2)   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/pmc.html","id":null,"dir":"Reference","previous_headings":"","what":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","title":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","text":"Computes cumulative distribution function (CDF), \\(F(q) = P(X \\le q)\\), McDonald (Mc) distribution (also known Beta Power) parameters gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution defined interval (0, 1) special case Generalized Kumaraswamy (GKw) distribution \\(\\alpha = 1\\) \\(\\beta = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","text":"","code":"pmc(q, gamma, delta, lambda, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/pmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","text":"q Vector quantiles (values generally 0 1). gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(P(X \\le q)\\), otherwise, \\(P(X > q)\\). log_p Logical; TRUE, probabilities \\(p\\) given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","text":"vector probabilities, \\(F(q)\\), logarithms/complements depending lower_tail log_p. length result determined recycling rule applied arguments (q, gamma, delta, lambda). Returns 0 (-Inf log_p = TRUE) q <= 0 1 (0 log_p = TRUE) q >= 1. Returns NaN invalid parameters.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","text":"McDonald (Mc) distribution special case five-parameter Generalized Kumaraswamy (GKw) distribution (pgkw) obtained setting parameters \\(\\alpha = 1\\) \\(\\beta = 1\\). CDF GKw distribution \\(F_{GKw}(q) = I_{y(q)}(\\gamma, \\delta+1)\\), \\(y(q) = [1-(1-q^{\\alpha})^{\\beta}]^{\\lambda}\\) \\(I_x(,b)\\) regularized incomplete beta function (pbeta). Setting \\(\\alpha=1\\) \\(\\beta=1\\) simplifies \\(y(q)\\) \\(q^\\lambda\\), yielding Mc CDF: $$ F(q; \\gamma, \\delta, \\lambda) = I_{q^\\lambda}(\\gamma, \\delta+1) $$ evaluated using pbeta function pbeta(q^lambda, shape1 = gamma, shape2 = delta + 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","text":"McDonald, J. B. (1984). generalized functions size distribution income. Econometrica, 52(3), 647-663. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/pmc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/pmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"CDF of the McDonald (Mc)/Beta Power Distribution — pmc","text":"","code":"# \\donttest{ # Example values q_vals <- c(0.2, 0.5, 0.8) gamma_par <- 2.0 delta_par <- 1.5 lambda_par <- 1.0 # Equivalent to Beta(gamma, delta+1)  # Calculate CDF P(X <= q) using pmc probs <- pmc(q_vals, gamma_par, delta_par, lambda_par) print(probs) #> [1] 0.1413499 0.6022524 0.9463344 # Compare with Beta CDF print(stats::pbeta(q_vals, shape1 = gamma_par, shape2 = delta_par + 1)) #> [1] 0.1413499 0.6022524 0.9463344  # Calculate upper tail P(X > q) probs_upper <- pmc(q_vals, gamma_par, delta_par, lambda_par,                    lower_tail = FALSE) print(probs_upper) #> [1] 0.85865010 0.39774756 0.05366563 # Check: probs + probs_upper should be 1 print(probs + probs_upper) #> [1] 1 1 1  # Calculate log CDF log_probs <- pmc(q_vals, gamma_par, delta_par, lambda_par, log_p = TRUE) print(log_probs) #> [1] -1.95651693 -0.50707859 -0.05515932 # Check: should match log(probs) print(log(probs)) #> [1] -1.95651693 -0.50707859 -0.05515932  # Compare with pgkw setting alpha = 1, beta = 1 probs_gkw <- pgkw(q_vals, alpha = 1.0, beta = 1.0, gamma = gamma_par,                   delta = delta_par, lambda = lambda_par) print(paste(\"Max difference:\", max(abs(probs - probs_gkw)))) # Should be near zero #> [1] \"Max difference: 5.55111512312578e-17\"  # Plot the CDF for different lambda values curve_q <- seq(0.01, 0.99, length.out = 200) curve_p1 <- pmc(curve_q, gamma = 2, delta = 3, lambda = 0.5) curve_p2 <- pmc(curve_q, gamma = 2, delta = 3, lambda = 1.0) # Beta(2, 4) curve_p3 <- pmc(curve_q, gamma = 2, delta = 3, lambda = 2.0)  plot(curve_q, curve_p2, type = \"l\", main = \"Mc/Beta Power CDF (gamma=2, delta=3)\",      xlab = \"q\", ylab = \"F(q)\", col = \"red\", ylim = c(0, 1)) lines(curve_q, curve_p1, col = \"blue\") lines(curve_q, curve_p3, col = \"green\") legend(\"bottomright\", legend = c(\"lambda=0.5\", \"lambda=1.0 (Beta)\", \"lambda=2.0\"),        col = c(\"blue\", \"red\", \"green\"), lty = 1, bty = \"n\")  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/qbeta_.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","title":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","text":"Computes quantile function (inverse CDF) standard Beta distribution, using parameterization common generalized distribution families. finds value q \\(P(X \\le q) = p\\). distribution parameterized gamma (\\(\\gamma\\)) delta (\\(\\delta\\)), corresponding standard Beta distribution shape parameters shape1 = gamma shape2 = delta + 1.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbeta_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","text":"","code":"qbeta_(p, gamma, delta, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/qbeta_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","text":"p Vector probabilities (values 0 1). gamma First shape parameter (shape1), \\(\\gamma > 0\\). Can scalar vector. Default: 1.0. delta Second shape parameter delta + 1 (shape2), requires \\(\\delta \\ge 0\\) shape2 >= 1. Can scalar vector. Default: 0.0 (leading shape2 = 1). lower_tail Logical; TRUE (default), probabilities \\(p = P(X \\le q)\\), otherwise, probabilities \\(p = P(X > q)\\). log_p Logical; TRUE, probabilities p given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbeta_.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","text":"vector quantiles corresponding given probabilities p. length result determined recycling rule applied arguments (p, gamma, delta). Returns: 0 p = 0 (p = -Inf log_p = TRUE, lower_tail = TRUE). 1 p = 1 (p = 0 log_p = TRUE, lower_tail = TRUE). NaN p < 0 p > 1 (corresponding log scale). NaN invalid parameters (e.g., gamma <= 0, delta < 0). Boundary return values adjusted accordingly lower_tail = FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbeta_.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","text":"function computes quantiles Beta distribution parameters shape1 = gamma shape2 = delta + 1. equivalent calling stats::qbeta(p, shape1 = gamma, shape2 = delta + 1, lower.tail = lower_tail, log.p = log_p). distribution arises special case five-parameter Generalized Kumaraswamy (GKw) distribution (qgkw) obtained setting \\(\\alpha = 1\\), \\(\\beta = 1\\), \\(\\lambda = 1\\). therefore also equivalent McDonald (Mc)/Beta Power distribution (qmc) \\(\\lambda = 1\\). function likely calls R's underlying qbeta function ensures consistent parameter recycling handling within C++ environment, matching style functions related families. Boundary conditions (p=0, p=1) handled explicitly.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbeta_.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","text":"Johnson, N. L., Kotz, S., & Balakrishnan, N. (1995). Continuous Univariate Distributions, Volume 2 (2nd ed.). Wiley. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation,","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/qbeta_.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbeta_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Function of the Beta Distribution (gamma, delta+1 Parameterization) — qbeta_","text":"","code":"# \\donttest{ # Example values p_vals <- c(0.1, 0.5, 0.9) gamma_par <- 2.0 # Corresponds to shape1 delta_par <- 3.0 # Corresponds to shape2 - 1 shape1 <- gamma_par shape2 <- delta_par + 1  # Calculate quantiles using qbeta_ quantiles <- qbeta_(p_vals, gamma_par, delta_par) print(quantiles) #> [1] 0.1122350 0.3138102 0.5838904  # Compare with stats::qbeta quantiles_stats <- stats::qbeta(p_vals, shape1 = shape1, shape2 = shape2) print(paste(\"Max difference vs stats::qbeta:\", max(abs(quantiles - quantiles_stats)))) #> [1] \"Max difference vs stats::qbeta: 0\"  # Compare with qgkw setting alpha=1, beta=1, lambda=1 quantiles_gkw <- qgkw(p_vals, alpha = 1.0, beta = 1.0, gamma = gamma_par,                       delta = delta_par, lambda = 1.0) print(paste(\"Max difference vs qgkw:\", max(abs(quantiles - quantiles_gkw)))) #> [1] \"Max difference vs qgkw: 5.55111512312578e-17\"  # Compare with qmc setting lambda=1 quantiles_mc <- qmc(p_vals, gamma = gamma_par, delta = delta_par, lambda = 1.0) print(paste(\"Max difference vs qmc:\", max(abs(quantiles - quantiles_mc)))) #> [1] \"Max difference vs qmc: 0\"  # Calculate quantiles for upper tail quantiles_upper <- qbeta_(p_vals, gamma_par, delta_par, lower_tail = FALSE) print(quantiles_upper) #> [1] 0.5838904 0.3138102 0.1122350 print(stats::qbeta(p_vals, shape1, shape2, lower.tail = FALSE)) #> [1] 0.5838904 0.3138102 0.1122350  # Calculate quantiles from log probabilities log_p_vals <- log(p_vals) quantiles_logp <- qbeta_(log_p_vals, gamma_par, delta_par, log_p = TRUE) print(quantiles_logp) #> [1] 0.1122350 0.3138102 0.5838904 print(stats::qbeta(log_p_vals, shape1, shape2, log.p = TRUE)) #> [1] 0.1122350 0.3138102 0.5838904  # Verify inverse relationship with pbeta_ p_check <- 0.75 q_calc <- qbeta_(p_check, gamma_par, delta_par) p_recalc <- pbeta_(q_calc, gamma_par, delta_par) print(paste(\"Original p:\", p_check, \" Recalculated p:\", p_recalc)) #> [1] \"Original p: 0.75  Recalculated p: 0.75\" # abs(p_check - p_recalc) < 1e-9 # Should be TRUE  # Boundary conditions print(qbeta_(c(0, 1), gamma_par, delta_par)) # Should be 0, 1 #> [1] 0 1 print(qbeta_(c(-Inf, 0), gamma_par, delta_par, log_p = TRUE)) # Should be 0, 1 #> [1] 0 1  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/qbkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","title":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","text":"Computes quantile function (inverse CDF) Beta-Kumaraswamy (BKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)). finds value q \\(P(X \\le q) = p\\). distribution special case Generalized Kumaraswamy (GKw) distribution parameter \\(\\lambda = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","text":"","code":"qbkw(p, alpha, beta, gamma, delta, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/qbkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","text":"p Vector probabilities (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lower_tail Logical; TRUE (default), probabilities \\(p = P(X \\le q)\\), otherwise, probabilities \\(p = P(X > q)\\). log_p Logical; TRUE, probabilities p given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","text":"vector quantiles corresponding given probabilities p. length result determined recycling rule applied arguments (p, alpha, beta, gamma, delta). Returns: 0 p = 0 (p = -Inf log_p = TRUE, lower_tail = TRUE). 1 p = 1 (p = 0 log_p = TRUE, lower_tail = TRUE). NaN p < 0 p > 1 (corresponding log scale). NaN invalid parameters (e.g., alpha <= 0, beta <= 0, gamma <= 0, delta < 0). Boundary return values adjusted accordingly lower_tail = FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","text":"quantile function \\(Q(p)\\) inverse CDF \\(F(q)\\). CDF BKw (\\(\\lambda=1\\)) distribution \\(F(q) = I_{y(q)}(\\gamma, \\delta+1)\\), \\(y(q) = 1 - (1 - q^\\alpha)^\\beta\\) \\(I_z(,b)\\) regularized incomplete beta function (see pbkw). find quantile \\(q\\), first invert outer Beta part: let \\(y = ^{-1}_{p}(\\gamma, \\delta+1)\\), \\(^{-1}_p(,b)\\) inverse regularized incomplete beta function, computed via qbeta. , invert inner Kumaraswamy part: \\(y = 1 - (1 - q^\\alpha)^\\beta\\), leads \\(q = \\{1 - (1-y)^{1/\\beta}\\}^{1/\\alpha}\\). Substituting \\(y\\) gives quantile function: $$ Q(p) = \\left\\{ 1 - \\left[ 1 - ^{-1}_{p}(\\gamma, \\delta+1) \\right]^{1/\\beta} \\right\\}^{1/\\alpha} $$ function uses formula, calculating \\(^{-1}_{p}(\\gamma, \\delta+1)\\) via qbeta(p, gamma, delta + 1, ...) respecting lower_tail log_p arguments.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/qbkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qbkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Function of the Beta-Kumaraswamy (BKw) Distribution — qbkw","text":"","code":"# \\donttest{ # Example values p_vals <- c(0.1, 0.5, 0.9) alpha_par <- 2.0 beta_par <- 1.5 gamma_par <- 1.0 delta_par <- 0.5  # Calculate quantiles quantiles <- qbkw(p_vals, alpha_par, beta_par, gamma_par, delta_par) print(quantiles) #> [1] 0.2138865 0.5149104 0.8003866  # Calculate quantiles for upper tail probabilities P(X > q) = p quantiles_upper <- qbkw(p_vals, alpha_par, beta_par, gamma_par, delta_par,                         lower_tail = FALSE) print(quantiles_upper) #> [1] 0.8003866 0.5149104 0.2138865 # Check: qbkw(p, ..., lt=F) == qbkw(1-p, ..., lt=T) print(qbkw(1 - p_vals, alpha_par, beta_par, gamma_par, delta_par)) #> [1] 0.8003866 0.5149104 0.2138865  # Calculate quantiles from log probabilities log_p_vals <- log(p_vals) quantiles_logp <- qbkw(log_p_vals, alpha_par, beta_par, gamma_par, delta_par,                        log_p = TRUE) print(quantiles_logp) #> [1] 0.2138865 0.5149104 0.8003866 # Check: should match original quantiles print(quantiles) #> [1] 0.2138865 0.5149104 0.8003866  # Compare with qgkw setting lambda = 1 quantiles_gkw <- qgkw(p_vals, alpha_par, beta_par, gamma = gamma_par,                      delta = delta_par, lambda = 1.0) print(paste(\"Max difference:\", max(abs(quantiles - quantiles_gkw)))) # Should be near zero #> [1] \"Max difference: 2.77555756156289e-17\"  # Verify inverse relationship with pbkw p_check <- 0.75 q_calc <- qbkw(p_check, alpha_par, beta_par, gamma_par, delta_par) p_recalc <- pbkw(q_calc, alpha_par, beta_par, gamma_par, delta_par) print(paste(\"Original p:\", p_check, \" Recalculated p:\", p_recalc)) #> [1] \"Original p: 0.75  Recalculated p: 0.75\" # abs(p_check - p_recalc) < 1e-9 # Should be TRUE  # Boundary conditions print(qbkw(c(0, 1), alpha_par, beta_par, gamma_par, delta_par)) # Should be 0, 1 #> [1] 0 1 print(qbkw(c(-Inf, 0), alpha_par, beta_par, gamma_par, delta_par, log_p = TRUE)) # Should be 0, 1 #> [1] 0 1  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/qekw.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","title":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","text":"Computes quantile function (inverse CDF) Exponentiated Kumaraswamy (EKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), lambda (\\(\\lambda\\)). finds value q \\(P(X \\le q) = p\\). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\) \\(\\delta = 0\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qekw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","text":"","code":"qekw(p, alpha, beta, lambda, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/qekw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","text":"p Vector probabilities (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. lambda Shape parameter lambda > 0 (exponent parameter). Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(p = P(X \\le q)\\), otherwise, probabilities \\(p = P(X > q)\\). log_p Logical; TRUE, probabilities p given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qekw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","text":"vector quantiles corresponding given probabilities p. length result determined recycling rule applied arguments (p, alpha, beta, lambda). Returns: 0 p = 0 (p = -Inf log_p = TRUE, lower_tail = TRUE). 1 p = 1 (p = 0 log_p = TRUE, lower_tail = TRUE). NaN p < 0 p > 1 (corresponding log scale). NaN invalid parameters (e.g., alpha <= 0, beta <= 0, lambda <= 0). Boundary return values adjusted accordingly lower_tail = FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qekw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","text":"quantile function \\(Q(p)\\) inverse CDF \\(F(q)\\). CDF EKw (\\(\\gamma=1, \\delta=0\\)) distribution \\(F(q) = [1 - (1 - q^\\alpha)^\\beta ]^\\lambda\\) (see pekw). Inverting equation \\(q\\) yields quantile function: $$ Q(p) = \\left\\{ 1 - \\left[ 1 - p^{1/\\lambda} \\right]^{1/\\beta} \\right\\}^{1/\\alpha} $$ function uses closed-form expression correctly handles lower_tail log_p arguments transforming p appropriately applying formula. equivalent general GKw quantile function (qgkw) evaluated \\(\\gamma=1, \\delta=0\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qekw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","text":"Nadarajah, S., Cordeiro, G. M., & Ortega, E. M. (2012). exponentiated Kumaraswamy distribution. Journal Franklin Institute, 349(3), Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/qekw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qekw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Function of the Exponentiated Kumaraswamy (EKw) Distribution — qekw","text":"","code":"# \\donttest{ # Example values p_vals <- c(0.1, 0.5, 0.9) alpha_par <- 2.0 beta_par <- 3.0 lambda_par <- 1.5  # Calculate quantiles quantiles <- qekw(p_vals, alpha_par, beta_par, lambda_par) print(quantiles) #> [1] 0.2787375 0.5311017 0.7695287  # Calculate quantiles for upper tail probabilities P(X > q) = p quantiles_upper <- qekw(p_vals, alpha_par, beta_par, lambda_par,                         lower_tail = FALSE) print(quantiles_upper) #> [1] 0.7695287 0.5311017 0.2787375 # Check: qekw(p, ..., lt=F) == qekw(1-p, ..., lt=T) print(qekw(1 - p_vals, alpha_par, beta_par, lambda_par)) #> [1] 0.7695287 0.5311017 0.2787375  # Calculate quantiles from log probabilities log_p_vals <- log(p_vals) quantiles_logp <- qekw(log_p_vals, alpha_par, beta_par, lambda_par,                        log_p = TRUE) print(quantiles_logp) #> [1] 0.2787375 0.5311017 0.7695287 # Check: should match original quantiles print(quantiles) #> [1] 0.2787375 0.5311017 0.7695287  # Compare with qgkw setting gamma = 1, delta = 0 quantiles_gkw <- qgkw(p_vals, alpha = alpha_par, beta = beta_par,                      gamma = 1.0, delta = 0.0, lambda = lambda_par) print(paste(\"Max difference:\", max(abs(quantiles - quantiles_gkw)))) # Should be near zero #> [1] \"Max difference: 1.11022302462516e-16\"  # Verify inverse relationship with pekw p_check <- 0.75 q_calc <- qekw(p_check, alpha_par, beta_par, lambda_par) p_recalc <- pekw(q_calc, alpha_par, beta_par, lambda_par) print(paste(\"Original p:\", p_check, \" Recalculated p:\", p_recalc)) #> [1] \"Original p: 0.75  Recalculated p: 0.75\" # abs(p_check - p_recalc) < 1e-9 # Should be TRUE  # Boundary conditions print(qekw(c(0, 1), alpha_par, beta_par, lambda_par)) # Should be 0, 1 #> [1] 0 1 print(qekw(c(-Inf, 0), alpha_par, beta_par, lambda_par, log_p = TRUE)) # Should be 0, 1 #> [1] 0 1 # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/qgkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","title":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","text":"Computes quantile function (inverse CDF) five-parameter Generalized Kumaraswamy (GKw) distribution. Finds value x \\(P(X \\le x) = p\\), X follows GKw distribution.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qgkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","text":"","code":"qgkw(p, alpha, beta, gamma, delta, lambda, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/qgkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","text":"p Vector probabilities (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(P(X \\le x)\\), otherwise, \\(P(X > x)\\). log_p Logical; TRUE, probabilities p given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qgkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","text":"vector quantiles corresponding given probabilities p. length result determined recycling rule applied arguments (p, alpha, beta, gamma, delta, lambda). Returns: 0 p = 0 (p = -Inf log_p = TRUE). 1 p = 1 (p = 0 log_p = TRUE). NaN p < 0 p > 1 (corresponding log scale). NaN invalid parameters (e.g., alpha <= 0, beta <= 0, gamma <= 0, delta < 0, lambda <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qgkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","text":"quantile function \\(Q(p)\\) inverse CDF \\(F(x)\\). Given \\(F(x) = I_{y(x)}(\\gamma, \\delta+1)\\) \\(y(x) = [1-(1-x^{\\alpha})^{\\beta}]^{\\lambda}\\), quantile function : $$ Q(p) = x = \\left\\{ 1 - \\left[ 1 - \\left( ^{-1}_{p}(\\gamma, \\delta+1) \\right)^{1/\\lambda} \\right]^{1/\\beta} \\right\\}^{1/\\alpha} $$ \\(^{-1}_{p}(, b)\\) inverse regularized incomplete beta function, corresponds quantile function Beta distribution, qbeta. computation proceeds follows: Calculate y = stats::qbeta(p, shape1 = gamma, shape2 = delta + 1, lower.tail = lower_tail, log.p = log_p). Calculate \\(v = y^{1/\\lambda}\\). Calculate \\(w = (1 - v)^{1/\\beta}\\). Note: Requires \\(v \\le 1\\). Calculate \\(q = (1 - w)^{1/\\alpha}\\). Note: Requires \\(w \\le 1\\). Numerical stability maintained handling boundary cases (p = 0, p = 1) directly checking intermediate results (e.g., ensuring arguments powers non-negative).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qgkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/qgkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qgkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Kumaraswamy Distribution Quantile Function — qgkw","text":"","code":"# \\donttest{ # Basic quantile calculation (median) median_val <- qgkw(0.5, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) print(median_val) #> [1] 0.454202  # Computing multiple quantiles probs <- c(0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99) quantiles <- qgkw(probs, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) print(quantiles) #> [1] 0.05783171 0.18577033 0.30238999 0.45420202 0.60830870 0.73201169 0.88575196  # Upper tail quantile (e.g., find x such that P(X > x) = 0.1, which is 90th percentile) q90 <- qgkw(0.1, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1,             lower_tail = FALSE) print(q90) #> [1] 0.7320117 # Check: should match quantile for p = 0.9 with lower_tail = TRUE print(qgkw(0.9, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1)) #> [1] 0.7320117  # Log probabilities median_logp <- qgkw(log(0.5), alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1,                     log_p = TRUE) print(median_logp) # Should match median_val #> [1] 0.454202  # Vectorized parameters alphas_vec <- c(0.5, 1.0, 2.0) betas_vec <- c(1.0, 2.0, 3.0) # Get median for 3 different GKw distributions medians_vec <- qgkw(0.5, alpha = alphas_vec, beta = betas_vec, gamma = 1, delta = 0, lambda = 1) print(medians_vec) #> [1] 0.2500000 0.2928932 0.4542020  # Verify inverse relationship with pgkw p_val <- 0.75 x_val <- qgkw(p_val, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) p_check <- pgkw(x_val, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) print(paste(\"Calculated p:\", p_check, \" (Expected:\", p_val, \")\")) #> [1] \"Calculated p: 0.75  (Expected: 0.75 )\" # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/qkkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","title":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","text":"Computes quantile function (inverse CDF) Kumaraswamy-Kumaraswamy (kkw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). finds value q \\(P(X \\le q) = p\\). distribution special case Generalized Kumaraswamy (GKw) distribution parameter \\(\\gamma = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","text":"","code":"qkkw(p, alpha, beta, delta, lambda, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/qkkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","text":"p Vector probabilities (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(p = P(X \\le q)\\), otherwise, probabilities \\(p = P(X > q)\\). log_p Logical; TRUE, probabilities p given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","text":"vector quantiles corresponding given probabilities p. length result determined recycling rule applied arguments (p, alpha, beta, delta, lambda). Returns: 0 p = 0 (p = -Inf log_p = TRUE, lower_tail = TRUE). 1 p = 1 (p = 0 log_p = TRUE, lower_tail = TRUE). NaN p < 0 p > 1 (corresponding log scale). NaN invalid parameters (e.g., alpha <= 0, beta <= 0, delta < 0, lambda <= 0). Boundary return values adjusted accordingly lower_tail = FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","text":"quantile function \\(Q(p)\\) inverse CDF \\(F(q)\\). CDF kkw (\\(\\gamma=1\\)) distribution (see pkkw): $$ F(q) = 1 - \\bigl\\{1 - \\bigl[1 - (1 - q^\\alpha)^\\beta\\bigr]^\\lambda\\bigr\\}^{\\delta + 1} $$ Inverting equation \\(q\\) yields quantile function: $$ Q(p) = \\left[ 1 - \\left\\{ 1 - \\left[ 1 - (1 - p)^{1/(\\delta+1)} \\right]^{1/\\lambda} \\right\\}^{1/\\beta} \\right]^{1/\\alpha} $$ function uses closed-form expression correctly handles lower_tail log_p arguments transforming p appropriately applying formula.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/qkkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Function of the Kumaraswamy-Kumaraswamy (kkw) Distribution — qkkw","text":"","code":"# \\donttest{ # Example values p_vals <- c(0.1, 0.5, 0.9) alpha_par <- 2.0 beta_par <- 3.0 delta_par <- 0.5 lambda_par <- 1.5  # Calculate quantiles quantiles <- qkkw(p_vals, alpha_par, beta_par, delta_par, lambda_par) print(quantiles) #> [1] 0.2425575 0.4631919 0.6851540  # Calculate quantiles for upper tail probabilities P(X > q) = p # e.g., for p=0.1, find q such that P(X > q) = 0.1 (90th percentile) quantiles_upper <- qkkw(p_vals, alpha_par, beta_par, delta_par, lambda_par,                          lower_tail = FALSE) print(quantiles_upper) #> [1] 0.6851540 0.4631919 0.2425575 # Check: qkkw(p, ..., lt=F) == qkkw(1-p, ..., lt=T) print(qkkw(1 - p_vals, alpha_par, beta_par, delta_par, lambda_par)) #> [1] 0.6851540 0.4631919 0.2425575  # Calculate quantiles from log probabilities log_p_vals <- log(p_vals) quantiles_logp <- qkkw(log_p_vals, alpha_par, beta_par, delta_par, lambda_par,                         log_p = TRUE) print(quantiles_logp) #> [1] 0.2425575 0.4631919 0.6851540 # Check: should match original quantiles print(quantiles) #> [1] 0.2425575 0.4631919 0.6851540  # Compare with qgkw setting gamma = 1 quantiles_gkw <- qgkw(p_vals, alpha_par, beta_par, gamma = 1.0,                       delta_par, lambda_par) print(paste(\"Max difference:\", max(abs(quantiles - quantiles_gkw)))) # Should be near zero #> [1] \"Max difference: 0\"  # Verify inverse relationship with pkkw p_check <- 0.75 q_calc <- qkkw(p_check, alpha_par, beta_par, delta_par, lambda_par) p_recalc <- pkkw(q_calc, alpha_par, beta_par, delta_par, lambda_par) print(paste(\"Original p:\", p_check, \" Recalculated p:\", p_recalc)) #> [1] \"Original p: 0.75  Recalculated p: 0.75\" # abs(p_check - p_recalc) < 1e-9 # Should be TRUE  # Boundary conditions print(qkkw(c(0, 1), alpha_par, beta_par, delta_par, lambda_par)) # Should be 0, 1 #> [1] 0 1 print(qkkw(c(-Inf, 0), alpha_par, beta_par, delta_par, lambda_par, log_p = TRUE)) # Should be 0, 1 #> [1] 0 1  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/qkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","title":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","text":"Computes quantile function (inverse CDF) two-parameter Kumaraswamy (Kw) distribution shape parameters alpha (\\(\\alpha\\)) beta (\\(\\beta\\)). finds value q \\(P(X \\le q) = p\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","text":"","code":"qkw(p, alpha, beta, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/qkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","text":"p Vector probabilities (values 0 1). alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(p = P(X \\le q)\\), otherwise, probabilities \\(p = P(X > q)\\). log_p Logical; TRUE, probabilities p given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","text":"vector quantiles corresponding given probabilities p. length result determined recycling rule applied arguments (p, alpha, beta). Returns: 0 p = 0 (p = -Inf log_p = TRUE, lower_tail = TRUE). 1 p = 1 (p = 0 log_p = TRUE, lower_tail = TRUE). NaN p < 0 p > 1 (corresponding log scale). NaN invalid parameters (e.g., alpha <= 0, beta <= 0). Boundary return values adjusted accordingly lower_tail = FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","text":"quantile function \\(Q(p)\\) inverse CDF \\(F(q)\\). CDF Kumaraswamy distribution \\(F(q) = 1 - (1 - q^\\alpha)^\\beta\\) (see pkw). Inverting equation \\(q\\) yields quantile function: $$ Q(p) = \\left\\{ 1 - (1 - p)^{1/\\beta} \\right\\}^{1/\\alpha} $$ function uses closed-form expression correctly handles lower_tail log_p arguments transforming p appropriately applying formula. equivalent general GKw quantile function (qgkw) evaluated \\(\\gamma=1, \\delta=0, \\lambda=1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","text":"Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/qkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Function of the Kumaraswamy (Kw) Distribution — qkw","text":"","code":"# \\donttest{ # Example values p_vals <- c(0.1, 0.5, 0.9) alpha_par <- 2.0 beta_par <- 3.0  # Calculate quantiles using qkw quantiles <- qkw(p_vals, alpha_par, beta_par) print(quantiles) #> [1] 0.1857703 0.4542020 0.7320117  # Calculate quantiles for upper tail probabilities P(X > q) = p quantiles_upper <- qkw(p_vals, alpha_par, beta_par, lower_tail = FALSE) print(quantiles_upper) #> [1] 0.7320117 0.4542020 0.1857703  # Calculate quantiles from log probabilities log_p_vals <- log(p_vals) quantiles_logp <- qkw(log_p_vals, alpha_par, beta_par, log_p = TRUE) print(quantiles_logp) #> [1] 0.1857703 0.4542020 0.7320117 # Check: should match original quantiles print(quantiles) #> [1] 0.1857703 0.4542020 0.7320117  # Compare with qgkw setting gamma = 1, delta = 0, lambda = 1 quantiles_gkw <- qgkw(p_vals, alpha = alpha_par, beta = beta_par,                      gamma = 1.0, delta = 0.0, lambda = 1.0) print(paste(\"Max difference:\", max(abs(quantiles - quantiles_gkw)))) # Should be near zero #> [1] \"Max difference: 2.77555756156289e-17\"  # Verify inverse relationship with pkw p_check <- 0.75 q_calc <- qkw(p_check, alpha_par, beta_par) p_recalc <- pkw(q_calc, alpha_par, beta_par) print(paste(\"Original p:\", p_check, \" Recalculated p:\", p_recalc)) #> [1] \"Original p: 0.75  Recalculated p: 0.75\" # abs(p_check - p_recalc) < 1e-9 # Should be TRUE  # Boundary conditions print(qkw(c(0, 1), alpha_par, beta_par)) # Should be 0, 1 #> [1] 0 1 print(qkw(c(-Inf, 0), alpha_par, beta_par, log_p = TRUE)) # Should be 0, 1 #> [1] 0 1  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/qmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","title":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","text":"Computes quantile function (inverse CDF) McDonald (Mc) distribution (also known Beta Power) parameters gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). finds value q \\(P(X \\le q) = p\\). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\alpha = 1\\) \\(\\beta = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","text":"","code":"qmc(p, gamma, delta, lambda, lower_tail = TRUE, log_p = FALSE)"},{"path":"https://evandeilton.github.io/gkwdist/reference/qmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","text":"p Vector probabilities (values 0 1). gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0. lower_tail Logical; TRUE (default), probabilities \\(p = P(X \\le q)\\), otherwise, probabilities \\(p = P(X > q)\\). log_p Logical; TRUE, probabilities p given \\(\\log(p)\\). Default: FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","text":"vector quantiles corresponding given probabilities p. length result determined recycling rule applied arguments (p, gamma, delta, lambda). Returns: 0 p = 0 (p = -Inf log_p = TRUE, lower_tail = TRUE). 1 p = 1 (p = 0 log_p = TRUE, lower_tail = TRUE). NaN p < 0 p > 1 (corresponding log scale). NaN invalid parameters (e.g., gamma <= 0, delta < 0, lambda <= 0). Boundary return values adjusted accordingly lower_tail = FALSE.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","text":"quantile function \\(Q(p)\\) inverse CDF \\(F(q)\\). CDF Mc (\\(\\alpha=1, \\beta=1\\)) distribution \\(F(q) = I_{q^\\lambda}(\\gamma, \\delta+1)\\), \\(I_z(,b)\\) regularized incomplete beta function (see pmc). find quantile \\(q\\), first invert Beta function part: let \\(y = ^{-1}_{p}(\\gamma, \\delta+1)\\), \\(^{-1}_p(,b)\\) inverse computed via qbeta. solve \\(q^\\lambda = y\\) \\(q\\), yielding quantile function: $$ Q(p) = \\left[ ^{-1}_{p}(\\gamma, \\delta+1) \\right]^{1/\\lambda} $$ function uses formula, calculating \\(^{-1}_{p}(\\gamma, \\delta+1)\\) via qbeta(p, gamma, delta + 1, ...) respecting lower_tail log_p arguments. equivalent general GKw quantile function (qgkw) evaluated \\(\\alpha=1, \\beta=1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","text":"McDonald, J. B. (1984). generalized functions size distribution income. Econometrica, 52(3), 647-663. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/qmc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/qmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quantile Function of the McDonald (Mc)/Beta Power Distribution — qmc","text":"","code":"# \\donttest{ # Example values p_vals <- c(0.1, 0.5, 0.9) gamma_par <- 2.0 delta_par <- 1.5 lambda_par <- 1.0 # Equivalent to Beta(gamma, delta+1)  # Calculate quantiles using qmc quantiles <- qmc(p_vals, gamma_par, delta_par, lambda_par) print(quantiles) #> [1] 0.1649288 0.4355544 0.7379563 # Compare with Beta quantiles print(stats::qbeta(p_vals, shape1 = gamma_par, shape2 = delta_par + 1)) #> [1] 0.1649288 0.4355544 0.7379563  # Calculate quantiles for upper tail probabilities P(X > q) = p quantiles_upper <- qmc(p_vals, gamma_par, delta_par, lambda_par,                        lower_tail = FALSE) print(quantiles_upper) #> [1] 0.7379563 0.4355544 0.1649288 # Check: qmc(p, ..., lt=F) == qmc(1-p, ..., lt=T) print(qmc(1 - p_vals, gamma_par, delta_par, lambda_par)) #> [1] 0.7379563 0.4355544 0.1649288  # Calculate quantiles from log probabilities log_p_vals <- log(p_vals) quantiles_logp <- qmc(log_p_vals, gamma_par, delta_par, lambda_par, log_p = TRUE) print(quantiles_logp) #> [1] 0.1649288 0.4355544 0.7379563 # Check: should match original quantiles print(quantiles) #> [1] 0.1649288 0.4355544 0.7379563  # Compare with qgkw setting alpha = 1, beta = 1 quantiles_gkw <- qgkw(p_vals, alpha = 1.0, beta = 1.0, gamma = gamma_par,                       delta = delta_par, lambda = lambda_par) print(paste(\"Max difference:\", max(abs(quantiles - quantiles_gkw)))) # Should be near zero #> [1] \"Max difference: 5.55111512312578e-17\"  # Verify inverse relationship with pmc p_check <- 0.75 q_calc <- qmc(p_check, gamma_par, delta_par, lambda_par) # Use lambda != 1 p_recalc <- pmc(q_calc, gamma_par, delta_par, lambda_par) print(paste(\"Original p:\", p_check, \" Recalculated p:\", p_recalc)) #> [1] \"Original p: 0.75  Recalculated p: 0.75\" # abs(p_check - p_recalc) < 1e-9 # Should be TRUE  # Boundary conditions print(qmc(c(0, 1), gamma_par, delta_par, lambda_par)) # Should be 0, 1 #> [1] 0 1 print(qmc(c(-Inf, 0), gamma_par, delta_par, lambda_par, log_p = TRUE)) # Should be 0, 1 #> [1] 0 1  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/rbeta_.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","title":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","text":"Generates random deviates standard Beta distribution, using parameterization common generalized distribution families. distribution parameterized gamma (\\(\\gamma\\)) delta (\\(\\delta\\)), corresponding standard Beta distribution shape parameters shape1 = gamma shape2 = delta + 1. special case Generalized Kumaraswamy (GKw) distribution \\(\\alpha = 1\\), \\(\\beta = 1\\), \\(\\lambda = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbeta_.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","text":"","code":"rbeta_(n, gamma, delta)"},{"path":"https://evandeilton.github.io/gkwdist/reference/rbeta_.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","text":"n Number observations. length(n) > 1, length taken number required. Must non-negative integer. gamma First shape parameter (shape1), \\(\\gamma > 0\\). Can scalar vector. Default: 1.0. delta Second shape parameter delta + 1 (shape2), requires \\(\\delta \\ge 0\\) shape2 >= 1. Can scalar vector. Default: 0.0 (leading shape2 = 1, .e., Uniform).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbeta_.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","text":"numeric vector length n containing random deviates Beta(\\(\\gamma, \\delta+1\\)) distribution, values (0, 1). length result determined n recycling rule applied parameters (gamma, delta). Returns NaN parameters invalid (e.g., gamma <= 0, delta < 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbeta_.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","text":"function generates samples Beta distribution parameters shape1 = gamma shape2 = delta + 1. equivalent calling stats::rbeta(n, shape1 = gamma, shape2 = delta + 1). distribution arises special case five-parameter Generalized Kumaraswamy (GKw) distribution (rgkw) obtained setting \\(\\alpha = 1\\), \\(\\beta = 1\\), \\(\\lambda = 1\\). therefore also equivalent McDonald (Mc)/Beta Power distribution (rmc) \\(\\lambda = 1\\). function likely calls R's underlying rbeta function ensures consistent parameter recycling handling within C++ environment, matching style functions related families.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbeta_.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","text":"Johnson, N. L., Kotz, S., & Balakrishnan, N. (1995). Continuous Univariate Distributions, Volume 2 (2nd ed.). Wiley. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Devroye, L. (1986). Non-Uniform Random Variate Generation. Springer-Verlag.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/rbeta_.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbeta_.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Generation for the Beta Distribution (gamma, delta+1 Parameterization) — rbeta_","text":"","code":"# \\donttest{ set.seed(2030) # for reproducibility  # Generate 1000 samples using rbeta_ gamma_par <- 2.0 # Corresponds to shape1 delta_par <- 3.0 # Corresponds to shape2 - 1 shape1 <- gamma_par shape2 <- delta_par + 1  x_sample <- rbeta_(1000, gamma = gamma_par, delta = delta_par) summary(x_sample) #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.007135 0.190328 0.306978 0.335931 0.466661 0.886553   # Compare with stats::rbeta x_sample_stats <- stats::rbeta(1000, shape1 = shape1, shape2 = shape2) # Visually compare histograms or QQ-plots hist(x_sample, main=\"rbeta_ Sample\", freq=FALSE, breaks=30) curve(dbeta_(x, gamma_par, delta_par), add=TRUE, col=\"red\", lwd=2)  hist(x_sample_stats, main=\"stats::rbeta Sample\", freq=FALSE, breaks=30) curve(stats::dbeta(x, shape1, shape2), add=TRUE, col=\"blue\", lwd=2)  # Compare summary stats (should be similar due to randomness) print(summary(x_sample)) #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.007135 0.190328 0.306978 0.335931 0.466661 0.886553  print(summary(x_sample_stats)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01034 0.19696 0.31440 0.33723 0.45535 0.84423   # Compare summary stats with rgkw(alpha=1, beta=1, lambda=1) x_sample_gkw <- rgkw(1000, alpha = 1.0, beta = 1.0, gamma = gamma_par,                      delta = delta_par, lambda = 1.0) print(\"Summary stats for rgkw(a=1,b=1,l=1) sample:\") #> [1] \"Summary stats for rgkw(a=1,b=1,l=1) sample:\" print(summary(x_sample_gkw)) #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.004943 0.189179 0.313707 0.328485 0.445345 0.892626   # Compare summary stats with rmc(lambda=1) x_sample_mc <- rmc(1000, gamma = gamma_par, delta = delta_par, lambda = 1.0) print(\"Summary stats for rmc(l=1) sample:\") #> [1] \"Summary stats for rmc(l=1) sample:\" print(summary(x_sample_mc)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.00105 0.19221 0.31254 0.33300 0.45504 0.91894   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/rbkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","title":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","text":"Generates random deviates Beta-Kumaraswamy (BKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), gamma (\\(\\gamma\\)), delta (\\(\\delta\\)). distribution special case Generalized Kumaraswamy (GKw) distribution parameter \\(\\lambda = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","text":"","code":"rbkw(n, alpha, beta, gamma, delta)"},{"path":"https://evandeilton.github.io/gkwdist/reference/rbkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","text":"n Number observations. length(n) > 1, length taken number required. Must non-negative integer. alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","text":"vector length n containing random deviates BKw distribution. length result determined n recycling rule applied parameters (alpha, beta, gamma, delta). Returns NaN parameters invalid (e.g., alpha <= 0, beta <= 0, gamma <= 0, delta < 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","text":"generation method uses relationship GKw distribution Beta distribution. general procedure GKw (rgkw) : \\(W \\sim \\mathrm{Beta}(\\gamma, \\delta+1)\\), \\(X = \\{1 - [1 - W^{1/\\lambda}]^{1/\\beta}\\}^{1/\\alpha}\\) follows GKw(\\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\)) distribution. BKw distribution, \\(\\lambda=1\\). Therefore, algorithm simplifies : Generate \\(V \\sim \\mathrm{Beta}(\\gamma, \\delta+1)\\) using rbeta. Compute BKw variate \\(X = \\{1 - (1 - V)^{1/\\beta}\\}^{1/\\alpha}\\). procedure implemented efficiently, handling parameter recycling needed.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Devroye, L. (1986). Non-Uniform Random Variate Generation. Springer-Verlag. (General methods random variate generation).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/rbkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rbkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Number Generation for the Beta-Kumaraswamy (BKw) Distribution — rbkw","text":"","code":"# \\donttest{ set.seed(2026) # for reproducibility  # Generate 1000 random values from a specific BKw distribution alpha_par <- 2.0 beta_par <- 1.5 gamma_par <- 1.0 delta_par <- 0.5  x_sample_bkw <- rbkw(1000, alpha = alpha_par, beta = beta_par,                      gamma = gamma_par, delta = delta_par) summary(x_sample_bkw) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01187 0.36143 0.51194 0.51019 0.67906 0.99278   # Histogram of generated values compared to theoretical density hist(x_sample_bkw, breaks = 30, freq = FALSE, # freq=FALSE for density      main = \"Histogram of BKw Sample\", xlab = \"x\", ylim = c(0, 2.5)) curve(dbkw(x, alpha = alpha_par, beta = beta_par, gamma = gamma_par,            delta = delta_par),       add = TRUE, col = \"red\", lwd = 2, n = 201) legend(\"topright\", legend = \"Theoretical PDF\", col = \"red\", lwd = 2, bty = \"n\")   # Comparing empirical and theoretical quantiles (Q-Q plot) prob_points <- seq(0.01, 0.99, by = 0.01) theo_quantiles <- qbkw(prob_points, alpha = alpha_par, beta = beta_par,                        gamma = gamma_par, delta = delta_par) emp_quantiles <- quantile(x_sample_bkw, prob_points, type = 7)  plot(theo_quantiles, emp_quantiles, pch = 16, cex = 0.8,      main = \"Q-Q Plot for BKw Distribution\",      xlab = \"Theoretical Quantiles\", ylab = \"Empirical Quantiles (n=1000)\") abline(a = 0, b = 1, col = \"blue\", lty = 2)   # Compare summary stats with rgkw(..., lambda=1, ...) # Note: individual values will differ due to randomness x_sample_gkw <- rgkw(1000, alpha = alpha_par, beta = beta_par, gamma = gamma_par,                      delta = delta_par, lambda = 1.0) print(\"Summary stats for rbkw sample:\") #> [1] \"Summary stats for rbkw sample:\" print(summary(x_sample_bkw)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01187 0.36143 0.51194 0.51019 0.67906 0.99278  print(\"Summary stats for rgkw(lambda=1) sample:\") #> [1] \"Summary stats for rgkw(lambda=1) sample:\" print(summary(x_sample_gkw)) # Should be similar #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.04279 0.36298 0.52400 0.51632 0.67744 0.98445   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/rekw.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","title":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","text":"Generates random deviates Exponentiated Kumaraswamy (EKw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\gamma = 1\\) \\(\\delta = 0\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rekw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","text":"","code":"rekw(n, alpha, beta, lambda)"},{"path":"https://evandeilton.github.io/gkwdist/reference/rekw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","text":"n Number observations. length(n) > 1, length taken number required. Must non-negative integer. alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. lambda Shape parameter lambda > 0 (exponent parameter). Can scalar vector. Default: 1.0.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rekw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","text":"vector length n containing random deviates EKw distribution. length result determined n recycling rule applied parameters (alpha, beta, lambda). Returns NaN parameters invalid (e.g., alpha <= 0, beta <= 0, lambda <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rekw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","text":"generation method uses inverse transform (quantile) method. , \\(U\\) random variable following standard Uniform distribution (0, 1), \\(X = Q(U)\\) follows EKw distribution, \\(Q(u)\\) EKw quantile function (qekw): $$ Q(u) = \\left\\{ 1 - \\left[ 1 - u^{1/\\lambda} \\right]^{1/\\beta} \\right\\}^{1/\\alpha} $$ computationally equivalent general GKw generation method (rgkw) specialized \\(\\gamma=1, \\delta=0\\), required Beta(1, 1) random variate equivalent standard Uniform(0, 1) variate. implementation generates \\(U\\) using runif applies transformation .","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rekw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","text":"Nadarajah, S., Cordeiro, G. M., & Ortega, E. M. (2012). exponentiated Kumaraswamy distribution. Journal Franklin Institute, 349(3), Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Devroye, L. (1986). Non-Uniform Random Variate Generation. Springer-Verlag. (General methods random variate generation).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/rekw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rekw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Number Generation for the Exponentiated Kumaraswamy (EKw) Distribution — rekw","text":"","code":"# \\donttest{ set.seed(2027) # for reproducibility  # Generate 1000 random values from a specific EKw distribution alpha_par <- 2.0 beta_par <- 3.0 lambda_par <- 1.5  x_sample_ekw <- rekw(1000, alpha = alpha_par, beta = beta_par, lambda = lambda_par) summary(x_sample_ekw) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01796 0.40449 0.53117 0.52906 0.65941 0.95165   # Histogram of generated values compared to theoretical density hist(x_sample_ekw, breaks = 30, freq = FALSE, # freq=FALSE for density      main = \"Histogram of EKw Sample\", xlab = \"x\", ylim = c(0, 3.0)) curve(dekw(x, alpha = alpha_par, beta = beta_par, lambda = lambda_par),       add = TRUE, col = \"red\", lwd = 2, n = 201) legend(\"topright\", legend = \"Theoretical PDF\", col = \"red\", lwd = 2, bty = \"n\")   # Comparing empirical and theoretical quantiles (Q-Q plot) prob_points <- seq(0.01, 0.99, by = 0.01) theo_quantiles <- qekw(prob_points, alpha = alpha_par, beta = beta_par,                        lambda = lambda_par) emp_quantiles <- quantile(x_sample_ekw, prob_points, type = 7)  plot(theo_quantiles, emp_quantiles, pch = 16, cex = 0.8,      main = \"Q-Q Plot for EKw Distribution\",      xlab = \"Theoretical Quantiles\", ylab = \"Empirical Quantiles (n=1000)\") abline(a = 0, b = 1, col = \"blue\", lty = 2)   # Compare summary stats with rgkw(..., gamma=1, delta=0, ...) # Note: individual values will differ due to randomness x_sample_gkw <- rgkw(1000, alpha = alpha_par, beta = beta_par, gamma = 1.0,                      delta = 0.0, lambda = lambda_par) print(\"Summary stats for rekw sample:\") #> [1] \"Summary stats for rekw sample:\" print(summary(x_sample_ekw)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01796 0.40449 0.53117 0.52906 0.65941 0.95165  print(\"Summary stats for rgkw(gamma=1, delta=0) sample:\") #> [1] \"Summary stats for rgkw(gamma=1, delta=0) sample:\" print(summary(x_sample_gkw)) # Should be similar #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.02851 0.39394 0.53074 0.52923 0.66914 0.98175   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/rgkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Generalized Kumaraswamy Distribution Random Generation — rgkw","title":"Generalized Kumaraswamy Distribution Random Generation — rgkw","text":"Generates random deviates five-parameter Generalized Kumaraswamy (GKw) distribution defined interval (0, 1).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rgkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generalized Kumaraswamy Distribution Random Generation — rgkw","text":"","code":"rgkw(n, alpha, beta, gamma, delta, lambda)"},{"path":"https://evandeilton.github.io/gkwdist/reference/rgkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generalized Kumaraswamy Distribution Random Generation — rgkw","text":"n Number observations. length(n) > 1, length taken number required. Must non-negative integer. alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rgkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generalized Kumaraswamy Distribution Random Generation — rgkw","text":"vector length n containing random deviates GKw distribution. length result determined n recycling rule applied parameters (alpha, beta, gamma, delta, lambda). Returns NaN parameters invalid (e.g., alpha <= 0, beta <= 0, gamma <= 0, delta < 0, lambda <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rgkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generalized Kumaraswamy Distribution Random Generation — rgkw","text":"generation method relies transformation property: \\(V \\sim \\mathrm{Beta}(\\gamma, \\delta+1)\\), random variable X defined $$ X = \\left\\{ 1 - \\left[ 1 - V^{1/\\lambda} \\right]^{1/\\beta} \\right\\}^{1/\\alpha} $$ follows GKw(\\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\)) distribution. algorithm proceeds follows: Generate V stats::rbeta(n, shape1 = gamma, shape2 = delta + 1). Calculate \\(v = V^{1/\\lambda}\\). Calculate \\(w = (1 - v)^{1/\\beta}\\). Calculate \\(x = (1 - w)^{1/\\alpha}\\). Parameters (alpha, beta, gamma, delta, lambda) recycled match length required n. Numerical stability maintained handling potential edge cases transformations.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rgkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Generalized Kumaraswamy Distribution Random Generation — rgkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88.","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/rgkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Generalized Kumaraswamy Distribution Random Generation — rgkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rgkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generalized Kumaraswamy Distribution Random Generation — rgkw","text":"","code":"# \\donttest{ set.seed(1234) # for reproducibility  # Generate 1000 random values from a specific GKw distribution (Kw case) x_sample <- rgkw(1000, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) summary(x_sample) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01524 0.31493 0.46345 0.46265 0.60804 0.96441   # Histogram of generated values compared to theoretical density hist(x_sample, breaks = 30, freq = FALSE, # freq=FALSE for density scale      main = \"Histogram of GKw(2,3,1,0,1) Sample\", xlab = \"x\", ylim = c(0, 2.5)) curve(dgkw(x, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1),       add = TRUE, col = \"red\", lwd = 2, n = 201) legend(\"topright\", legend = \"Theoretical PDF\", col = \"red\", lwd = 2, bty = \"n\")   # Comparing empirical and theoretical quantiles (Q-Q plot) prob_points <- seq(0.01, 0.99, by = 0.01) theo_quantiles <- qgkw(prob_points, alpha = 2, beta = 3, gamma = 1, delta = 0, lambda = 1) emp_quantiles <- quantile(x_sample, prob_points)  plot(theo_quantiles, emp_quantiles, pch = 16, cex = 0.8,      main = \"Q-Q Plot for GKw(2,3,1,0,1)\",      xlab = \"Theoretical Quantiles\", ylab = \"Empirical Quantiles (n=1000)\") abline(a = 0, b = 1, col = \"blue\", lty = 2)   # Using vectorized parameters: generate 1 value for each alpha alphas_vec <- c(0.5, 1.0, 2.0) n_param <- length(alphas_vec) samples_vec <- rgkw(n_param, alpha = alphas_vec, beta = 2, gamma = 1, delta = 0, lambda = 1) print(samples_vec) # One sample for each alpha value #> [1] 0.4386491 0.2135709 0.8667377 # Result length matches n=3, parameters alpha recycled accordingly  # Example with invalid parameters (should produce NaN) invalid_sample <- rgkw(1, alpha = -1, beta = 2, gamma = 1, delta = 0, lambda = 1) #> Warning: rgkw: invalid parameters at index 1 (alpha,beta,gamma>0, delta>=0, lambda>0) print(invalid_sample) #> [1] NA # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/rkkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Number Generation for the kkw Distribution — rkkw","title":"Random Number Generation for the kkw Distribution — rkkw","text":"Generates random deviates Kumaraswamy-Kumaraswamy (kkw) distribution parameters alpha (\\(\\alpha\\)), beta (\\(\\beta\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution parameter \\(\\gamma = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Number Generation for the kkw Distribution — rkkw","text":"","code":"rkkw(n, alpha, beta, delta, lambda)"},{"path":"https://evandeilton.github.io/gkwdist/reference/rkkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Number Generation for the kkw Distribution — rkkw","text":"n Number observations. length(n) > 1, length taken number required. Must non-negative integer. alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Number Generation for the kkw Distribution — rkkw","text":"vector length n containing random deviates kkw distribution. length result determined n recycling rule applied parameters (alpha, beta, delta, lambda). Returns NaN parameters invalid (e.g., alpha <= 0, beta <= 0, delta < 0, lambda <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Number Generation for the kkw Distribution — rkkw","text":"generation method uses inverse transform method based quantile function (qkkw). kkw quantile function : $$ Q(p) = \\left[ 1 - \\left\\{ 1 - \\left[ 1 - (1 - p)^{1/(\\delta+1)} \\right]^{1/\\lambda} \\right\\}^{1/\\beta} \\right]^{1/\\alpha} $$ Random deviates generated evaluating \\(Q(p)\\) \\(p\\) random variable following standard Uniform distribution (0, 1) (runif). equivalent general method GKw distribution (rgkw) specialized \\(\\gamma=1\\). GKw method generates \\(W \\sim \\mathrm{Beta}(\\gamma, \\delta+1)\\) applies transformations. \\(\\gamma=1\\), \\(W \\sim \\mathrm{Beta}(1, \\delta+1)\\), can generated via \\(W = 1 - V^{1/(\\delta+1)}\\) \\(V \\sim \\mathrm{Unif}(0,1)\\). Substituting \\(W\\) GKw transformation yields result evaluating \\(Q(1-V)\\) (noting \\(p = 1-V\\) also Uniform).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random Number Generation for the kkw Distribution — rkkw","text":"Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Devroye, L. (1986). Non-Uniform Random Variate Generation. Springer-Verlag. (General methods random variate generation).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/rkkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Random Number Generation for the kkw Distribution — rkkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Number Generation for the kkw Distribution — rkkw","text":"","code":"# \\donttest{ set.seed(2025) # for reproducibility  # Generate 1000 random values from a specific kkw distribution alpha_par <- 2.0 beta_par <- 3.0 delta_par <- 0.5 lambda_par <- 1.5  x_sample_kkw <- rkkw(1000, alpha = alpha_par, beta = beta_par,                        delta = delta_par, lambda = lambda_par) summary(x_sample_kkw) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.06135 0.34367 0.46565 0.46855 0.58892 0.88108   # Histogram of generated values compared to theoretical density hist(x_sample_kkw, breaks = 30, freq = FALSE, # freq=FALSE for density      main = \"Histogram of kkw Sample\", xlab = \"x\", ylim = c(0, 3.5)) curve(dkkw(x, alpha = alpha_par, beta = beta_par, delta = delta_par,             lambda = lambda_par),       add = TRUE, col = \"red\", lwd = 2, n = 201) legend(\"topright\", legend = \"Theoretical PDF\", col = \"red\", lwd = 2, bty = \"n\")   # Comparing empirical and theoretical quantiles (Q-Q plot) prob_points <- seq(0.01, 0.99, by = 0.01) theo_quantiles <- qkkw(prob_points, alpha = alpha_par, beta = beta_par,                         delta = delta_par, lambda = lambda_par) emp_quantiles <- quantile(x_sample_kkw, prob_points, type = 7) # type 7 is default  plot(theo_quantiles, emp_quantiles, pch = 16, cex = 0.8,      main = \"Q-Q Plot for kkw Distribution\",      xlab = \"Theoretical Quantiles\", ylab = \"Empirical Quantiles (n=1000)\") abline(a = 0, b = 1, col = \"blue\", lty = 2)   # Compare summary stats with rgkw(..., gamma=1, ...) # Note: individual values will differ due to randomness x_sample_gkw <- rgkw(1000, alpha = alpha_par, beta = beta_par, gamma = 1.0,                      delta = delta_par, lambda = lambda_par) print(\"Summary stats for rkkw sample:\") #> [1] \"Summary stats for rkkw sample:\" print(summary(x_sample_kkw)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.06135 0.34367 0.46565 0.46855 0.58892 0.88108  print(\"Summary stats for rgkw(gamma=1) sample:\") #> [1] \"Summary stats for rgkw(gamma=1) sample:\" print(summary(x_sample_gkw)) # Should be similar #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.04101 0.34241 0.46850 0.46428 0.58476 0.88441  # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/rkw.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","title":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","text":"Generates random deviates two-parameter Kumaraswamy (Kw) distribution shape parameters alpha (\\(\\alpha\\)) beta (\\(\\beta\\)).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","text":"","code":"rkw(n, alpha, beta)"},{"path":"https://evandeilton.github.io/gkwdist/reference/rkw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","text":"n Number observations. length(n) > 1, length taken number required. Must non-negative integer. alpha Shape parameter alpha > 0. Can scalar vector. Default: 1.0. beta Shape parameter beta > 0. Can scalar vector. Default: 1.0.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","text":"vector length n containing random deviates Kw distribution, values (0, 1). length result determined n recycling rule applied parameters (alpha, beta). Returns NaN parameters invalid (e.g., alpha <= 0, beta <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkw.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","text":"generation method uses inverse transform (quantile) method. , \\(U\\) random variable following standard Uniform distribution (0, 1), \\(X = Q(U)\\) follows Kw distribution, \\(Q(p)\\) Kw quantile function (qkw): $$ Q(p) = \\left\\{ 1 - (1 - p)^{1/\\beta} \\right\\}^{1/\\alpha} $$ implementation generates \\(U\\) using runif applies transformation. equivalent general GKw generation method (rgkw) evaluated \\(\\gamma=1, \\delta=0, \\lambda=1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkw.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","text":"Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Jones, M. C. (2009). Kumaraswamy's distribution: beta-type distribution tractability advantages. Statistical Methodology, 6(1), 70-81. Devroye, L. (1986). Non-Uniform Random Variate Generation. Springer-Verlag. (General methods random variate generation).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/rkw.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rkw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Number Generation for the Kumaraswamy (Kw) Distribution — rkw","text":"","code":"# \\donttest{ set.seed(2029) # for reproducibility  # Generate 1000 random values from a specific Kw distribution alpha_par <- 2.0 beta_par <- 3.0  x_sample_kw <- rkw(1000, alpha = alpha_par, beta = beta_par) summary(x_sample_kw) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01825 0.29985 0.45247 0.45264 0.58978 0.93608   # Histogram of generated values compared to theoretical density hist(x_sample_kw, breaks = 30, freq = FALSE, # freq=FALSE for density      main = \"Histogram of Kw Sample\", xlab = \"x\", ylim = c(0, 2.5)) curve(dkw(x, alpha = alpha_par, beta = beta_par),       add = TRUE, col = \"red\", lwd = 2, n = 201) legend(\"top\", legend = \"Theoretical PDF\", col = \"red\", lwd = 2, bty = \"n\")   # Comparing empirical and theoretical quantiles (Q-Q plot) prob_points <- seq(0.01, 0.99, by = 0.01) theo_quantiles <- qkw(prob_points, alpha = alpha_par, beta = beta_par) emp_quantiles <- quantile(x_sample_kw, prob_points, type = 7)  plot(theo_quantiles, emp_quantiles, pch = 16, cex = 0.8,      main = \"Q-Q Plot for Kw Distribution\",      xlab = \"Theoretical Quantiles\", ylab = \"Empirical Quantiles (n=1000)\") abline(a = 0, b = 1, col = \"blue\", lty = 2)   # Compare summary stats with rgkw(..., gamma=1, delta=0, lambda=1) # Note: individual values will differ due to randomness x_sample_gkw <- rgkw(1000, alpha = alpha_par, beta = beta_par, gamma = 1.0,                      delta = 0.0, lambda = 1.0) print(\"Summary stats for rkw sample:\") #> [1] \"Summary stats for rkw sample:\" print(summary(x_sample_kw)) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01825 0.29985 0.45247 0.45264 0.58978 0.93608  print(\"Summary stats for rgkw(gamma=1, delta=0, lambda=1) sample:\") #> [1] \"Summary stats for rgkw(gamma=1, delta=0, lambda=1) sample:\" print(summary(x_sample_gkw)) # Should be similar #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.00568 0.30017 0.45069 0.45469 0.59646 0.95381   # }"},{"path":"https://evandeilton.github.io/gkwdist/reference/rmc.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","title":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","text":"Generates random deviates McDonald (Mc) distribution (also known Beta Power) parameters gamma (\\(\\gamma\\)), delta (\\(\\delta\\)), lambda (\\(\\lambda\\)). distribution special case Generalized Kumaraswamy (GKw) distribution \\(\\alpha = 1\\) \\(\\beta = 1\\).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rmc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","text":"","code":"rmc(n, gamma, delta, lambda)"},{"path":"https://evandeilton.github.io/gkwdist/reference/rmc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","text":"n Number observations. length(n) > 1, length taken number required. Must non-negative integer. gamma Shape parameter gamma > 0. Can scalar vector. Default: 1.0. delta Shape parameter delta >= 0. Can scalar vector. Default: 0.0. lambda Shape parameter lambda > 0. Can scalar vector. Default: 1.0.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rmc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","text":"vector length n containing random deviates Mc distribution, values (0, 1). length result determined n recycling rule applied parameters (gamma, delta, lambda). Returns NaN parameters invalid (e.g., gamma <= 0, delta < 0, lambda <= 0).","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rmc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","text":"generation method uses relationship GKw distribution Beta distribution. general procedure GKw (rgkw) : \\(W \\sim \\mathrm{Beta}(\\gamma, \\delta+1)\\), \\(X = \\{1 - [1 - W^{1/\\lambda}]^{1/\\beta}\\}^{1/\\alpha}\\) follows GKw(\\(\\alpha, \\beta, \\gamma, \\delta, \\lambda\\)) distribution. Mc distribution, \\(\\alpha=1\\) \\(\\beta=1\\). Therefore, algorithm simplifies significantly: Generate \\(U \\sim \\mathrm{Beta}(\\gamma, \\delta+1)\\) using rbeta. Compute Mc variate \\(X = U^{1/\\lambda}\\). procedure implemented efficiently, handling parameter recycling needed.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rmc.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","text":"McDonald, J. B. (1984). generalized functions size distribution income. Econometrica, 52(3), 647-663. Cordeiro, G. M., & de Castro, M. (2011). new family generalized distributions. Journal Statistical Computation Simulation, Kumaraswamy, P. (1980). generalized probability density function double-bounded random processes. Journal Hydrology, 46(1-2), 79-88. Devroye, L. (1986). Non-Uniform Random Variate Generation. Springer-Verlag. (General methods random variate generation).","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/reference/rmc.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","text":"Lopes, J. E.","code":""},{"path":"https://evandeilton.github.io/gkwdist/reference/rmc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Number Generation for the McDonald (Mc)/Beta Power Distribution — rmc","text":"","code":"# \\donttest{ set.seed(2028) # for reproducibility  # Generate 1000 random values from a specific Mc distribution gamma_par <- 2.0 delta_par <- 1.5 lambda_par <- 1.0 # Equivalent to Beta(gamma, delta+1)  x_sample_mc <- rmc(1000, gamma = gamma_par, delta = delta_par,                    lambda = lambda_par) summary(x_sample_mc) #>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.  #> 0.01013 0.27034 0.43516 0.44456 0.60679 0.97755   # Histogram of generated values compared to theoretical density hist(x_sample_mc, breaks = 30, freq = FALSE, # freq=FALSE for density      main = \"Histogram of Mc Sample (Beta Case)\", xlab = \"x\") curve(dmc(x, gamma = gamma_par, delta = delta_par, lambda = lambda_par),       add = TRUE, col = \"red\", lwd = 2, n = 201) curve(stats::dbeta(x, gamma_par, delta_par + 1), add=TRUE, col=\"blue\", lty=2) legend(\"topright\", legend = c(\"Theoretical Mc PDF\", \"Theoretical Beta PDF\"),        col = c(\"red\", \"blue\"), lwd = c(2,1), lty=c(1,2), bty = \"n\")   # Comparing empirical and theoretical quantiles (Q-Q plot) lambda_par_qq <- 0.7 # Use lambda != 1 for non-Beta case x_sample_mc_qq <- rmc(1000, gamma = gamma_par, delta = delta_par,                       lambda = lambda_par_qq) prob_points <- seq(0.01, 0.99, by = 0.01) theo_quantiles <- qmc(prob_points, gamma = gamma_par, delta = delta_par,                       lambda = lambda_par_qq) emp_quantiles <- quantile(x_sample_mc_qq, prob_points, type = 7)  plot(theo_quantiles, emp_quantiles, pch = 16, cex = 0.8,      main = \"Q-Q Plot for Mc Distribution\",      xlab = \"Theoretical Quantiles\", ylab = \"Empirical Quantiles (n=1000)\") abline(a = 0, b = 1, col = \"blue\", lty = 2)   # Compare summary stats with rgkw(..., alpha=1, beta=1, ...) # Note: individual values will differ due to randomness x_sample_gkw <- rgkw(1000, alpha = 1.0, beta = 1.0, gamma = gamma_par,                      delta = delta_par, lambda = lambda_par_qq) print(\"Summary stats for rmc sample:\") #> [1] \"Summary stats for rmc sample:\" print(summary(x_sample_mc_qq)) #>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.  #> 0.0008202 0.1596539 0.3145063 0.3473583 0.5006081 0.9639265  print(\"Summary stats for rgkw(alpha=1, beta=1) sample:\") #> [1] \"Summary stats for rgkw(alpha=1, beta=1) sample:\" print(summary(x_sample_gkw)) # Should be similar #>     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.  #> 0.007415 0.159005 0.298210 0.330192 0.483725 0.932327   # }"},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"documentation-improvements-1-0-5","dir":"Changelog","previous_headings":"","what":"Documentation Improvements","title":"gkwdist 1.0.5","text":"Enhanced Examples Likelihood Functions: ll*, gr*, hs* functions now include comprehensive examples demonstrating: Maximum likelihood estimation analytical gradients Univariate profile likelihoods confidence thresholds 2D likelihood surfaces confidence regions (90%, 95%, 99%) Confidence ellipses marginal intervals parameter pairs Numerical vs analytical derivative verification Likelihood ratio tests score tests Professional Visualization Standards: Consistent color scheme across examples Grid-adaptive algorithms computational efficiency Base R - external dependencies required Complete Coverage: Enhanced documentation distribution families (Kw, EKw, KKw, GKw) covering 2 5 parameters Theoretical References: Documentation cites foundational work Carrasco et al. (2010), Jones (2009), Kumaraswamy (1980), standard inference theory Casella & Berger (2002)","code":""},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"gkwdist-103","dir":"Changelog","previous_headings":"","what":"gkwdist 1.0.3","title":"gkwdist 1.0.3","text":"Fix zzz.R file removing useless texts","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"enhanced-gkwgetstartvalues-function-1-0-1","dir":"Changelog","previous_headings":"Major Improvements","what":"Enhanced gkwgetstartvalues() Function","title":"gkwdist 1.0.1","text":"Automatically returns correct number parameters family Family-specific initial value strategies better convergence Supported families: \"gkw\", \"bkw\", \"kkw\", \"ekw\", \"mc\", \"kw\", \"beta\" Case-insensitive family names user convenience","code":""},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"documentation-enhancements-1-0-1","dir":"Changelog","previous_headings":"Major Improvements","what":"Documentation Enhancements","title":"gkwdist 1.0.1","text":"LaTeX formulas corrected verified proper rendering Eight comprehensive examples using optim() analytical gradients Corrected function signatures: ll*(), gr*(), hs*() functions use (par, data) signature Added performance benchmarks demonstrating 10-50× speedup C++ implementation Hierarchical structure diagram distribution families Model selection workflow practical guidelines Removed references deprecated gkwfit() function","code":""},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"cran-submission-readiness-1-0-1","dir":"Changelog","previous_headings":"Major Improvements","what":"CRAN Submission Readiness","title":"gkwdist 1.0.1","text":"Proper Authors@R field formatting Removed unused dependencies (numDeriv) Corrected package dependencies (RcppArmadillo LinkingTo) Enhanced description DOI references Fixed maintainer email formatting","code":""},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"bug-fixes-1-0-1","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"gkwdist 1.0.1","text":"Fixed function call signatures README examples match actual implementation Corrected parameter passing optimization examples (now consistently use (par, data)) Fixed LaTeX rendering issues \\left/\\right delimiters GitHub Markdown","code":""},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"testing-1-0-1","dir":"Changelog","previous_headings":"","what":"Testing","title":"gkwdist 1.0.1","text":"100+ tests covering exported functions Tests 7 distribution families (GKw, BKw, KKw, EKw, MC, Kw, Beta) PDF, CDF, quantile, random generation tests Log-likelihood, gradient, Hessian validation Parameter recovery tests MLE Edge cases boundary condition handling Integration tests PDF-CDF consistency","code":""},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"performance-1-0-1","dir":"Changelog","previous_headings":"","what":"Performance","title":"gkwdist 1.0.1","text":"functions implemented C++ maximum computational efficiency Analytical derivatives (gradient Hessian) provide exact computations Optimized numerical stability extreme parameter values","code":""},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"notes-1-0-1","dir":"Changelog","previous_headings":"","what":"Notes","title":"gkwdist 1.0.1","text":"initial CRAN submission Package focuses exclusively distribution functions (high-level fitting interface) Companion package gkwreg provides regression modeling capabilities user-facing functions maintain backward compatibility C++ implementation uses RcppArmadillo linear algebra operations Analytical functions use robust log-scale computations prevent overflow/underflow Random generation uses inverse CDF method closed-form solutions exist","code":""},{"path":[]},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"new-features-0-1-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"gkwdist 0.1.0","text":"Initial CRAN release Generalized Kumaraswamy distribution (5 parameters) Six nested sub-families: Beta, Kumaraswamy, Exponentiated-Kumaraswamy, Kumaraswamy-Kumaraswamy, Beta-Kumaraswamy, McDonald distributions Complete set distribution functions (d/p/q/r) Log-likelihood, gradient, Hessian functions families","code":""},{"path":"https://evandeilton.github.io/gkwdist/news/index.html","id":"performance-0-1-0","dir":"Changelog","previous_headings":"","what":"Performance","title":"gkwdist 0.1.0","text":"Optimized C++ implementation via Rcpp Vectorized operations speed","code":""}]
